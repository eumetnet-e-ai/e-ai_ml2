%!TEX root = lec09.tex
% ================================================================================
% Lecture 9 â€” Slide 03
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Sampling via a Neural Network}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.56\textwidth}

\textbf{Neural sampler: noise $\rightarrow$ data}

\begin{codeonly}{Neural generator mapping noise to samples}
class Generator(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(1, 64),
            nn.ReLU(),
            nn.Linear(64, 64),
            nn.ReLU(),
            nn.Linear(64, 1) )

    def forward(self, z):
        return self.net(z)
\end{codeonly}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.4\textwidth}

\vspace{-9mm}
The network transforms white noise into samples.

\vspace{2mm}
\textbf{What is different from regression?}

\begin{itemize}
  \item No target output for a given input
  \item Input is random noise
  \item Only the \emph{distribution} matters
\end{itemize}

\vspace{2mm}
\textbf{Interpretation}

\begin{itemize}
  \item $z \sim \mathcal{N}(0,1)$
  \item $x = f_\theta(z) \sim p_\theta(x)$
\end{itemize}

\footnotesize
\begin{lstlisting}
z = torch.randn(N, 1) # noise
x = G(z)           # samples
\end{lstlisting}

\end{column}

\end{columns}

\end{frame}
