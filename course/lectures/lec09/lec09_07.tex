%!TEX root = lec09.tex
% ================================================================================
% Lecture 9 â€” Slide 07
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Forward Diffusion: Adding Noise Step by Step}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.55\textwidth}

\textbf{Forward process}

We gradually destroy structure by adding noise:
\[
x_t = \sqrt{\bar{\alpha}_t}\,x_0
     + \sqrt{1-\bar{\alpha}_t}\,\epsilon,
\quad \epsilon \sim \mathcal{N}(0,1)
\]

\vspace{2mm}
\begin{itemize}
  \item $t = 0$: clean data
  \item $t \uparrow$: increasing noise
  \item $t = T$: pure noise
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.4\textwidth}

\vspace{-2mm}
\textbf{Important properties}

\begin{itemize}
  \item Process is \y{fixed}
  \item No learning involved
  \item Fully known statistics
\end{itemize}

\vspace{2mm}
\textbf{Why do this?}

\begin{itemize}
  \item Generates training data
  \item Connects data to noise
\end{itemize}

\vspace{2mm}
This defines the learning problem.

\end{column}

\end{columns}

\end{frame}
