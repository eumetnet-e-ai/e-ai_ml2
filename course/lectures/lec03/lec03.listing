import torch, time
torch.set_default_dtype(torch.float16)
d = torch.device("cuda")
x = torch.randn((20000,1024), device=d)
W1 = torch.randn((1024,4096), device=d)
W2 = torch.randn((4096,1024), device=d)
t0 = time.time()
y = torch.nn.functional.gelu(x @ W1)
z = y @ W2
torch.cuda.synchronize()
print("FP16 time:", round(time.time()-t0,3))
