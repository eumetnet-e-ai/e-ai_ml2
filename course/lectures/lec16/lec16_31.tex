%!TEX root = lec16.tex
% ================================================================================
% Lecture 16 â€” Slide 31
% ================================================================================
\begin{frame}[t]
\mytitle{Why This Is \emph{Not} Explicit Pattern Matching}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.56\textwidth}
\footnotesize
\vspace{-2mm}

A common misconception is:
\begin{center}
\textit{``The network finds the blob pattern and just copies it forward.''}
\end{center}

\vspace{2mm}
\textbf{What actually happens:}
\begin{itemize}
  \item the CNN computes many internal feature variables (32 channels)
  \item each channel responds to \y{different local aspects}
  \item the forecast is produced by recombining these features
\end{itemize}

\vspace{2mm}
\rtext{\textbf{Key point:}
the NN does not store templates --- it learns a \y{continuous mapping}
from input to forecast.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}

\vspace{-8mm}
\begin{center}
\includegraphics[width=\linewidth]{../../images/img16/cnn_translation_features_h2.png}
\includegraphics[width=\linewidth]{../../images/img16/cnn_translation_features_h3.png}

\vspace{1mm}
{\scriptsize \textit{Example: 6 of 32 feature channels in layer $h3$.}}
\end{center}
\end{column}

\end{columns}
\end{frame}
