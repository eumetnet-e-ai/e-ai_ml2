%!TEX root = lec08.tex
% ================================================================================
% Lecture 08 â€” Slide 24
% ================================================================================
\begin{frame}[t]

\mytitle{Multimodal Models Available at OpenAI}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\textbf{GPT-4 family}

\begin{itemize}
  \item First widely deployed multimodal models
  \item Text and image input
  \item Text output
  \item Strong vision-language reasoning
\end{itemize}

\vspace{0mm}
Typical use cases:
\begin{itemize}
  \item image interpretation
  \item document understanding
  \item visual question answering
\end{itemize}

\vspace{2mm}
Used extensively in early multimodal
weather and geoscience applications.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}

\vspace{-7mm}
\textbf{GPT-5 family}

\begin{itemize}
  \item Current OpenAI foundation model generation
  \item Native multimodal reasoning
  \item Text and image input
  \item Text output with improved reasoning depth
\end{itemize}

\vspace{0mm}
Key characteristics:
\begin{itemize}
  \item stronger cross-modal alignment
  \item improved robustness and consistency
  \item better handling of complex visual scenes
\end{itemize}

\end{column}

\end{columns}

\end{frame}
