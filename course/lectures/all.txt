%!TEX root = lec00.tex
% ================================================================================
% Lecture 00 — Intro Slides 01–10
% File: lec00_01.tex
% ================================================================================

% ================================================================================
% Slide 01
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}
\mytitle{AI as Strategic Transformation}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.60\textwidth}
\footnotesize
\vspace{-2mm}


\vspace{1mm}
Artificial Intelligence is becoming a \y{core component} of the next-generation
\y{observation--forecast--service chain}.

\vspace{2mm}
\textbf{What changes}

\begin{itemize}
  \item Some components will be \y{replaced by AI-driven methods}
  \item Many will be \y{hybridized} for better efficiency and accuracy
  \item Some remain targeted classical methods --- but AI supports their
        \y{use, development and understanding}
\end{itemize}

\vspace{1mm}
\textbf{Strategic goal:} enable \y{scalable AI adoption} without losing
\y{operational stability}.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.40\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{Key point}

\vspace{1mm}
\begin{quote}
\textbf{AI transforms the full modeling ecosystem, not just single algorithms.}
\end{quote}

\vspace{2mm}
\textbf{Outcome}

\vspace{1mm}
\begin{itemize}
  \item faster cycles from idea to product
  \item stronger automation in workflows
  \item new products and interaction modes
\end{itemize}

\end{column}

\end{columns}
\end{tightmath}
\end{frame}
% ================================================================================
% Lecture 00 — Slide 02
% ================================================================================

\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{AI as Tool of Discovery: From Ideas to Tested Systems}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{Discovery viewpoint}

\vspace{1mm}
AI is not only about producing forecasts --- it increasingly supports
\y{scientific discovery} and \y{systematic development}.

\vspace{2mm}
\textbf{What AI adds to science and engineering}

\begin{itemize}
  \item accelerate \y{coding and refactoring} of research and operational software
  \item help to \y{formulate} \rtext{equations, losses, and constraints} in a consistent way
  \item generate \y{tests}, validation scripts, and diagnostic plots automatically
  \item \y{explore hypotheses}: \rtext{patterns, regimes, causal links} in large datasets
\end{itemize}


\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\vspace{2mm}
\textbf{Result}

\vspace{1mm}
We move from isolated scripts to \y{AI-supported workflows}
that iterate fast: idea $\rightarrow$ prototype $\rightarrow$ test $\rightarrow$ deploy.

\vspace{5mm}
\textbf{Key takeaway}

\vspace{1mm}
\begin{quote}
\textbf{AI becomes part of the scientific method:}
hypothesize, implement, test, improve.
\end{quote}

\includegraphics[height=2cm]{../../images/img16/physics_and_ai.png}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
% ================================================================================
% Lecture 00 — Slide 03 (REVISED layout)
% ================================================================================

\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Python Everywhere: The Universal AI Workflow Environment}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{Course principle}

\vspace{1mm}
We learn AI techniques inside a \y{Python-based workflow} ---
because this is the environment that is \y{adequate today} for research and operations.

\vspace{2mm}
\textbf{Python runs everywhere}

\begin{itemize}
  \item \y{laptop} development and rapid prototyping
  \item \y{online + browser} execution (cloud notebooks, collaboration)
  \item \y{GPU} training environments
  \item \y{Linux + macOS} daily engineering platforms
  \item \y{HPC systems} for scaling and operations
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{Practical consequences}

\vspace{1mm}
\begin{itemize}
  \item transfer skills \y{across platforms} with minimal friction
  \item the same toolchain supports \y{research and operations}
  \item consistent workflows: \y{data}, \y{training}, \y{inference}, \y{plots}
\end{itemize}

\vspace{2mm}
\textbf{Key message}

\vspace{1mm}
\begin{quote}
\textbf{Python is mastering data, models, and operations.}
\end{quote}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
% ================================================================================
% Lecture 00 — Slide 04
% ================================================================================

\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{We Use Git Heavily: Reproducibility, Collaboration, Traceability}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.62\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{Course principle}

\vspace{1mm}
We use \y{Git} as the backbone for structured work --- not optional, but essential.

\vspace{2mm}
\textbf{Why Git matters}

\begin{itemize}
  \item \y{reproducibility:} exact versions of code + configs
  \item \y{collaboration:} branching, merging, review culture
  \item \y{traceability:} who changed what, why, and when
  \item \y{safe experimentation:} try ideas without breaking the main line
\end{itemize}

\vspace{2mm}
\textbf{Operational viewpoint}

\vspace{1mm}
Modern AI systems require \y{controlled evolution}:
models, code, data interfaces and validation must co-evolve.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.38\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{Key takeaway}

\vspace{1mm}
\begin{quote}
\textbf{Git makes individual work maintainable and save.}
\end{quote}

\vspace{2mm}
\textbf{In this course}

\begin{itemize}
  \item clone / pull / commit daily
  \item structured repos for lectures + code
  \item CI/CD connection later in the week
\end{itemize}

\vspace{4mm}
\rtext{\y{\bf Setup your own git repos!}}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
% ================================================================================
% Lecture 00 — Slide 05
% ================================================================================

\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Domain Knowledge Stays Central: AI Needs Science}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{Message to classical modelers}

\vspace{1mm}
AI does \rtext{not} replace domain expertise.
Instead, \y{domain knowledge becomes even more valuable}:
it determines what is physically meaningful, operationally relevant,
and scientifically trustworthy.

\vspace{2mm}
\begin{minipage}[b]{4cm}
\textbf{Why expertise matters}

\begin{itemize}
  \item choose variables, scales, and constraints
  \item define loss functions and evaluation metrics
  \item identify artefacts vs.\ true signals
  \item judge extreme events and non-stationarity
\end{itemize}
\end{minipage}
\begin{minipage}[t]{2cm}
\includegraphics[width=3.4cm]{../../images/img16/weather_t1_t48_rain_gsp_1honly_europe_crop.png}
\end{minipage}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{Weather service viewpoint}

\vspace{1mm}
Forecasting is not only a model:
it is an \y{ecosystem} of \rtext{\bf observation processing, modeling,
validation, products and communication.}

\vspace{2mm}
\textbf{Domain knowledge is central in}

\begin{itemize}
  \item \y{services:} impact products, warnings, tailored guidance
  \item \y{forecasting:} interpretation, uncertainty, plausibility
  \item \y{development:} model design, physics coupling, DA strategy
\end{itemize}

\vspace{2mm}
\raggedright
\begin{quote}
\textbf{AI becomes powerful when grounded in science.}
\end{quote}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
% ================================================================================
% E-AI Tutorial Slides
% Filename: lec00.tex
% 
% Roland Potthast 2025/2026
% Licence: CC-BY4.0
% ================================================================================
\documentclass[aspectratio=169]{beamer}

% --- Load lecture macros --------------------------------------------------------
\input{../lec_macros.tex}
\newcommand{\LectureNumber}{Lecture 0/20}

% --- Document -------------------------------------------------------------------
\begin{document}

\setagendaboxforlecture{1}

\input{../lec_agenda.tex}
\input{lec00_01.tex}
\input{lec00_02.tex}
\input{lec00_03.tex}
\input{lec00_04.tex}
\input{lec00_05.tex}
\input{lec00_06.tex}
\input{lec00_07.tex}

% --- End Document ---------------------------------------------------------------
\end{document}
%!TEX root = lec01.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t,fragile]

% --- Title ---------------------------------------------------------------------
\mytitle{Lecture 1: Python Setup and Basics}

% --- Content -------------------------------------------------------------------
\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Goal of Lecture}

\begin{itemize}
  \item Setup Python
  \item \y{Synchronize} with your knowledge of programming
  \item Become aware of the importance of proper \y{package management}
  \item Numpy and Matplotlib
  \item Get simple plots working
  \item write and import functions
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\begin{itemize}
  \item Flow Control
  \item File management
  \item \y{Dictionaries}
  \item \y{Json} Data Handling
  \item Classes and Dynamics
\end{itemize}

\vspace{1mm}
\slideimage[height=2.5cm]{../../images/img01/json_wiki.png}


% --- End Columns, Column and Frame ---------------------------------------------
\end{column}
\end{columns}
\end{frame}



%!TEX root = lec01.tex
% ================================================================================
% Slide 
% ================================================================================
\begin{frame}[t,fragile]

% --- Title ---------------------------------------------------------------------
\mytitle{Python Setup: First Check and Create Virtual Environment}

% --- Content -------------------------------------------------------------------
\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}{0.3\textwidth}
  \textbf{Goal of this step}

  \begin{itemize}
    \item Verify that Python is installed
    \item Work across Linux, macOS, Windows, WSL
    \item Create isolated environments: aipy
    \item \y{No dependency} 
    	\y{conflicts}
  \end{itemize}
\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}{0.68\textwidth}
  
\begin{codeonly}{Basic Installation}
python --version.   # check version
python3 --version.  # check version
python3.12 --version   
cd                  # go to home
python -m venv aipy # create venv
alias aipy="source ~/aipy/bin/activate"
aipy                # activate aipy
python              # interactive python
\end{codeonly}

\vspace{1mm}
{\footnotesize Linux/macOS example}
  
% --- End Columns, Column and Frame ---------------------------------------------
\end{column}
\end{columns}
\end{frame}
%!TEX root = lec01.tex
% ================================================================================
% Slide 02
% ================================================================================
\begin{frame}[t,fragile]

% --- Title ---------------------------------------------------------------------
\mytitle{Python Package Stack: How Things Build on Each Other}

% --- Content -------------------------------------------------------------------
\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.38\textwidth}

\textbf{Core idea}

\begin{itemize}
  \item Python is a \y{layered ecosystem}
  \item Packages build on top of each other
  \item Higher layers assume lower layers exist
  \item This structure matters for:
    \begin{itemize}
      \item installation
      \item debugging
      \item performance
    \end{itemize}
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.60\textwidth}

\begin{codeonly}{Conceptual Package Stack (ASCII)}
Python
 |
 +-- NumPy        (arrays, numerics)
 |
 +-- Matplotlib   (plots, figures)
 |
 +-- AI / ML
     |
     +-- PyTorch
     +-- scikit-learn
\end{codeonly}

\vspace{1mm}
{\footnotesize Conceptual view, not an exact dependency graph}

% --- End Columns ---------------------------------------------------------------
\end{column}
\end{columns}

\end{frame}
%!TEX root = lec01.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t,fragile]

% --- Title ---------------------------------------------------------------------
\mytitle{Installing Core Scientific Packages}

% --- Content -------------------------------------------------------------------
\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}{0.32\textwidth}

\textbf{What we need first}

\begin{itemize}
  \item \y{NumPy} for numerical arrays
  \item \y{Matplotlib} for visualization
  \item Foundation for most scientific libraries
  \item Same tools across weather, climate, AI
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}{0.66\textwidth}

\begin{codeonly}{Install basic packages}
# activate virtual environment 
aipy

# install core scientific packages
pip install numpy
pip install matplotlib

# verify installation
python -c "import numpy, matplotlib; print('OK')"
\end{codeonly}

\vspace{1mm}
{\footnotesize These packages will be reused throughout the course}

% --- End Columns ---------------------------------------------------------------
\end{column}
\end{columns}

\end{frame}
%!TEX root = lec01.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t,fragile]

% --- Title ---------------------------------------------------------------------
\mytitle{Installing Python Packages with \texttt{pip}}

% --- Content -------------------------------------------------------------------
\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}{0.35\textwidth}

\textbf{Why package management matters}

\begin{itemize}
  \item Python itself is \y{minimal}
  \item Most functionality comes from packages
  \item Packages define your \y{working environment}
  \item Reproducibility depends on exact versions
\end{itemize}

\vspace{1mm}
\textbf{Key idea:}
\begin{itemize}
  \item One project $\Rightarrow$ one environment
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}{0.63\textwidth}

\begin{codeonly}{Basic pip workflow}
# activate aipy, list installed 
aipy
pip list

# install core packages
pip install numpy
pip install matplotlib

# verify installation
python -c "import numpy, matplotlib; print('ok')"
\end{codeonly}

\vspace{1mm}
{\footnotesize Always install packages \y{inside} an activated virtual environment}

\end{column}

% --- End Frame -----------------------------------------------------------------
\end{columns}
\end{frame}
%!TEX root = lec01.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t,fragile]

% --- Title ---------------------------------------------------------------------
\mytitle{NumPy Arrays: 1D, 2D, and 3D Data - \y{Standard Programming Skills}}

% --- Content -------------------------------------------------------------------
\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}{0.34\textwidth}

\textbf{Core idea}

\begin{itemize}
  \item One data structure for science
  \item Same logic for 1D, 2D, 3D data
  \item Used for time series, maps, fields
  \item Basis for ML tensors
  \item \y{Learn the basics}
  \y{yourself, its easy.}
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}{0.64\textwidth}

\begin{codeonly}{NumPy array dimensions}
import numpy as np

x = np.array([1, 2, 4])          # 1D
A = np.array([[1, 2], [3, 4]])   # 2D
B = np.zeros((10, 50, 100))      # 3D

print(x.shape, A.shape, B.shape)
# prints (3,) (2, 2) (10, 50, 100)

print(x)
# prints [1 2 4]
\end{codeonly}

\vspace{1mm}
{\footnotesize Dimensions encode structure, not meaning}

% --- End Columns ---------------------------------------------------------------
\end{column}
\end{columns}

\end{frame}
%!TEX root = lec01.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Vectors, Matrices, and Broadcasting}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}{0.34\textwidth}

\textbf{Core concepts}

\begin{itemize}
  \item Vectors (1D)
  \item Matrices (2D)
  \item Matrix--vector product
  \item Matrix--matrix product
  \item Broadcasting
\end{itemize}

\vspace{5mm}
\y{Carry out MATLAB like}
\y{Linear Algebra}

\vspace{5mm}
\y{\color{red}\bf Loops only Top Level!}
\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}{0.64\textwidth}

\begin{codeonly}{Linear algebra in NumPy}
import numpy as np

x = np.array([1., 2.])
A = np.array([[1., 2.], [3., 4.]])

b = A @ x        # matrix-vector
B = A @ A        # matrix-matrix
C = A + 1.0      # broadcasting

print(f"b={b},\nB={B},\nC={C}")
\end{codeonly}

{\footnotesize Operations follow array shapes}

\end{column}
\end{columns}

\end{frame}
%!TEX root = lec01.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Indexing, Slicing, and Masks - \y{Think Efficiency!}}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}{0.34\textwidth}

\textbf{Why this matters}

\begin{itemize}
  \item Access elements efficiently
  \item Select subdomains in space or time
  \item Apply conditions to data
  \item Basis of filtering and diagnostics
\end{itemize}

\vspace{5mm}
\y{Make sure you use an}
\y{{\red\bf efficient coding} approach!}
\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}{0.64\textwidth}

\begin{codeonly}{Selecting array data}
import numpy as np

A = np.array([[1., 2.], [3., 4.]])

B = A[0, 1]          # single element
C = A[:, 0]          # first column
D = A>2              # boolean mask
E = A[A > 2]         # select elements

print("A=", A, "\nB=", B, "\nC=", C, "\nD=", D, "\nE=", E)
\end{codeonly}

{\footnotesize Masks are vectorized and fast}

\end{column}
\end{columns}

\end{frame}
%!TEX root = lec01.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t,fragile]

% --- Title ---------------------------------------------------------------------
\mytitle{Visualization Engines: A Sine Wave Example}

% --- Content -------------------------------------------------------------------
\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}{0.32\textwidth}

\textbf{What happens here}

\begin{itemize}
  \item Generate numerical data with \y{NumPy}
  \item Compute a math function
  \item \y{Visualize} data using Matplotlib
  \item \y{Save} plots for later use
\end{itemize}

\vspace{-3mm}
\hfill\includegraphics[width=3cm]{../../images/img01/plot-sine-wave.png}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}{0.66\textwidth}

\vspace{-3mm}
\begin{codeonly}{plot-sine-wave.py}
import numpy as np
import matplotlib.pyplot as plt

x = np.linspace(0, 10, 100)
y = np.sin(x)

plt.figure(figsize=(4,3))
plt.plot(x, y)
plt.xlabel("x"); plt.ylabel("sin(x)")
plt.title('Sine Wave'); plt.tight_layout()                                                                  
plt.savefig("plot-sine-wave.png")
plt.close()
\end{codeonly}

\vspace{1mm}
{\footnotesize A minimal but complete scientific plotting workflow}

% --- End Columns ---------------------------------------------------------------
\end{column}
\end{columns}

\end{frame}
%!TEX root = lec01.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Visualizing 2D Data with Matplotlib}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}{0.32\textwidth}

\textbf{Key idea}

\begin{itemize}
  \item 2D arrays represent spatial fields
  \item Colors encode values
  \item Typical for weather and climate data
\end{itemize}

\vspace{1mm}
\hfill\includegraphics[width=4cm]{../../images/img01/plot-2d-field.png}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}{0.66\textwidth}

\vspace{-3mm}
\begin{codeonly}{Simple 2D field}
import numpy as np
import matplotlib.pyplot as plt

x = np.linspace(0, 4, 120)
y = np.linspace(0, 3, 90)
X, Y = np.meshgrid(x, y)
Z = np.sin(X) * np.cos(Y)

plt.imshow(Z, origin="lower",
     extent=[0,4,0,3], cmap="viridis")
plt.colorbar(); plt.title("2d Field"); 
plt.savefig("plot-2d-field.png"); 
plt.close()
\end{codeonly}

\end{column}
\end{columns}
\end{frame}
%!TEX root = lec01.tex
% ================================================================================
% Slide 10
% ================================================================================
\begin{frame}[t,fragile]

% --- Title ---------------------------------------------------------------------
\mytitle{3D Data: Fields and Surfaces}

% --- Content -------------------------------------------------------------------
\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}{0.32\textwidth}

\textbf{Why 3D matters}

\begin{itemize}
  \item Many geophysical fields are \y{spatial}
  \item Height, depth, or phase space
  \item Visualization helps intuition
\end{itemize}

\vspace{-12mm}
\hspace*{-8mm}\includegraphics[width=6cm]{../../images/img01/plot-3d.png}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}{0.66\textwidth}

\vspace{-3mm}
\begin{codeonly}{plot-3d.py}
import numpy as np
import matplotlib.pyplot as plt

x = np.linspace(0, 4, 80)
y = np.linspace(0, 3, 60)
X, Y = np.meshgrid(x, y)
Z = np.sin(X) * np.cos(Y)

fig = plt.figure(figsize=(4,3))
ax = fig.add_subplot(projection="3d")
ax.plot_surface(X, Y, Z, cmap="viridis")
plt.savefig("plot-3d.png"); plt.close()
\end{codeonly}

\vspace{1mm}
{\footnotesize Example of a smooth 3D field defined on a 2D grid}

% --- End Columns ---------------------------------------------------------------
\end{column}
\end{columns}

\end{frame}
%!TEX root = lec01.tex
% ================================================================================
% Slide 11
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Functions: Turn {\red Ideas} into Reusable Tools}

\begin{columns}[T,totalwidth=\textwidth]

\begin{column}{0.32\textwidth}

\textbf{Why functions matter}

\begin{itemize}
  \item Turn a workflow step into a \y{reusable tool}
  \item Make intent explicit: inputs $\rightarrow$ output
  \item Easier testing, debugging, and collaboration
  \item Foundation for \y{pipelines} and \y{ML training loops}
\end{itemize}

\end{column}

\begin{column}{0.66\textwidth}

\begin{codeonly}{Mini tool: normalize a signal}
import numpy as np

def normalize(x):
    x = np.asarray(x)
    return (x - x.mean()) / x.std()

x = np.array([2., 3., 5., 9.])
print("x =", x)
print("z =", normalize(x))
\end{codeonly}

{\footnotesize A pattern you will reuse everywhere: prepare data in one function}

\end{column}
\end{columns}
\end{frame}
%!TEX root = lec01.tex
% ================================================================================
% Slide 12
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Control Flow: Quality Checks and Simple Automation}

\begin{columns}[T,totalwidth=\textwidth]

\begin{column}{0.28\textwidth}

\textbf{Control flow in practice}

\begin{itemize}
  \item Decision making: \y{reject bad inputs} early
  \item Works on full arrays, makes it \y{fast}
  \item Clearly essential for \y{robust scripts} and experiments
\end{itemize}

\end{column}

\begin{column}{0.7\textwidth}

\vspace{-3mm}
\begin{codeonly}{Filter missing values}
import numpy as np
x = np.array([1.2, 2.0, 1e30, 4.9])
thr = 1e20
# removing values outside of range: 
x2 = x[x < thr]; dn = len(x)-len(x2)

fmt = "{:10.3g}"   # width=10, 3 digits
print("".join(fmt.format(v) for v in x))
print("".join(fmt.format(v) for v in x2))
print("mean=", f"{x2.mean():.3f}")
\end{codeonly}

{\footnotesize Quality control on observations or model fields}

\end{column}
\end{columns}
\end{frame}
%!TEX root = lec01.tex
% ================================================================================
% Slide 13
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Dictionaries and JSON: Configs You Can Share}

\begin{columns}[T,totalwidth=\textwidth]

\begin{column}{0.32\textwidth}

\textbf{Why this is exciting}

\begin{itemize}
  \item Store model and experiment settings cleanly
  \item Pass configs through \y{APIs} and workflows
  \item {\red\bf Reproducibility}: one file describes the run
\end{itemize}

\end{column}

\begin{column}{0.66\textwidth}

\begin{codeonly}{Config for an experiment}
import json

cfg = {"dt": 0.5, "n": 20, "model": "toy"}
s = json.dumps(cfg, indent=2)
print(s)

cfg2 = json.loads(s)
print("dt =", cfg2["dt"])
\end{codeonly}

{\footnotesize This is the bridge to automation + deployment later}

\end{column}
\end{columns}
\end{frame}
%!TEX root = lec01.tex
% ================================================================================
% Slide 15
% ================================================================================
\begin{frame}[t,fragile]

% --- Title ---------------------------------------------------------------------
\mytitle{Loops in Python: Time Stepping and Accumulation}

% --- Content -------------------------------------------------------------------
\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}{0.4\textwidth}

\textbf{Typical use case}

\begin{itemize}
  \item Discrete \y{time stepping}
  \item Running sums and averages
  \item Diagnostics over trajectories
  \item Core pattern in models
\end{itemize}

\vspace{1mm}
\textbf{Mental model}

\begin{itemize}
  \item Each loop = one time step
  \item State evolves sequentially
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}{0.58\textwidth}

\vspace{-3mm}
\begin{codeonly}{time\_loop.py}
import numpy as np

dt = 0.1; x = 0.0; traj = [] # initialization

for n in range(20):
    x = x + dt * np.sin(x)
    traj.append(x)

traj = np.array(traj)
print("final x =", x)
print("mean x  =", traj.mean())
\end{codeonly}

\vspace{1mm}
{\footnotesize Sequential updates cannot be vectorized away}

% --- End Columns ---------------------------------------------------------------
\end{column}
\end{columns}

\end{frame}
%!TEX root = lec01.tex
% ================================================================================
% Slide 14
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Files: Log Results, \y{help yourself, Scientist!}}

\begin{columns}[T,totalwidth=\textwidth]

\begin{column}{0.32\textwidth}

\textbf{File I/O patterns}

\begin{itemize}
  \item Save key results after every run
  \item Keep a simple \y{experiment log}
  \item The \texttt{with} pattern avoids subtle bugs
\end{itemize}

\end{column}

\begin{column}{0.66\textwidth}

\vspace{0mm}
\begin{codeonly}{Write a tiny log file}
from datetime import datetime

myerr = 0.23 # example 
msg = f"{datetime.now()}  rmse={myerr}\n"
with open("log-run.log", "a") as f:
    f.write(msg) # a is for append

with open("log-run.log") as f:
    last_line = f.readlines()[-1]
    print(last_line.strip())
\end{codeonly}

{\footnotesize Minimal logging already gives you \y{insight} and \y{transparency}}

\end{column}
\end{columns}
\end{frame}
%!TEX root = lec01.tex
% ================================================================================
% Slide 15
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Classes I: Encapsulate State (A Tiny Model Component)}

\begin{columns}[T,totalwidth=\textwidth]

\begin{column}{0.32\textwidth}

\textbf{Why classes appear everywhere}

\begin{itemize}
  \item Components have a \y{state} (e.g., temperature)
  \item Methods update that state consistently
  \item Same structure in NWP, ESMs, and ML modules
\end{itemize}

\end{column}

\begin{column}{0.66\textwidth}

\begin{codeonly}{A relaxating temperature}
class RelaxTemp:
    def __init__(self, T):
        self.T = T
    def step(self, dt, target):
        self.T += 0.1*dt*(target - self.T)

atm = RelaxTemp(288.0)
atm.step(1.0, 290.0)
print("T =", atm.T)
\end{codeonly}

{\footnotesize A tiny but real modeling pattern: relaxation toward forcing}

\end{column}
\end{columns}
\end{frame}
%!TEX root = lec01.tex
% ================================================================================
% Slide 16
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Classes II: Coupling Two Components (Mini Earth-System Pattern)}

\begin{columns}[T,totalwidth=\textwidth]

\begin{column}{0.32\textwidth}

\textbf{The exciting part}

\begin{itemize}
  \item Two components, each with its own state
  \item A controller coordinates \y{information exchange}
  \item This is the conceptual core of coupled models
\end{itemize}

\end{column}

\begin{column}{0.66\textwidth}

\vspace{-3mm}
\begin{codeonly}{Coupling in 10 lines}
class Box: 
    def __init__(s,x): s.x=x
    def step(s,dt,t): s.x+=0.2*dt*(t-s.x)

atm, ocn = Box(288.), Box(290.)
ocn.step(1., atm.x); atm.step(1., ocn.x)
print("atm=", atm.x, "ocn=", ocn.x)
\end{codeonly}

{\footnotesize Same coupling idea, later: many variables + grids + physics}

\end{column}
\end{columns}
\end{frame}
%!TEX root = lec01.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t,fragile]

% --- Title ---------------------------------------------------------------------
\mytitle{Lecture 1 — Key Takeaways}

% --- Content -------------------------------------------------------------------
\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}{0.48\textwidth}

\textbf{Technical Foundations}

\begin{itemize}
  \item Python as a portable \y{workhorse} for science
  \item \y{Virtual environments} avoid dependency conflicts
  \item \texttt{pip} and \texttt{requirements.txt} ensure reproducibility
  \item NumPy arrays as the \y{core data structure}
  \item Vectorization replaces explicit loops
  \item Matplotlib for \y{fast diagnostic visualization}
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}{0.48\textwidth}

\textbf{Conceptual Lessons}

\begin{itemize}
  \item Think in terms of \y{arrays, not scalars}
  \item Data selection via slicing and masking
  \item Broadcasting enables compact math expressions
  \item Visualization supports scientific intuition
  \item Clean code beats clever code
  \item Python skills will transfer directly to \y{AI/ML development}
\end{itemize}

\end{column}

% --- End Columns ---------------------------------------------------------------
\end{columns}

\end{frame}
%!TEX root = lec1.tex
% ================================================================================
% Lecture 1, Slide 20
% ================================================================================
\begin{frame}[t,fragile]
  \mytitle{Lecture 1 — Slide 20}

  % Content goes here

\end{frame}
%!TEX root = lec1.tex
% ================================================================================
% Lecture 1, Slide 21
% ================================================================================
\begin{frame}[t,fragile]
  \mytitle{Lecture 1 — Slide 21}

  % Content goes here

\end{frame}
%!TEX root = lec1.tex
% ================================================================================
% Lecture 1, Slide 22
% ================================================================================
\begin{frame}[t,fragile]
  \mytitle{Lecture 1 — Slide 22}

  % Content goes here

\end{frame}
%!TEX root = lec1.tex
% ================================================================================
% Lecture 1, Slide 23
% ================================================================================
\begin{frame}[t,fragile]
  \mytitle{Lecture 1 — Slide 23}

  % Content goes here

\end{frame}
%!TEX root = lec1.tex
% ================================================================================
% Lecture 1, Slide 24
% ================================================================================
\begin{frame}[t,fragile]
  \mytitle{Lecture 1 — Slide 24}

  % Content goes here

\end{frame}
%!TEX root = lec1.tex
% ================================================================================
% Lecture 1, Slide 25
% ================================================================================
\begin{frame}[t,fragile]
  \mytitle{Lecture 1 — Slide 25}

  % Content goes here

\end{frame}
% ================================================================================
% E-AI Tutorial Slides
% Filename: lec01.tex
% 
% Roland Potthast 2025/2026
% Licence: CC-BY4.0
% ================================================================================
\documentclass[aspectratio=169]{beamer}

% --- Load lecture macros --------------------------------------------------------
\input{../lec_macros.tex}
\newcommand{\LectureNumber}{Lecture 1}

% --- Document -------------------------------------------------------------------
\begin{document}

\setagendaboxforlecture{1}

\input{../lec_agenda.tex}
\input{lec01_01.tex}
\input{lec01_02.tex}
\input{lec01_03.tex}
\input{lec01_04.tex}
\input{lec01_05.tex}
\input{lec01_06.tex}
\input{lec01_07.tex}
\input{lec01_08.tex}
\input{lec01_09.tex}
\input{lec01_10.tex}
\input{lec01_11.tex}
\input{lec01_12.tex}
\input{lec01_13.tex}
\input{lec01_14.tex}
\input{lec01_15.tex}
\input{lec01_16.tex}
\input{lec01_17.tex}
\input{lec01_18.tex}
\input{lec01_19.tex}

% --- End Document ---------------------------------------------------------------
\end{document}
%!TEX root = lec02.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t]

% --- Content -------------------------------------------------------------------
\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.2\textwidth}

\raggedright
\setlength{\leftskip}{0mm}
\setlength{\parindent}{0pt}
\textbf{Jupyter Notebook}

\vspace*{5mm}
\begin{itemize}

  \item Cells with \y{comments}
  \item Cells with \y{code}
  \item Cells with \y{output}
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.78\textwidth}

\includegraphics[width=0.99\textwidth]{../../images/img02/jupyter02.png}

% --- End Columns, Column and Frame ---------------------------------------------
\end{column}
\end{columns}
\end{frame}
%!TEX root = lec02.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t,fragile]

% --- Title ---------------------------------------------------------------------
\mytitle{Lecture 2: Jupyter Notebooks, APIs and Servers}

% --- Content -------------------------------------------------------------------
\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Goal of this Lecture}

\begin{itemize}
  \item Work \y{productively} with Jupyter Notebooks
  \item Understand Notebooks as part of a \y{scientific workflow}
  \item Prepare the ground for \y{reproducible} ML experiments
\end{itemize}

\vspace{1mm}
\textbf{Focus}

\begin{itemize}
  \item Not UI details, but \y{how things fit together}
  \item From exploration to engineering
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Topics Overview}

\begin{itemize}
  \item Jupyter Notebooks: Kernel, Server, Browser
  \item Environments and package management
  \item Markdown, magic commands, shell integration
  \item Data visualization as quality control
  \item \y{APIs} as a structuring principle
  \item Local, library and web APIs
  \item Native code integration (Fortran / C++)
\end{itemize}

% --- End Columns, Column and Frame ---------------------------------------------
\end{column}
\end{columns}
\end{frame}
%!TEX root = lec02.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t,fragile]

% --- Title ---------------------------------------------------------------------
\mytitle{Why Jupyter Notebooks in Science and ML?}

% --- Content -------------------------------------------------------------------
\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Why Notebooks Matter}

\begin{itemize}
  \item Rapid \y{exploration} of data and ideas
  \item Immediate feedback via plots and diagnostics
  \item Combine code, results and explanation
\end{itemize}

\vspace{1mm}
\textbf{In Research Contexts}

\begin{itemize}
  \item Hypothesis testing and prototyping
  \item Understanding data and model behavior
  \item Bridging theory and implementation
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Why They Scale Beyond Prototyping}

\begin{itemize}
  \item Documentation of decisions and assumptions
  \item Reproducible experiments (when done right)
  \item Natural interface to libraries and APIs
  \item Gateway to larger workflows and services
\end{itemize}

\textbf{Key Message}

\begin{itemize}
  \item Notebooks are \y{tools}, not products
  \item Value comes from disciplined usage
\end{itemize}

% --- End Columns, Column and Frame ---------------------------------------------
\end{column}
\end{columns}
\end{frame}
%!TEX root = lec02.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t,fragile]

% --- Title ---------------------------------------------------------------------
\mytitle{Jupyter Architecture: Browser – Server – Kernel}

% --- Content -------------------------------------------------------------------
\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Three Core Components}

\begin{itemize}
  \item \textbf{Browser}  
        User interface: notebooks, plots, interaction
  \item \textbf{Jupyter Server}  
        Manages files, sessions, security
  \item \textbf{Kernel}  
        Executes Python code, holds state
\end{itemize}

\vspace{1mm}
\textbf{Key Idea}

\begin{itemize}
  \item UI and computation are \y{decoupled}
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Why This Matters}

\begin{itemize}  \item Code runs in the \y{kernel}, not in the browser
  \item Kernel state persists across cells
  \item Server and kernel may run \y{remotely}
  \item Multiple notebooks can share one kernel
\end{itemize}

\vspace{1mm}
\textbf{Strength and Risk}

\begin{itemize}
  \item Powerful interactive workflow
  \item Risk of hidden state and irreproducibility
\end{itemize}

% --- End Columns, Column and Frame ---------------------------------------------
\end{column}
\end{columns}
\end{frame}
%!TEX root = lec02.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t,fragile]

% --- Title ---------------------------------------------------------------------
\mytitle{Reproducibility in Jupyter Notebooks}

% --- Content -------------------------------------------------------------------
\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Why Reproducibility Matters}

\begin{itemize}
  \item Results must be repeatable
  \item Experiments must be explainable
  \item Others (and you later) must trust them
\end{itemize}

\vspace{1mm}
\textbf{Typical Problems}

\begin{itemize}
  \item Hidden kernel state
  \item Cells executed out of order
  \item Undocumented dependencies
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Four Simple Rules}

\begin{itemize}
  \item Restart kernel and \y{Run All}
  \item Clear, explicit import and parameter cells
  \item Save outputs (plots, files, artefacts)
  \item Document dependencies and environment
\end{itemize}

\vspace{1mm}
\textbf{Key Message}

\begin{itemize}
  \item A notebook is an \y{executable document}
\end{itemize}

% --- End Columns, Column and Frame ---------------------------------------------
\end{column}
\end{columns}
\end{frame}
%!TEX root = lec02.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t,fragile]

% --- Title ---------------------------------------------------------------------
\mytitle{Installing Packages in Jupyter Notebooks}

% --- Content -------------------------------------------------------------------
\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Recommended Workflow}

\begin{itemize}
  \item Install packages either outside in the right virtual environment or 
  \y{directly in the notebook}
  \item Use \texttt{pip install} or \texttt{!pip install}
  \item Packages are installed into the \y{running kernel}
\end{itemize}

\vspace{1mm}
\textbf{Why This Works}

\begin{itemize}
  \item Jupyter uses the kernel's Python environment
  \item \texttt{pip} is typically bound to this Python
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Good Practice: Check Once}

\vspace{3mm}
\begin{codeonly}{Check active environment}
import sys
print(f"Python executable: {sys.executable}")
\end{codeonly}

\vspace{1mm}
\textbf{Key Message}

\begin{itemize}
  \item Use \texttt{pip} where you run your code
  \item Verify the environment if something looks wrong
\end{itemize}

% --- End Columns, Column and Frame ---------------------------------------------
\end{column}
\end{columns}
\end{frame}
%!TEX root = lec02.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t,fragile]

% --- Title ---------------------------------------------------------------------
\mytitle{Markdown and Narrative Computing}

% --- Content -------------------------------------------------------------------
\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Why Markdown Matters}

\begin{itemize}
  \item Makes notebooks \y{readable}
  \item \y{Explains} intent, not just results
  \item Turns experiments into documents
\end{itemize}

\vspace{1mm}
\textbf{Narrative Computing}

\begin{itemize}
  \item Code, text and results in one place
  \item \y{Reasoning} becomes explicit
  \item Supports review and reuse
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Minimum You Should Use}

\begin{itemize}
  \item Headings \,(\texttt{\#}, \texttt{\#\#})
  \item Bullet lists \,(\texttt{-})
  \item Inline formulas \,(\texttt{\$x\^{}2\$})
  \item Short explanations 
\end{itemize}

\vspace{1mm}
\textbf{Markdown Cells}

\begin{itemize}
  \item Change cell type: \texttt{Esc} \,$\rightarrow$\, \texttt{M}
\end{itemize}

\vspace{1mm}
\textbf{Key Message}

\begin{itemize}
  \item A notebook should read like a \y{lab notebook}
\end{itemize}

% --- End Columns, Column and Frame ---------------------------------------------
\end{column}
\end{columns}
\end{frame}
%!TEX root = lec02.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t,fragile]

% --- Title ---------------------------------------------------------------------
\mytitle{Magic Commands and Shell Access}

% --- Content -------------------------------------------------------------------
\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Why Magic Commands}

\begin{itemize}
  \item Speed up interactive work
  \item Reduce boilerplate code
  \item Support exploration and debugging
\end{itemize}

\vspace{1mm}
\textbf{Line vs Cell Magics}

\begin{itemize}
  \item \texttt{\%} for single-line commands
  \item \texttt{\%\%} for whole cells
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{The Few You Really Need}

\begin{itemize}
  \item \texttt{\%timeit} \,(runtime)
  \item \texttt{\%\%writefile} \,(save code)
  \item \texttt{\%\%bash} \,(run shell)
  \item \texttt{!pip} \,(install packages)
  \item \texttt{!ls} \,(files)
\end{itemize}

\vspace{1mm}
\textbf{Key Message}

\begin{itemize}
  \item Use magic and shell commands \y{sparingly}
\end{itemize}

% --- End Columns, Column and Frame ---------------------------------------------
\end{column}
\end{columns}
\end{frame}
%!TEX root = lec02.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t,fragile]

% --- Title ---------------------------------------------------------------------
\mytitle{Visualization as Quality Control}

% --- Content -------------------------------------------------------------------
\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Why Visualization Matters}

\begin{itemize}
  \item See patterns and \y{anomalies}
  \item {\color{red} Detect bugs early}
  \item Build \y{intuition} about data and models
\end{itemize}

\vspace{1mm}
\textbf{Typical Questions}

\begin{itemize}
  \item Does this look reasonable?
  \item Are scales and units correct?
  \item Are outliers expected?
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}


% --- Image --------------------------------------------------------------------
\vspace{-2.5cm}

\hspace*{-2cm}
\includegraphics[height=6cm]{../../images/img02/lorenz63.png}

\vspace{-6mm}
\textbf{Static vs Interactive}

\begin{itemize}
  \item Static: documentation, papers
  \item Interactive: exploration, debugging
\end{itemize}

\vspace{1mm}
\textbf{Key Message}

\begin{itemize}
  \item \y{Plot early, plot often!}
\end{itemize}

% --- End Columns, Column and Frame ---------------------------------------------
\end{column}
\end{columns}
\end{frame}
%!TEX root = lec02.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t]

% --- Content -------------------------------------------------------------------
\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.2\textwidth}

\raggedright
\setlength{\leftskip}{0mm}
\setlength{\parindent}{0pt}
\textbf{Interactive Plot via Plotly}

\vspace*{5mm}
\begin{itemize}

  \item Explore your data
  \item Learn, check!
  \item 
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.78\textwidth}

\includegraphics[width=0.99\textwidth]{../../images/img02/plotly01.png}

% --- End Columns, Column and Frame ---------------------------------------------
\end{column}
\end{columns}
\end{frame}
%!TEX root = lec02.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t,fragile]

% --- Title ---------------------------------------------------------------------
%\mytitle{Visualization Packages: Matplotlib vs Seaborn vs Plotly}

% --- Content -------------------------------------------------------------------
\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Matplotlib}

\begin{itemize}
  \item Low-level, explicit control
  \item Publication-ready figures
  \item Default for scientific Python
\end{itemize}

\vspace{1mm}
\begin{codeonly}{Matplotlib (static)}
plt.plot(x, y)
plt.xlabel("x"); 
plt.ylabel("y")
plt.savefig("plot.png")
\end{codeonly}

\vspace{1mm}
\textbf{When to use}

\begin{itemize}
  \item Final figures
  \item Full control over layout
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-4mm}
\textbf{Seaborn}

\begin{itemize}
  \item Built on Matplotlib
  \item Statistical defaults
  \item Fast insight into distributions
\end{itemize}

\begin{codeonly}{Seaborn (statistical)}
sns.kdeplot(x=data)
\end{codeonly}

\vspace{1mm}
\textbf{Plotly}

\begin{itemize}
  \item Interactive plots
  \item Zoom, hover, selection
\end{itemize}

\begin{codeonly}{Plotly (interactive)}
fig = px.scatter(df, x="x", 
	y="y"); fig.show()
\end{codeonly}

% --- End Columns, Column and Frame ---------------------------------------------
\end{column}
\end{columns}
\end{frame}
%!TEX root = lec02.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t,fragile]

% --- Title ---------------------------------------------------------------------
\mytitle{What Is an API — and What Is Not}

% --- Content -------------------------------------------------------------------
\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{What an API Is}

\begin{itemize}
  \item A \y{defined interface} to call functionality
  \item Clear inputs, outputs and behavior
  \item Stable contract between components
\end{itemize}

\vspace{1mm}
\textbf{Typical API Examples}

\begin{itemize}
  \item Python functions and classes
  \item Library interfaces (e.g.\ NumPy)
  \item Web endpoints (HTTP/REST)
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-3mm}
\textbf{What an API Is \emph{Not}}

\begin{itemize}
  \item Just installable code
  \item A script without defined entry points
  \item A collection of loosely coupled functions
\end{itemize}

\vspace{1mm}
\textbf{Important Distinction}

\begin{itemize}
  \item Installation is \y{distribution}
  \item An API is \y{how you call the code}
\end{itemize}

\vspace{1mm}
\textbf{Key Message}

\begin{itemize}
  \item Packages may \y{expose} APIs
  \item Installation alone does not define one
\end{itemize}

% --- End Columns, Column and Frame ---------------------------------------------
\end{column}
\end{columns}
\end{frame}
%!TEX root = lec02.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t,fragile]

% --- Title ---------------------------------------------------------------------
\mytitle{APIs as a Scaling Principle}

% --- Content -------------------------------------------------------------------
\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Core Idea}

\begin{itemize}
  \item APIs defines a contract on \y{how} functionality is accessed
  \item Clear \y{separation} of interface and implementation
  \item Same principle from notebooks to services
\end{itemize}

\vspace{1mm}
\textbf{Why This Matters}

\begin{itemize}
  \item Logic becomes reusable and testable
  \item Notebooks stay thin and readable
  \item Systems can grow without rewrites
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-1cm}
\textbf{Example 1: Local API (project code)}

\begin{codeonly}{Function API usage}
from model import forecast
y = forecast(x, params)
\end{codeonly}

\vspace{1mm}
\textbf{Example 2: Web API (service)}

\begin{codeonly}{HTTP request}
response = requests.get(
  "/weather",
  params={"city": "Berlin", "date": "2025-01-20"})
data = response.json()
\end{codeonly}

\vspace{1mm}
\textbf{Key Insight}

\begin{itemize}
  \item APIs shift complexity behind a \y{stable boundary}
\end{itemize}

% --- End Columns, Column and Frame ---------------------------------------------
\end{column}
\end{columns}
\end{frame}
%!TEX root = lec02.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{REST Essentials — \y{Tasks} as Resources / \y{Agent Framework Elements}}

\begin{columns}[T,totalwidth=\textwidth]

\begin{column}[T]{0.48\textwidth}

\textbf{Resources}

\begin{itemize}
  \item A task is a \y{resource}
  \item Identified by a URL
  \item Has a state and metadata
\end{itemize}

\vspace{1mm}
\begin{itemize}
  \item \texttt{/tasks}
  \item \texttt{/tasks/<id>}
\end{itemize}

\end{column}

\begin{column}[T]{0.48\textwidth}

\textbf{HTTP Methods}

\begin{itemize}
  \item \texttt{POST} — create a task
  \item \texttt{GET} — inspect task or list
  \item \texttt{PUT} — change task state
  \item \texttt{DELETE} — remove a task
\end{itemize}

\vspace{1mm}
\textbf{Status Codes (Minimum)}

\begin{itemize}
  \item \texttt{200} OK
  \item \texttt{201} Created
  \item \texttt{400} Bad Request
  \item \texttt{404} Not Found
\end{itemize}

\end{column}
\end{columns}
\end{frame}
%!TEX root = lec02.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Task Server Setup — Minimal Flask Example}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.3\textwidth}

\textbf{Goal}

\begin{itemize}
  \item Tasks as REST resources
  \item Explicit task state
  \item Minimal server logic
\end{itemize}

\vspace{1mm}
\textbf{States}

\begin{itemize}
  \item \texttt{created}
  \item \texttt{checked}
  \item \texttt{executing}
  \item \texttt{completed / failed}
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.68\textwidth}

\vspace{-3mm}
\begin{codeonly}{task\_server.py}
from flask import Flask, request, jsonify
app = Flask(__name__)
tasks = {}; i = 1

@app.post("/tasks")
def create():
    global i
    if not request.json: abort(400)
    t = {"id": i, "state": "created", "data": request.json}
    tasks[i] = t; i += 1
    return jsonify(t), 201
    
app.run()
\end{codeonly}

\end{column}

% --- End Columns --------------------------------------------------------------
\end{columns}
\end{frame}
%!TEX root = lec02.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Testing the Task REST API}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.38\textwidth}

\textbf{What We Test}

\begin{itemize}
  \item Send JSON to the server (\texttt{POST /tasks})
  \item Server creates a new task
  \item Server assigns \y{ID} and initial \y{state}
\end{itemize}

\vspace{1mm}
\textbf{Expected Result}

\begin{itemize}
  \item HTTP status \texttt{201 Created}
  \item JSON response with:
  \begin{itemize}
    \item task id
    \item state = \texttt{created}
    \item echoed input data
  \end{itemize}
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.6\textwidth}

\vspace{-1.1cm}
\begin{codeonly}{Test via \texttt{curl}}
curl -X POST http://127.0.0.1:5000/tasks  -H "Content-Type: application/json" -d '{"type":"demo","params":{"x":1}}' 
\end{codeonly}

\begin{codeonly}{Minimal Python Task Creation}
import requests
r = requests.post(
  "http://127.0.0.1:5000/tasks",
  json={"type":"demo","params":{"x":1}})
print(r.status_code); print(r.json())
\end{codeonly}

\vspace{-1mm}
\begin{lstlisting}
{'id': 1, 'state': 'created',
 'data': {'type': 'demo',
          'params': {'x': 1}}}
\end{lstlisting}

% --- End Columns ---------------------------------------------------------------
\end{column}
\end{columns}
\end{frame}
%!TEX root = lec02.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Flask Server Example — Task Endpoints}

\begin{columns}[T,totalwidth=\textwidth]

\begin{column}[T]{0.48\textwidth}

\textbf{Task Lifecycle}

\begin{itemize}
  \item \texttt{created}
  \item \texttt{checked}
  \item \texttt{executing}
  \item \texttt{completed / failed}
\end{itemize}

\vspace{1mm}
\textbf{Endpoints}

\begin{itemize}
  \item \texttt{POST /tasks}
  \item \texttt{GET /tasks/<id>}
  \item \texttt{PUT /tasks/<id>}
\end{itemize}

\end{column}

\begin{column}[T]{0.48\textwidth}

\textbf{Validation Pattern}

\begin{itemize}
  \item Check input JSON
  \item Check task existence
  \item Check valid state transitions
\end{itemize}

\begin{codeonly}{Flask validation}
if not request.json:
    abort(400)

if task is None:
    abort(404)
\end{codeonly}

\vspace{1mm}
\textbf{Key Point}

\begin{itemize}
  \item State changes happen on the server
\end{itemize}

\end{column}
\end{columns}
\end{frame}
%!TEX root = lec02.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Client Side — Using \texttt{requests}}

\begin{columns}[T,totalwidth=\textwidth]

\begin{column}[T]{0.48\textwidth}

\textbf{Sending Data}

\begin{codeonly}{Create task}
payload = {
  "type": "python_exec",
  "params": {"script": "run.py"}
}

r = requests.post(
  "/tasks",
  json=payload
)
\end{codeonly}

\end{column}

\begin{column}[T]{0.48\textwidth}

\textbf{Reading Responses}

\begin{codeonly}{Check response}
if r.status_code == 201:
    task = r.json()
else:
    print(r.status_code, r.text)
\end{codeonly}

\vspace{1mm}
\textbf{Debugging Rule}

\begin{itemize}
  \item \texttt{400} → client mistake
  \item \texttt{404} → wrong task id
\end{itemize}

\end{column}
\end{columns}
\end{frame}
%!TEX root = lec02.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Task API — Server Endpoints}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.42\textwidth}

\vspace{-1mm}
\textbf{Purpose}

\begin{itemize}
  \item Expose tasks via REST
  \item Read-only inspection
  \item Server owns all state
\end{itemize}

\vspace{1mm}
\textbf{\y{Server Resource Endpoints}}

\begin{itemize}
  \item \texttt{/tasks} — task collection
  \item \texttt{/tasks/<id>} — single task
\end{itemize}

\vspace{1mm}
\textbf{Semantics}

\begin{itemize}
  \item Stateless client
  \item Explicit URLs
  \item JSON responses
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.56\textwidth}

\vspace{-1.1cm}
\begin{codeonly}{task\_endpoints.py}
from flask import Flask, jsonify, abort
app = Flask(__name__)
tasks = {}

@app.get("/tasks")
def list_tasks():
    return jsonify(list(tasks.values()))

@app.get("/tasks/<int:i>")
def get_task(i):
    return jsonify(tasks[i]) if i in tasks else abort(404)

app.run()
\end{codeonly}

\end{column}

% --- End Columns --------------------------------------------------------------
\end{columns}
\end{frame}
%!TEX root = lec02.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Querying Tasks — Inspecting Server State}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.42\textwidth}

\vspace{-1mm}
\textbf{Goal}

\begin{itemize}
  \item Inspect existing tasks
  \item Read \y{state} and \y{metadata}
  \item No client-side state
\end{itemize}

\vspace{1mm}
\textbf{REST Principle}

\begin{itemize}
  \item Tasks are \y{resources}
  \item Identified by URL
  \item Read via \texttt{GET}
\end{itemize}

\vspace{1mm}
\textbf{Endpoints}

\begin{itemize}
  \item \texttt{GET /tasks}
  \item \texttt{GET /tasks/<id>}
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.56\textwidth}

\vspace{-2mm}
\begin{codeonly}{List all Tasks}
import requests
r = requests.get("http://127.0.0.1:5000/tasks")
print(r.status_code)
print(r.json())
\end{codeonly}

\vspace{1mm}
\begin{codeonly}{Describe one task}
import sys, requests
tid = int(sys.argv[1])
r = requests.get(f"http://127.0.0.1:5000/tasks/{tid}")
print(r.status_code)
print(r.json())
\end{codeonly}

\end{column}

% --- End Columns --------------------------------------------------------------
\end{columns}
\end{frame}
%!TEX root = lec02.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Native Code Integration: Fortran and C++ in Python \& ML}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\textbf{Why Native Code Matters}

\begin{itemize}
  \item Decades of validated \y{Fortran} in NWP
  \item High-performance kernels in \y{C++}
  \item Tight control over memory and execution
  \item Reuse of trusted implementations
\end{itemize}

\vspace{1mm}
\textbf{Typical Use Cases}

\begin{itemize}
  \item Physical parameterizations
  \item Linear operators, solvers, kernels
  \item Observation operators
  \item Legacy model components
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Python as the Orchestration Layer}

\begin{itemize}
  \item Python controls the \y{workflow}
  \item Native code provides \y{compute kernels}
  \item Clean separation via \y{APIs}
\end{itemize}

\vspace{1mm}
\textbf{Integration Options (Overview)}

\begin{itemize}
  \item \texttt{ctypes} – explicit C-compatible interfaces
  \item \texttt{f2py} – automatic Fortran bindings
  \item \texttt{pybind11} – modern C++ bindings
  \item Shared libraries: \texttt{.so} / \texttt{.dylib}
\end{itemize}

\end{column}

% --- End Columns --------------------------------------------------------------
\end{columns}
\end{frame}
%!TEX root = lec02.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Fortran with C Bindings: A Stable Interface}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.37\textwidth}

\vspace{-2mm}
\textbf{Why C Bindings?}

\begin{itemize}
  \item Fortran and Python do \y{not} talk directly
  \item The common denominator is the \y{C ABI}
  \item Stable, explicit, language-independent
\end{itemize}

\vspace{1mm}
\textbf{Key Concept}

\begin{itemize}
  \item Fortran exposes functions as \y{C-compatible symbols}
  \item No name mangling
  \item Well-defined data types
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.62\textwidth}

\vspace{-3mm}
\begin{codeonly}{Minimal Fortran Example}
function f_sin_cos(x) result(f) bind(C)
  use iso_c_binding
  real(c_double), intent(in) :: x
  real(c_double) :: f
  f = sin(x) * cos(x)
end function
\end{codeonly}

\vspace{1mm}
\textbf{What This Ensures}

\begin{itemize}
  \item Symbol name is predictable
  \item Argument layout follows C rules
  \item Callable from Python, C, C++
\end{itemize}

\end{column}

% --- End Columns --------------------------------------------------------------
\end{columns}
\end{frame}
%!TEX root = lec02.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Calling Fortran from Python with \texttt{ctypes}}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.32\textwidth}

\vspace{-1mm}
\textbf{Role of Python}

\begin{itemize}
  \item Python loads the shared library
  \item Defines the \y{function signature}
  \item Manages data exchange
\end{itemize}

\vspace{1mm}
\textbf{Important Detail}

\begin{itemize}
  \item Fortran arguments are passed \y{by reference}
  \item Python must pass pointers
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.68\textwidth}

\vspace{-3mm}
\begin{codeonly}{Minimal Python Interface}
import ctypes

lib = ctypes.CDLL("./fortran_interface.so")
lib.f_sin_cos.argtypes = [
    ctypes.POINTER(ctypes.c_double) ]
lib.f_sin_cos.restype = ctypes.c_double

x = ctypes.c_double(1.0)
y = lib.f_sin_cos(ctypes.byref(x))
\end{codeonly}

\vspace{-1mm}
\begin{itemize}
  \item Native Fortran computation
  \item Controlled Python interface
  \item No performance-critical Python loop
\end{itemize}

\end{column}

% --- End Columns --------------------------------------------------------------
\end{columns}
\end{frame}
%!TEX root = lec02.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t]

\mytitle{Native Code Integration — Fortran vs. C++ from Python}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-4mm}
\centering
\includegraphics[width=\linewidth]{../../images/img02/fortran_python_sines.png}

\vspace{1mm}
{\small
Fortran via \texttt{ISO\_C\_BINDING} + \texttt{ctypes}\\
Numerics compiled, called from Python
}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\centering
\includegraphics[width=\linewidth]{../../images/img02/c++_python_sines.png}

\vspace{1mm}
{\small
C++ via C-compatible ABI + \texttt{ctypes}\\
Explicit interface, manual symbol control
}

\end{column}

% --- End Columns --------------------------------------------------------------
\end{columns}

\vspace{1mm}
\begin{itemize}
  \item Python orchestrates, \y{native code computes}
  \item Identical workflow: compile → load → call → plot
\end{itemize}

\end{frame}
%!TEX root = lec02.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Exposing a C++ Function via the C ABI}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.38\textwidth}

\vspace{-1mm}
\textbf{Role of C++}

\begin{itemize}
  \item Implements numerical logic
  \item Compiled into a shared library
  \item Exposes a \y{stable C ABI}
\end{itemize}

\vspace{1mm}
\textbf{Key Requirement}

\begin{itemize}
  \item Use \texttt{extern "C"}
  \item Avoid C++ name mangling
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.6\textwidth}

\vspace{-1mm}
\begin{codeonly}{Minimal C++ Interface}
#include <cmath>

extern "C" double f_cpp(double x)
{
    return std::sin(x) / (1.0 + x*x);
}
\end{codeonly}

\vspace{0mm}
\begin{itemize}
  \item Plain C-compatible symbol
  \item No templates, no classes
  \item ABI-safe function signature
\end{itemize}

\end{column}

% --- End Columns --------------------------------------------------------------
\end{columns}
\end{frame}
%!TEX root = lec02.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Calling C++ from Python with \texttt{ctypes}}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.32\textwidth}

\vspace{-1mm}
\textbf{Role of Python}

\begin{itemize}
  \item Python loads the shared library
  \item Defines the \y{binary interface}
  \item Controls execution and visualization
\end{itemize}

\vspace{1mm}
\textbf{Important Detail}

\begin{itemize}
  \item C++ function uses \y{C ABI}
  \item Arguments passed \y{by value}
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.68\textwidth}

\vspace{-3mm}
\begin{codeonly}{Minimal Python Interface}
import ctypes

lib = ctypes.CDLL("./cpp_interface.so")
lib.f_cpp.argtypes = [ctypes.c_double]
lib.f_cpp.restype  = ctypes.c_double

x = 1.0
y = lib.f_cpp(x)
\end{codeonly}

\vspace{-1mm}
\begin{itemize}
  \item Native C++ computation
  \item Explicit ABI contract
  \item Minimal Python overhead
\end{itemize}

\end{column}

% --- End Columns --------------------------------------------------------------
\end{columns}
\end{frame}
%!TEX root = lec02.tex
% ================================================================================
% Slide
% ================================================================================
\begin{frame}[t]

\mytitle{Remote Jupyter — Network Architecture}

\vspace{-8mm}
\begin{center}
  \includegraphics[width=\textwidth]{../../images/img02/jupyter_graphics.pdf}
\end{center}


\end{frame}
%!TEX root = lec02.tex
% ================================================================================
% Slide 23
% ================================================================================
\begin{frame}[t]

\mytitle{Remote Jupyter — Principle}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Core Idea}

\begin{itemize}
  \item Compute: \y{remote} (server, HPC, cloud)
  \item Visualization: \y{local} in the browser
  \item Browser setup remains unchanged
\end{itemize}

\vspace{1mm}
\textbf{Typical Scenarios}

\begin{itemize}
  \item HPC login or compute nodes
  \item Cloud virtual machines
  \item Office workstation / bastion host
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Security Principle}

\begin{itemize}
  \item \textbf{No} open notebook ports to the network
  \item Never expose \texttt{:8888} on a public IP
  \item Access exclusively via \y{SSH tunnels}
\end{itemize}

\vspace{1mm}
\textbf{Key Takeaway}

\begin{itemize}
  \item Jupyter only listens \y{locally}
  \item SSH provides secure transport
\end{itemize}

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec02.tex
% ================================================================================
% Slide 
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Remote Jupyter — Port Forwarding Recipe}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}

\textbf{Step 1: Start Jupyter Remotely}

\vspace{1mm}
\begin{codeonly}{Remote (Linux)}
jupyter notebook \
  --no-browser \
  --port=8888
\end{codeonly}

\vspace{1mm}

\begin{itemize}
  \item Access token appears in the terminal
  \item Port is \y{local only} on the remote server
\end{itemize}

{\tiny\begin{lstlisting}
To access the server, open this file in a browser:
  file:///hpc/uhome/rpotthas/.local/share/jupyter/runtime/jpserver-1662241-open.html
Or copy and paste one of these URLs:
  http://localhost:8888/tree?token=369b469c83e8eaa369ee02ea443d994865ca93e4185bb385
  http://127.0.0.1:8888/tree?token=369b469c83e8eaa369ee02ea443d994865ca93e4185bb385
\end{lstlisting}}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\textbf{Step 2: Create SSH Tunnel}

\vspace{1mm}
\begin{codeonly}{Local (Bash / PowerShell)}
ssh -N -L 9001:localhost:8888 \
    user@remote-host
\end{codeonly}

\vspace{1mm}
\textbf{Step 3: Open in Browser}

\begin{itemize}
  \item \texttt{http://localhost:9001}
  \item Use token from the remote log
  \item \y{Adjust port} if needed
\end{itemize}

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec02.tex
% ================================================================================
% Slide 
% ================================================================================
\begin{frame}[t]

\mytitle{Remote Jupyter — Firewalls \& Troubleshooting}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Typical Problems}

\begin{itemize}
  \item Local port already in use
  \item Remote port 8888 blocked by firewall
  \item Unstable SSH connection
  \item Multi-hop access (Jump / Bastion host)
\end{itemize}

\vspace{1mm}
\textbf{Important Note}

\begin{itemize}
  \item A blocked \texttt{8888} is \y{not an error}
  \item SSH tunnels do not require open inbound ports
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Best Practices}

\begin{itemize}
  \item Remote:
  \begin{itemize}
    \item \texttt{--ip=127.0.0.1}
    \item no public binding
  \end{itemize}
  \item Local:
  \begin{itemize}
    \item choose a free port (9001, 9002, \ldots)
  \end{itemize}
  \item Infrastructure:
  \begin{itemize}
    \item Bastion / jump host via \texttt{-J}
  \end{itemize}
\end{itemize}

\vspace{1mm}
\textbf{Recommendation}

\begin{itemize}
  \item \y{Never} expose Jupyter notebook ports publicly
\end{itemize}

\end{column}

\end{columns}
\end{frame}
% ================================================================================
% E-AI Tutorial Slides
% Filename: lec02.tex
% 
% Roland Potthast 2025/2026
% Licence: CC-BY4.0
% ================================================================================
\documentclass[aspectratio=169]{beamer}

% --- Load lecture macros --------------------------------------------------------
\input{../lec_macros.tex}
\newcommand{\LectureNumber}{Lecture 2}

% --- Document -------------------------------------------------------------------
\begin{document}

\setagendaboxforlecture{2}

\input{../lec_agenda.tex}
\input{lec02_01.tex}
\input{lec02_01b.tex}
\input{lec02_02.tex}
\input{lec02_03.tex}
\input{lec02_04.tex}
\input{lec02_05.tex}
\input{lec02_06.tex}
\input{lec02_07.tex}
\input{lec02_08.tex}
\input{lec02_09.tex}
\input{lec02_09b.tex}
\input{lec02_10.tex}
\input{lec02_11.tex}
\input{lec02_12.tex}
\input{lec02_13.tex}
\input{lec02_14.tex}
\input{lec02_15.tex}
\input{lec02_16.tex}
\input{lec02_17.tex}
\input{lec02_18.tex}
\input{lec02_19.tex}
\input{lec02_20.tex}
\input{lec02_21.tex}
\input{lec02_22.tex}
\input{lec02_23.tex}
\input{lec02_23b.tex}
\input{lec02_24.tex}
\input{lec02_25.tex}

% --- End Document ---------------------------------------------------------------
\end{document}
%!TEX root = lec03.tex
% ================================================================================
% Slide 01
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Working with Meteorological Data for AI and ML}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.42\textwidth}

\vspace{-1mm}
\textbf{Context}

\begin{itemize}
  \item Python-based workflows
  \item \y{Meteorological fields} for AI and machine learning
  \item Real operational datasets
\end{itemize}

\vspace{1mm}
\textbf{Why this lecture?}

\begin{itemize}
  \item ML needs structured input data
  \item Models operate on \y{fields, not files}
  \item Visualization builds physical intuition
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.56\textwidth}

\vspace{-2mm}
\textbf{Core skills we build}

\begin{itemize}
  \item Access meteorological fields
  \item Understand grids and metadata
  \item Convert and preprocess data
  \item Visualize fields and observations
\end{itemize}

\vspace{2mm}
\textbf{Outcome}

\begin{itemize}
  \item Data ready for \y{ML pipelines}
  \item Reproducible Python workflows
\end{itemize}

\vfill
\hfill
\includegraphics[width=0.28\textwidth]{../../images/img03/icon_lsm_plot.png}

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec03.tex
% ================================================================================
% Lecture 3 — Slide 02
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Installing and Exploring ecCodes}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.42\textwidth}

\vspace{-1mm}
\textbf{What is ecCodes?}

\begin{itemize}
  \item ECMWF library for GRIB handling
  \item Standard tool in operational NWP
  \item Python interface available
\end{itemize}

\vspace{1mm}
\textbf{Why we need it}

\begin{itemize}
  \item Forecast data comes as GRIB
  \item We need access to \y{fields and metadata}
  \item Independent of model (IFS, ICON, \ldots)
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.59\textwidth}

\vspace{-1.0cm}
\begin{codeonly}{Installation and test}
# Linux / WSL
sudo apt update
sudo apt install eccodes libeccodes-tools

# macOS (Homebrew)
brew install eccodes

# Python bindings
pip install eccodes

# Test installation
grib_ls -V
python -c "import eccodes; print(eccodes.codes_get_api_version())"
\end{codeonly}

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec03.tex
% ================================================================================
% Lecture 3 — Slide 03
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Using ecCodes}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.30\textwidth}

\vspace{-1mm}
\begin{itemize}
  \item See what is inside a GRIB file
  \item Identify fields
  \item Get size and structure
\end{itemize}

\vspace{1mm}
\textbf{Key idea}

\begin{itemize}
  \item A GRIB file contains \y{multiple messages}
  \item Each message holds one field
  \item ecCodes iterates message by message
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.74\textwidth}

\vspace{-1.1cm}

\begin{codeonly}{Inspecting a GRIB file}
import eccodes

f = open("icon_eu_t2m_latest.grib2", "rb")
while True:
    gid = eccodes.codes_grib_new_from_file(f)
    if gid is None:
        break

    short = eccodes.codes_get(gid, "shortName")
    level = eccodes.codes_get(gid, "level")
    size  = eccodes.codes_get_size(gid, "values")
    print(short, level, size)
    eccodes.codes_release(gid)
f.close()
\end{codeonly}

\end{column}
\end{columns}
\end{frame}
%!TEX root = lec03.tex
% ================================================================================
% Lecture 3 — Slide 04
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{IFS Open Data — Access via Client Library}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.42\textwidth}

\vspace{-2mm}
\begin{itemize}
  \item IFS data is not exposed as simple directories
  \item Access is service-based and load-controlled
  \item \y{Small subsets} can be retrieved efficiently
\end{itemize}

\vspace{1mm}
\textbf{Key idea}

\begin{itemize}
  \item Use ECMWF’s official open-data client
  \item Request fields by \y{parameter, step, level}
  \item Result is a standard GRIB2 file
\end{itemize}
\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.56\textwidth}

\vspace{-0.3cm}
\begin{codeonly}{Downloading IFS fields with ecmwf-opendata}
from ecmwf.opendata import Client

client = Client(
    source="ecmwf",
    model="ifs",
)

client.retrieve(
    time=0,
    type="fc",
    step=24,
    param=["2t", "msl"],
    target="ifs_2t.grib2")
\end{codeonly}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec03.tex
% ================================================================================
% Lecture 3 — Slide 05
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Plotting an IFS Field (Regular Grid)}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.3\textwidth}

\vspace{-2mm}
\begin{itemize}
  \item IFS open data uses a \y{regular lat–lon grid}
  \item Field values form a 2-D NumPy array
  \item Plotting is straightforward
\end{itemize}

\vspace{1mm}
\textbf{Important}

\begin{itemize}
  \item Grid size is fixed by the model
  \item figsize controls readability only
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.74\textwidth}

\vspace{-0.4cm}
\begin{codeonly}{Plotting IFS 2 m temperature}
import eccodes
import numpy as np
import matplotlib.pyplot as plt

f = open("ifs_2t.grib2", "rb")
gid = eccodes.codes_grib_new_from_file(f)

nx = eccodes.codes_get(gid, "Ni")
ny = eccodes.codes_get(gid, "Nj")
values = eccodes.codes_get_array(gid, "values")
field = values.reshape(ny, nx)

plt.figure(figsize=(7, 3.5))
plt.imshow(field, origin="lower")
\end{codeonly}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec03.tex
% ================================================================================
% Lecture 3 — Slide 06
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Cartopy — Map Projections for Meteorological Fields}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.38\textwidth}

\vspace{-2mm}
\begin{itemize}
  \item Cartopy provides projection-aware plotting
  \item Separates \y{data coordinates} from \y{map projection}
  \item Built on top of matplotlib
\end{itemize}

\vspace{1mm}
\textbf{In practice}

\begin{itemize}
  \item Define projection, e.g.\ \texttt{PlateCarree} 
  \item Coastlines, borders, land masks
  \item Define geographic extent
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.63\textwidth}

\vspace{-0.4cm}
\begin{codeonly}{Cartopy-based map plot}
import cartopy.crs as ccrs
import cartopy.feature as cfeature

fig, ax = plt.subplots( figsize=(10,5),
    subplot_kw={"projection": ccrs.PlateCarree()})

ax.coastlines()
ax.add_feature(cfeature.BORDERS)

ax.pcolormesh(lon, lat, field,
    transform=ccrs.PlateCarree(),
    cmap="jet" )
\end{codeonly}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec03.tex
% ================================================================================
% Lecture 3 — Slide 07
% ================================================================================
\begin{frame}[t]

\mytitle{ICON Open Data — File-Based Access}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-2mm}
\begin{itemize}
  \item ICON data is published as \y{static GRIB files}
  \item Organised by model, run, and parameter
  \item Distributed via DWD Open Data server
\end{itemize}

\vspace{1mm}
\textbf{Typical workflow}

\begin{itemize}
  \item Query directory listing
  \item Identify \y{latest available timestamp}
  \item Download and decompress \texttt{.grib2.bz2}
\end{itemize}


\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Material provided}

\begin{itemize}
  \item Python script: \texttt{icon\_download\_t2m.py}
  \item Jupyter notebook: ICON download \& inspection
\end{itemize}

\vspace{1mm}
\includegraphics[width=0.75\textwidth]{../../images/img03/icon_t2m_global.png}

\vspace{-1mm}
{\footnotesize
See code and notebooks for a robust, reusable implementation.
}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec03.tex
% ================================================================================
% Lecture 3 — Slide 08
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{ICON Fields — Interpolation and Dateline Handling}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-2mm}
\begin{itemize}
  \item ICON uses an \y{unstructured triangular grid}
  \item Direct plotting requires \y{triangulation}
  \item Interpolation needed for:
    \begin{itemize}
      \item smooth visualization
      \item map projections
    \end{itemize}
\end{itemize}

\vspace{1mm}
\textbf{Key challenge}

\begin{itemize}
  \item Triangles crossing the \y{date line}
  \item Incorrect rendering in global projections
  \item Requires explicit geometric handling
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\vspace{-0.3cm}
\begin{itemize}
  \item Use \texttt{matplotlib.tri.Triangulation}
  \item Detect triangles spanning $>180^\circ$
  \item Duplicate / shift vertices across $\pm180^\circ$
\end{itemize}

\vspace{2mm}
\textbf{Implementation}

\begin{itemize}
  \item See Python script:
  \texttt{fix\_dateline\_triangles.py}
  (adapted from ICON tutorial)
\end{itemize}

\vspace{0mm}
\hspace{2cm}\includegraphics[width=0.5\textwidth]{../../images/img03/icon_t2m_global_interp.png}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec03.tex
% ================================================================================
% Lecture 3 — Slide 09
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Observational Data — Purpose and Characteristics}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.42\textwidth}

\vspace{-2mm}
\begin{itemize}
  \item Observations anchor models to \y{reality}
  \item Essential for:
    \begin{itemize}
      \item verification
      \item data assimilation
      \item ML training and validation
    \end{itemize}
\end{itemize}

\vspace{1mm}
\textbf{Typical properties}

\begin{itemize}
  \item Irregular spatial distribution
  \item Sparse and heterogeneous
  \item Strong metadata dependence
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.56\textwidth}

\vspace{-1mm}
\textbf{Common observation types}

\begin{itemize}
  \item SYNOP (surface stations)
  \item TEMP / radiosondes
  \item AIREP / AMDAR (aircraft)
  \item Satellite observations
\end{itemize}

\vspace{1mm}
\textbf{Key difference to models}

\begin{itemize}
  \item No grid
  \item Point-based measurements
  \item Representativeness matters
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec03.tex
% ================================================================================
% Lecture 3 — Slide 10
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{SYNOP Data — Reading Raw Observations}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.42\textwidth}

\vspace{-2mm}
\begin{itemize}
  \item SYNOP stored in \y{NetCDF}
  \item One record per station
  \item Variables include:
    \begin{itemize}
      \item latitude, longitude
      \item observed temperature
    \end{itemize}
\end{itemize}

\vspace{1mm}
\textbf{Minimal requirement}

\begin{itemize}
  \item Read coordinates
  \item Read physical quantity
  \item Preserve missing values
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.56\textwidth}

\vspace{-1mm}
\textbf{Python tools}

\begin{itemize}
  \item \texttt{netCDF4.Dataset}
  \item \texttt{numpy}
\end{itemize}

\vspace{1mm}
\textbf{Variables used}

\begin{itemize}
  \item \texttt{MLAH} — latitude
  \item \texttt{MLOH} — longitude
  \item \texttt{MTDBT} — temperature
\end{itemize}

\vspace{1mm}
\textbf{Implementation}

\begin{itemize}
  \item See function: \texttt{read\_synop\_data()}
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec03.tex
% ================================================================================
% Lecture 3 — Slide 11
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{SYNOP Observations — Point-Based Visualization}

\vspace{0mm}
\includegraphics[height=0.95\textheight]{../../images/img03/synop.png}

\end{frame}
%!TEX root = lec03.tex
% ================================================================================
% Lecture 3 — Slide 12
% ================================================================================
\begin{frame}[t]

\mytitle{SYNOP Observations — Map Projections}

\vspace{-2mm}
\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}{0.5\textwidth}

\centering
\textbf{Plate Carree}

\vspace{1mm}
\includegraphics[height=0.45\textheight]{../../images/img03/synop_PlateCarree.png}

\vspace{-1cm}
\textbf{EuroPP}

\vspace{1mm}
\includegraphics[height=0.45\textheight]{../../images/img03/synop_EuroPP.png}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}{0.5\textwidth}

\centering
\vspace{-0.9cm}
\textbf{Geostationary}

\vspace{1mm}
\includegraphics[height=0.45\textheight]{../../images/img03/synop_Geostationary.png}

\vspace{-2mm}
\textbf{Transverse Mercator}

\vspace{1mm}
\includegraphics[height=0.45\textheight]{../../images/img03/synop_TransverseMercator.png}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec03.tex
% ================================================================================
% Lecture 3 — Slide 13
% ================================================================================
\begin{frame}[t]

\mytitle{Feedback Files — Linking Models and Observations}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}{0.42\textwidth}

\vspace{-2mm}
\begin{itemize}
  \item Feedback files store \y{model–observation pairs}
  \item Generated during data assimilation
  \item Central diagnostic product
\end{itemize}

\vspace{1mm}
\textbf{Contained information}

\begin{itemize}
  \item Observation value
  \item \y{Model equivalent} (H(x))
  \item Quality control flags
  \item Metadata (time, location, type)
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}{0.56\textwidth}

\vspace{-1mm}
\textbf{Why they matter}

\begin{itemize}
  \item Quantify model bias and error
  \item Basis for monitoring systems
  \item Ideal input for \y{ML analysis}
\end{itemize}

\vspace{2mm}
\includegraphics[width=0.99\textwidth]{../../images/img03/airep.png}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec03.tex
% ================================================================================
% Lecture 3 — Slide 14
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Feedback Files — Structure and Indexing}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}{0.35\textwidth}

\vspace{-2mm}
\begin{itemize}
  \item Stored as structured \y{NetCDF} files
  \item Separate layers for:
    \begin{itemize}
      \item report metadata
      \item individual observations
    \end{itemize}
\end{itemize}

\vspace{1mm}
\textbf{Key idea}

\begin{itemize}
  \item One report may contain many observations
  \item Explicit indexing links both layers
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}{0.63\textwidth}

\vspace{-1mm}
\textbf{Core variables (excerpt)}

\begin{verbatim}
i_body    (nreport)     start index of report
l_body    (nreport)     number in report

obs       (nobs)        observation
veri_data (nmodel,nobs) model equivalent H(x)
\end{verbatim}

\vspace{1mm}
\textbf{Interpretation}

\begin{itemize}
  \item \texttt{i\_body:l\_body} maps reports → obs
  \item \texttt{obs} and \texttt{veri\_data} are aligned
  \item Enables direct O–B, O–A diagnostics
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec03.tex
% ================================================================================
% Lecture 3 — Slide 15
% ================================================================================
\begin{frame}[t]

\mytitle{AIREP Feedback — Statistical Diagnostics}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}{0.42\textwidth}

\vspace{-2mm}
\begin{itemize}
  \item AIREP / AMDAR provide aircraft observations
  \item Strong vertical and regional sampling biases
  \item Feedback files enable systematic evaluation
\end{itemize}

\vspace{1mm}
\textbf{Typical diagnostics}

\begin{itemize}
  \item Observation density vs height
  \item Mean and spread of innovations (O–B)
  \item Model-dependent biases
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}{0.56\textwidth}

\vspace{-2mm}
\textbf{Why this matters}

\begin{itemize}
  \item Identifies representativeness errors
  \item Reveals flow- and height-dependent biases
\end{itemize}

\vspace{-1mm}
\centering
\includegraphics[width=0.95\textwidth]{../../images/img03/airep_height_density.png}

\vspace{-2mm}
{\footnotesize AIREP observation density as a function of height}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec03.tex
% ================================================================================
% Lecture 3 — Slide 16
% ================================================================================
\begin{frame}[t]

\mytitle{AIREP Feedback — Horizontal Sampling}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}{0.42\textwidth}

\vspace{-2mm}
\begin{itemize}
  \item AIREP sampling follows \y{air traffic routes}
  \item Highly inhomogeneous horizontal coverage
  \item Strong land–sea and regional contrasts
\end{itemize}

\vspace{1mm}
\textbf{Key implications}

\begin{itemize}
  \item Data density reflects logistics, not physics
  \item Large unsampled regions persist
  \item Bias risk if learning ignores sampling
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}{0.56\textwidth}

\vspace{-2mm}
\centering
\includegraphics[width=0.95\textwidth]{../../images/img03/airep_global_density.png}

\vspace{-2mm}
{\footnotesize Global horizontal density of AIREP observations}

\vspace{3mm}
\textbf{Operational relevance}

\begin{itemize}
  \item Affects verification statistics
  \item Affects DA weighting
  \item Critical for ML generalisation
\end{itemize}
\end{column}

\end{columns}

\end{frame}
%!TEX root = lec03.tex
% ================================================================================
% Lecture 3 — Slide 17
% ================================================================================
\begin{frame}[t]

\mytitle{{\color{red}Why GRIB?} — Operational Requirements}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}{0.42\textwidth}

\vspace{-2mm}
\begin{itemize}
  \item GRIB = \y{GRIdded Binary}
  \item Designed for operational NWP
  \item Optimised for:
    \begin{itemize}
      \item large data volumes
      \item fast I/O
      \item network distribution
    \end{itemize}
\end{itemize}

\vspace{1mm}
\textbf{Core design goals}

\begin{itemize}
  \item Compact encoding
  \item Self-describing metadata
  \item Bit-level compression
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}{0.56\textwidth}

\vspace{-1mm}
\textbf{Why it is still used}

\begin{itemize}
  \item Global models produce \y{terabytes per day}
  \item Multiple grids and vertical coordinates
  \item Strict real-time constraints
\end{itemize}

\vspace{1mm}
\textbf{Operational reality}

\begin{itemize}
  \item WMO standard
  \item Tooling is mature and stable
  \item Backward compatibility matters
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec03.tex
% ================================================================================
% Lecture 3 — Slide 18
% ================================================================================
\begin{frame}[t]

\mytitle{{\color{red}Alternatives to GRIB} — Strengths and Limits}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}{0.42\textwidth}

\vspace{0mm}
\textbf{NetCDF / CF}

\begin{itemize}
  \item Widely used in research
  \item Human-readable metadata
  \item Excellent tool support
\end{itemize}

\vspace{1mm}
\textbf{Zarr / Cloud-native}

\begin{itemize}
  \item Chunked, parallel access
  \item Designed for object storage
  \item Attractive for ML workflows
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}{0.56\textwidth}

\vspace{-1mm}
\textbf{Why GRIB is not easily replaced}

\begin{itemize}
  \item Operational ecosystems are huge
  \item Encoding efficiency still unmatched
  \item Standards evolution is slow by design
\end{itemize}

\vspace{1mm}
\textbf{Current practice}

\begin{itemize}
  \item GRIB for production and exchange
  \item {\color{red}NetCDF / Zarr for analysis and ML}
  \item \y{Conversion layers in between}
\end{itemize}

\vspace{1mm}
\textbf{Key message}

\begin{itemize}
  \item Format choice reflects \y{use case}
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec03.tex
% ================================================================================
% Lecture 3 — Slide 19
% ================================================================================
\begin{frame}[t]

\mytitle{GPU Access in Practice — Why It Depends on the Platform}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}{0.53\textwidth}

\vspace{-2mm}
\begin{itemize}
  \item Most laptops \emph{do have a GPU}
  \item But GPU \y{type and backend} differ strongly
  \item Python code must match the backend
\end{itemize}

\vspace{1mm}
\textbf{Common GPU types}

\begin{itemize}
  \item \y{NVIDIA} — typical for HPC clusters
  \item \y{Apple GPU} — Apple Silicon 
  \item \y{AMD / Radeon} — some laptops, workstations
\end{itemize}

\vspace{1mm}
\textbf{Key message}

\begin{itemize}
  \item The \y{software interface} matters
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}{0.48\textwidth}

\vspace{-1mm}
\textbf{GPU backends used in Python}

\vspace{1mm}
\begin{itemize}
  \item \texttt{CUDA} — NVIDIA GPUs (Linux, HPC)
  \item \texttt{MPS / Metal} — Apple GPUs (macOS)
  \item \texttt{CPU fallback} — always available
\end{itemize}

\vspace{2mm}
\textbf{Implication for ML workflows}

\begin{itemize}
  \item Development often on laptops
  \item Training often on HPC systems
  \item Code must be \y{portable across backends}
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec03.tex
% ================================================================================
% Lecture 3 — Slide 20
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{GPU Tests in Python — Minimal Backend Checks}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}{0.53\textwidth}

\vspace{-2mm}
\textbf{\y{NVIDIA GPU (CUDA)}}

\vspace{1mm}
\begin{codeonly}{CUDA test}
import torch
print(torch.cuda.is_available())
\end{codeonly}

\vspace{2mm}
\textbf{\y{Apple GPU (Metal / MPS)}}

\vspace{1mm}
\begin{codeonly}{Apple GPU test}
import torch
print(torch.backends.mps.is_available())
\end{codeonly}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}{0.45\textwidth}

\vspace{-2mm}
\textbf{\y{AMD / Radeon GPUs}}

\vspace{1mm}
\begin{itemize}
\item No native PyTorch GPU backend
\end{itemize}

\vspace{2mm}
\textbf{Interpretation}

\begin{itemize}
  \item \texttt{True} → GPU usable
  \item \texttt{False} → CPU fallback
  \item Backend determines capability
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec03.tex
% ================================================================================
% Lecture 3 — Slide 21
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{GPU Execution in Python — Laptop vs. HPC}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}{0.49\textwidth}

\vspace{-2mm}
\textbf{\y{Apple GPU (Metal / MPS)}}

\vspace{1mm}
\begin{codeonly}{Apple GPU test}
import torch, time

d = torch.device("mps")
x = torch.rand((4000,4000), device=d)

t0 = time.time()
y = torch.matmul(x, x)
torch.mps.synchronize()

print("Apple GPU time:",
      round(time.time()-t0,3))
\end{codeonly}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}{0.49\textwidth}

\vspace{-2mm}
\textbf{\y{NVIDIA A100 (CUDA)}}

\vspace{1mm}
\begin{codeonly}{HPC GPU test}
import torch, time

d = torch.device("cuda")
x = torch.rand((8000,8000), device=d)

t0 = time.time()
y = torch.matmul(x, x)
torch.cuda.synchronize()

print("A100 time:",
      round(time.time()-t0,3))
\end{codeonly}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec03.tex
% ================================================================================
% Lecture 3 — Slide 22
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Interactive GPU Access and Verification Workflow}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-1mm}
\textbf{Step 1: Interactive GPU login}

\begin{codeonly}{Shell alias (interactive GPU)}
alias gpu1='qlogin -q gp_inter_dgx \
 --gpunum-lhost=1 \
 --cpunum-lhost=16 \
 -l elapstim_req=6:00:00 \
 -l memsz_job=240gb'
\end{codeonly}

\vspace{1mm}
\textbf{Step 2: Select GPU explicitly}

\begin{codeonly}{Shell}
export CUDA_VISIBLE_DEVICES=7
echo $CUDA_VISIBLE_DEVICES
\end{codeonly}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}

\vspace{-1mm}
\textbf{Step 3: Minimal verification}

\begin{codeonly}{Mini GPU check in Python}
import torch, os
print("CUDA_VISIBLE_DEVICES =", os.getenv("CUDA_VISIBLE_DEVICES"))
print("Visible GPUs =", torch.cuda.device_count())
print("GPU name =", torch.cuda.get_device_name(0))
\end{codeonly}

\vspace{0mm}
\begin{itemize}
  \item Interactive login allocates resources
  \item GPU visibility must be set \y{explicitly}
  \item Always verify from inside Python
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec03.tex
% ================================================================================
% Lecture 3 — Slide 23
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{CPU vs GPU — Execution Model and Performance: 30sec --> 3sec}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}

\vspace{-3mm}
\begin{codeonly}{CPU example}
import torch, time
n = 30000
x0 = torch.rand((n,n))
x1 = torch.rand((n,n))
t0 = time.time()
y0 = torch.matmul(x0,x0)
y1 = torch.matmul(x1,x1)
print(time.time()-t0)
\end{codeonly}

\vspace{1mm}
\textbf{Observed}

\begin{itemize}
  \item Operations are \y{blocking}
  \item Second call starts after first ends
  \item Parallelism only inside BLAS
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\vspace{-3mm}
\begin{codeonly}{Two-GPU example}
import torch, time
d0 = torch.device("cuda:0")
d1 = torch.device("cuda:1")
n. = 30000
x0 = torch.rand((n,n),device=d0)
x1 = torch.rand((n,n),device=d1)
t0 = time.time()
torch.matmul(x0,x0)
torch.matmul(x1,x1)
torch.cuda.synchronize()
print(time.time()-t0)
\end{codeonly}

\vspace{0mm}
\begin{itemize}
  \item Operations run \y{concurrently}
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec03.tex
% ================================================================================
% Lecture 3 — Slide 24
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Parallel Matrix Multiplication — What Actually Works}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}

\vspace{-3mm}
\textbf{Key idea}

\begin{itemize}
  \item Naive multi-GPU often shows \y{no speed-up}
  \item Reason: data transfers dominate computation
  \item Solution: \y{true model parallelism}
\end{itemize}

\vspace{2mm}
\textbf{What works}

\begin{itemize}
  \item Build matrices \y{directly on each GPU}
  \item Split the computation (block-wise)
  \item Avoid CPU–GPU transfers
  \item Collect results only at the end
\end{itemize}

\vspace{2mm}
\begin{itemize}
  \item 1 GPU: \textasciitilde 3 s
  \item 2 GPUs (naive): \textasciitilde 3 s
  \item 2 GPUs (correct): \y{\textasciitilde 0.5 s}
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.54\textwidth}

\vspace{-4mm}
\begin{codeonly}{True model-parallel matrix multiplication}
import torch, time
n = 30000
A0 = torch.rand((n//2,n), device="cuda:0")
A1 = torch.rand((n//2,n), device="cuda:1")
B  = torch.rand((n,n),     device="cuda:0")
t0 = time.time()
C0 = A0 @ B
C1 = A1 @ B.to("cuda:1")
torch.cuda.synchronize()
print("Time:", round(time.time()-t0,3))
\end{codeonly}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec03.tex
% ================================================================================
% Lecture 3 — Slide 25
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Mixed Precision Computing — Why FP16 Matters}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.41\textwidth}

\textbf{Why reduced precision?}

\begin{itemize}
  \item Modern GPUs are optimized for \y{FP16 / BF16}
  \item Higher throughput, lower memory traffic
  \item Essential for large ML models
\end{itemize}

\vspace{2mm}
\textbf{Typical ML pattern}

\begin{itemize}
  \item Dense linear layers
  \item Nonlinear activation
  \item Large batch sizes
\end{itemize}

\vspace{2mm}
Transformers, Diffusion, Weather

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.62\textwidth}

\vspace{-2mm}
\begin{codeonly}{FP16 neural-network-style workload}
import torch, time
torch.set_default_dtype(torch.float16)
d = torch.device("cuda")
x = torch.randn((20000,1024), device=d)
W1 = torch.randn((1024,4096), device=d)
W2 = torch.randn((4096,1024), device=d)
t0 = time.time()
y = torch.nn.functional.gelu(x @ W1)
z = y @ W2
torch.cuda.synchronize()
print("FP16 time:", round(time.time()-t0,3))
\end{codeonly}

\end{column}

\end{columns}

\end{frame}
% ================================================================================
% E-AI Tutorial Slides
% Filename: lec03.tex
%
% Roland Potthast 2025/2026
% Licence: CC-BY4.0
% ================================================================================
\documentclass[aspectratio=169]{beamer}

% --- Load lecture macros --------------------------------------------------------
\input{../lec_macros.tex}
\newcommand{\LectureNumber}{Lecture 3}

% --- Document -------------------------------------------------------------------
\begin{document}

\setagendaboxforlecture{3}

\input{../lec_agenda.tex}
\input{lec03_01.tex}
\input{lec03_02.tex}
\input{lec03_03.tex}
\input{lec03_04.tex}
\input{lec03_05.tex}
\input{lec03_06.tex}
\input{lec03_07.tex}
\input{lec03_08.tex}
\input{lec03_09.tex}
\input{lec03_10.tex}
\input{lec03_11.tex}
\input{lec03_12.tex}
\input{lec03_13.tex}
\input{lec03_14.tex}
\input{lec03_15.tex}
\input{lec03_16.tex}
\input{lec03_17.tex}
\input{lec03_18.tex}
\input{lec03_19.tex}
\input{lec03_20.tex}
\input{lec03_21.tex}
\input{lec03_22.tex}
\input{lec03_23.tex}
\input{lec03_24.tex}
\input{lec03_25.tex}

% --- End Document ---------------------------------------------------------------
\end{document}
%!TEX root = lec04.tex
% ================================================================================
% Lecture 4 — Slide 01
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{AI and ML — A Problem-Solving Perspective}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Classical approach}

\begin{itemize}
  \item Explicit equations
  \item Physical \y{laws and dynamics}
  \item Expert-designed structure
  \item Limited by model assumptions
\end{itemize}

\vspace{1mm}
\[
\partial_t x = F(x,\theta)
\]
The temporal change of $x$ is calculated based on $x$ and parameters $\theta$.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{AI / ML approach}

\begin{itemize}
  \item Learn mappings $x \rightarrow y$ from data
  \item High-dimensional, nonlinear relations
  \item Neural nets as \y{universal approximators}
  \item Used in natural sciences as well as language
\end{itemize}

\vspace{1mm}
\[
\hat{z} = f_\theta(x)
\]
Some quantity $z$ is estimated \\
from input $x$

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec04.tex
% ================================================================================
% Lecture 4 — Slide 02
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{AI and ML — A Set of Tools}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Core ML frameworks}

\begin{itemize}
  \item \y{PyTorch}, TensorFlow
  \item scikit-learn
  \item Automatic differentiation
  \item GPU acceleration
\end{itemize}

\vspace{1mm}
\[
\min_{\theta} \; L\!\left(y,\hat{y}(x;\theta)\right)
\]

\y{Training} = minimizing a loss function  
by adjusting parameters $\theta$.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{AI as a service}

\begin{itemize}
  \item \y{LLM APIs} (OpenAI, Mistral, Anthropic, Google, Meta, ...)
  \item Pre-trained foundation models
  \item On-premise models (Llama, Mistral)
  \item Cloud, local, or hybrid use
\end{itemize}

\vspace{1mm}
\[
\text{API call} \;\rightarrow\; \text{model inference}
\]

Models are used without  
training from scratch.

\hfill{\bf\color{red}What is my own role in this?}
\end{column}

\end{columns}

\end{frame}
%!TEX root = lec04.tex
% ================================================================================
% Lecture 4 — Slide 03
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{AI and ML — A New Paradigm for Interactivity}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Human–AI interaction}

\begin{itemize}
  \item Code assistants
  \item Natural language interfaces
  \item \y{Interactive problem solving}
  \item Rapid prototyping
\end{itemize}

\vspace{1mm}
\[
\text{Prompt} \;\rightarrow\; \text{Response}
\]

\vspace{2mm}
{\bf\color{red} Iterative dialogue} replaces\\
\hspace{2cm} static interfaces.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{AI in research workflows}

\begin{itemize}
  \item \y{Data exploration}
  \item Hypothesis support
  \item \y{Equation generation} and review
  \item Support Reasoning 
\end{itemize}

\vspace{1mm}
\[
\text{Human} \;\leftrightarrow\; \text{AI}
\]

\y{Collaboration}, not replacement. 

\vspace{3mm}
{\bf\color{red}AI as Partner for Reasoning.}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec04.tex
% ================================================================================
% Lecture 4 — Slide 04
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Critical Evaluation I — Reliability and Limits}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Strengths}

\begin{itemize}
  \item Fast pattern recognition
  \item Handles high-dimensional data
  \item Automates repetitive tasks
  \item Strong empirical performance
\end{itemize}

\vspace{1mm}
\[
\hat{y} = f_\theta(x)
\]

Works well within  \\
the \y{learned data regime.}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Limitations}

\begin{itemize}
  \item No physical understanding
  \item Hallucinations possible
  \item Sensitive to data bias
  \item Weak extrapolation
\end{itemize}

\vspace{1mm}
\[
f_\theta(x) \neq \text{truth}
\]

\y{Prediction is not validation.}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec04.tex
% ================================================================================
% Lecture 4 — Slide 05
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Critical Evaluation II — Trust, Oversight, Responsibility}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Why human oversight matters}

\begin{itemize}
  \item AI outputs look convincing
  \item Errors are often non-obvious
  \item No built-in notion of consequences
  \item Responsibility remains human
\end{itemize}

\vspace{1mm}
\[
\text{Decision} = \text{AI} + \text{Human}
\]

\y{AI supports, it does not decide.}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Key risk dimensions}

\begin{itemize}
  \item Transparency and explainability
  \item Bias and unfairness
  \item Reproducibility
  \item Accountability
\end{itemize}

\vspace{1mm}
\[
\text{\y{Confidence}} \neq \text{\y{Correctness}}
\]

Trust must be earned, not assumed.

\vspace{2mm}
{\bf\color{red}Be careful, AI makes many mistakes!}
\end{column}

\end{columns}

\end{frame}
%!TEX root = lec04.tex
% ================================================================================
% Lecture 4 — Slide 06
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Torch Tensors — The Core Data Structure}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{What is a tensor?}

\begin{itemize}
  \item Similar to NumPy arrays
  \item Supports CPU and GPU
  \item Tracks operations for gradients
  \item Basis of all learning
\end{itemize}

\vspace{1mm}
\textbf{Key properties}

\begin{itemize}
  \item Shape and dtype
  \item Device awareness
  \item \texttt{requires\_grad=True}
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-2mm}
\begin{codeonly}{Basic tensor example}
import torch

x = torch.tensor([2.,3.], requires_grad=True)

y = x[0]**2 + x[1]**2
y.backward()

print(x.grad)
\end{codeonly}

\vspace{1mm}
\[
\nabla_x (x_1^2 + x_2^2)
\]

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec04.tex
% ================================================================================
% Lecture 4 — Slide 07
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Automatic Differentiation (Autograd)}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Core idea}

\begin{itemize}
  \item Gradients computed automatically
  \item No manual derivative formulas
  \item Works for arbitrary computation graphs
  \item Enabled by \y{dynamic graphs}
\end{itemize}

\vspace{1mm}
\[
\frac{\partial \mathcal{L}}{\partial \theta}
\]
Gradients drive parameter updates.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Why this matters}

\begin{itemize}
  \item Learning = optimization
  \item Backpropagation at scale
  \item Essential for deep networks
  \item Same mechanism on CPU and GPU
\end{itemize}

\vspace{1mm}
\[
\theta_{k+1} = \theta_k - \eta \nabla_\theta \mathcal{L}
\]
\y{Gradient-based learning step.}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec04.tex
% ================================================================================
% Lecture 4 — Slide 08
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Data Handling in PyTorch: Dataset and DataLoader}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Why data loaders exist}

\begin{itemize}
  \item Datasets often too large for memory
  \item Training uses \y{mini-batches}
  \item Data order matters for optimization
  \item Separation of data and model logic
\end{itemize}

\vspace{1mm}
\[
(x_i, y_i) \;\rightarrow\; (X_B, Y_B)
\]
Samples are grouped into batches.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{What DataLoader provides}

\begin{itemize}
  \item Batching
  \item Optional shuffling
  \item Parallel loading (CPU workers)
  \item Consistent interface for training loops
\end{itemize}

\vspace{1mm}
\[
(X_B, Y_B) \;\rightarrow\; \mathcal{L}(f_\theta(X_B), Y_B)
\]
Each batch produces one loss value.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec04.tex
% ================================================================================
% Lecture 4 — Slide 09
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{\y{Batches} Explained: What Comes Out of the DataLoader}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Features and labels}

\begin{itemize}
  \item \y{Features} $x$: input quantities
  \item \y{Labels} $y$: measured target values
  \item Learning means fitting $x \rightarrow y$
\end{itemize}

\vspace{1mm}
\textbf{Structure of the data}

\begin{itemize}
  \item $N$ = number of samples
  \item $d$ = number of features per sample
  \item One row = one $(x,y)$ pair
\end{itemize}

\vspace{1mm}
\[
X \in \mathbb{R}^{N \times d}
\;\Rightarrow\;
X_B \in \mathbb{R}^{B \times d}
\]

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Labels and targets}

\begin{itemize}
  \item Labels collected in $Y$
  \item One target per input sample
  \item Same batching as for features
\end{itemize}
\[
Y \in \mathbb{R}^{N \times k}
\;\Rightarrow\;
Y_B \in \mathbb{R}^{B \times k}
\]

\vspace{0mm}
\textbf{Why mini-batches help}

\begin{itemize}
  \item Memory-efficient processing
  \item Faster parameter updates
  \item Noise improves generalization
\end{itemize}

\vspace{-1mm}
\[
\nabla_\theta \mathcal{L}(X_B, Y_B)
\;\approx\;
\nabla_\theta \mathcal{L}(X, Y)
\]

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec04.tex
% ================================================================================
% Lecture 4 — Slide 10
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Defining a Simple Neural Network}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.4\textwidth}

\textbf{Neural network idea}

\begin{itemize}
  \item Learn a mapping $f_\theta : x \rightarrow \hat{y}$
  \item \y{Parameters} $\theta$ are trainable
  \item Composition of simple operations
\end{itemize}

\vspace{1mm}
\textbf{Basic building blocks}

\begin{itemize}
  \item \y{Linear transformation}
  \item \y{Nonlinear activation}
  \item Output layer
\end{itemize}

\vspace{-2mm}
\[
\hat{y} = f_\theta(x)
\]

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.58\textwidth}

\vspace{-5mm}
\begin{codeonly}{Minimal PyTorch model}
import torch.nn as nn

class SimpleNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(1,16)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(16,1)

    def forward(self,x):
        x = self.fc1(x)
        x = self.relu(x)
        return self.fc2(x)
\end{codeonly}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec04.tex
% ================================================================================
% Lecture 4 — Slide 11
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{What the Model Actually Represents}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Model as a function}

\begin{itemize}
  \item Neural network defines a parametric function
  \item Parameters = weights and biases
  \item Training adjusts these parameters
\end{itemize}

\vspace{1mm}
\[
\hat{y} = W_2 \,\sigma(W_1 x + b_1) + b_2
\]

\vspace{1mm}
Nonlinearity $\sigma$ enables complex mappings.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Trainable parameters}

\begin{itemize}
  \item Layer 1: $1 \rightarrow 16$
  \item Layer 2: $16 \rightarrow 1$
\end{itemize}

\vspace{1mm}
\[
\begin{aligned}
\text{fc1: } &16 \text{ weights} + 16 \text{ biases} = 32 \\
\text{fc2: } &16 \text{ weights} + 1 \text{ bias} = 17
\end{aligned}
\]

\vspace{1mm}
\textbf{Total:} $\;32 + 17 = \y{49}$ parameters

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec04.tex
% ================================================================================
% Lecture 4 — Slide 12
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Loss Functions — Measuring Error}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{What is a loss?}

\begin{itemize}
  \item Quantifies model \y{error}
  \item Single \y{scalar} value
  \item Compares prediction vs label
\end{itemize}

\vspace{1mm}
The loss defines the objective
that learning tries to \y{minimize}.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Example: Mean Squared Error}

\vspace{1mm}
\[
\mathcal{L}
= \frac{1}{N}
\sum_{i=1}^{N}
\bigl(y_i - \hat{y}_i\bigr)^2
\]

\vspace{1mm}
\begin{itemize}
  \item $y$: true \y{label}
  \item $\hat{y}$: model prediction
  \item $N$: number of samples
\end{itemize}

\vspace{1mm}
Lower loss $\Rightarrow$ \y{better fit}.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec04.tex
% ================================================================================
% Lecture 4 — Slide 13
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{The Adam Optimizer — Adaptive Gradient Descent}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Why optimizers matter}

\begin{itemize}
  \item Loss defines \y{what} to minimize
  \item Optimizer defines \y{how}
  \item Controls stability and speed
\end{itemize}

\vspace{1mm}
Goal: update parameters
to reduce loss \y{efficiently}.

\vspace{1mm}
Adam combines momentum and scaling:
\[
\delta \theta \;\propto\; 
- \frac{\text{average current gradient}}{\text{typical gradient size}}
\]


\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Adam in a nutshell}

\begin{itemize}
  \item Uses \y{gradients}
  \item Tracks first moment (mean)
  \item Tracks second moment (variance)
  \item Adaptive step size per parameter
\end{itemize}

\vspace{1mm}
Parameter update (conceptually):
\[
\theta_{t+1}
=
\theta_t - \eta \,
\frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon}
\]

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec04.tex
% ================================================================================
% Lecture 4 — Slide 14
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{End-to-End Example — Learning a Sine Function}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Goal of the example}

\begin{itemize}
  \item Approximate a known function: \y{$\sin(x)$}
  \item Learn from sampled input–output pairs
  \item Demonstrate full ML workflow
\end{itemize}

\vspace{1mm}
Target mapping:
\[
x \;\mapsto\; \sin(x)
\]

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Components involved}

\begin{itemize}
  \item Synthetic dataset $(x, y)$
  \item Neural network model
  \item Loss function (error measure)
  \item Optimizer updating parameters
\end{itemize}

\vspace{1mm}
Training objective:
\[
\min_\theta \; \sum_i
\bigl\lVert f_\theta(x_i) - y_i \bigr\rVert^2
\]

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec04.tex
% ================================================================================
% Lecture 4 — Slide 15
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Sine Example — Data and DataLoader}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.4\textwidth}

\textbf{Dataset construction}

\begin{itemize}
  \item Sample input values $x$
  \item Compute labels \y{$y=\sin(x)$}
  \item Supervised learning setup
\end{itemize}

\vspace{1mm}
Each sample:
\[
x_i \;\rightarrow\; y_i
\]

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.6\textwidth}

\vspace{-4mm}
\begin{codeonly}{Creating dataset and loader}
x = np.linspace(0, 2*np.pi, 1000)
y = np.sin(x)

x_t = torch.tensor(x).float().unsqueeze(1)
y_t = torch.tensor(y).float().unsqueeze(1)

data = TensorDataset(x_t, y_t)
loader = DataLoader(data,
                    batch_size=32,
                    shuffle=True)
\end{codeonly}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec04.tex
% ================================================================================
% Lecture 4 — Slide 16
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Model and Training Loop}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.4\textwidth}

\textbf{Model idea}

\begin{itemize}
  \item Input: scalar $x$
  \item Output: scalar $\hat{y}$
  \item Learn nonlinear mapping
\end{itemize}

\vspace{1mm}
\textbf{Training}

\begin{itemize}
  \item Compare $\hat{y}$ and \y{$y$}
  \item Minimize prediction error
  \item Update model parameters
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.6\textwidth}

\vspace{-11mm}
\begin{codeonly}{Model and training loop}
model = nn.Sequential(
    nn.Linear(1,16), nn.ReLU(),
    nn.Linear(16,16), nn.ReLU(),
    nn.Linear(16,1)
)

loss_fn = nn.MSELoss()
opt = torch.optim.Adam(
      model.parameters(), lr=0.01)

for x_b,y_b in loader:
    opt.zero_grad()
    y_p = model(x_b)
    loss = loss_fn(y_p, y_b)
    loss.backward()
    opt.step()
\end{codeonly}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec04.tex
% ================================================================================
% Lecture 4 — Slide 17
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Sine Example — Training Outcome}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{What happened during training?}

\begin{itemize}
  \item Loss decreases over epochs
  \item Network parameters adapt
  \item Mapping $x \rightarrow \hat{y}$ improves
\end{itemize}

\vspace{1mm}
\textbf{Interpretation}

\begin{itemize}
  \item Model learned a smooth function
  \item No explicit sine formula given
  \item Learning via \y{gradient descent}
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-11mm}
\begin{minipage}[T]{1.5cm}
\textbf{Loss\\during\\training}
\end{minipage}
\begin{minipage}[T]{4cm}
\includegraphics[height=3.5cm]{../../images/img04/sine_training_loss.png}
\end{minipage}

\vspace{0mm}
\includegraphics[height=3cm]{../../images/img04/sine_approximation.png}

\vspace{-2mm}
\centering
Actual sine (solid) vs.\ model prediction (dashed)

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec04.tex
% ================================================================================
% Lecture 4 — Slide 18
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{DataLoader Without Shuffling}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{What happens?}

\begin{itemize}
  \item Samples returned in fixed order
  \item Batches follow dataset sequence
  \item Same batches every epoch
\end{itemize}

\vspace{1mm}
\textbf{Why this can be problematic}

\begin{itemize}
  \item Correlated samples in one batch
  \item Biased gradient estimates
  \item Slower or unstable learning
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-6mm}
\begin{codeonly}{Ordered batches}
loader = DataLoader(
    dataset,
    batch_size=4,
    shuffle=False
)

for x_b, y_b in loader:
    print(y_b.squeeze())
    break
\end{codeonly}

\vspace{1mm}
First batch always contains the same labels.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec04.tex
% ================================================================================
% Lecture 4 — Slide 19
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{DataLoader With Shuffling}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{What changes?}

\begin{itemize}
  \item Samples randomly permuted
  \item Different batches every epoch
  \item Decorrelated gradients
\end{itemize}

\vspace{1mm}
\textbf{Why this helps}

\begin{itemize}
  \item More robust optimization
  \item Better generalization
  \item Standard practice in ML
\end{itemize}

{\tiny\begin{lstlisting}
=== DataLoader WITHOUT shuffling ===
Batch 1: [1, 2, 3, 4, 5, 6]
Batch 2: [7, 8, 9, 10, 11, 12]
Batch 3: [13, 14, 15, 16, 17, 18]
Batch 4: [19, 20]
\end{lstlisting}}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-6mm}
\begin{codeonly}{Shuffled batches}
loader = DataLoader(
    dataset,
    batch_size=4,
    shuffle=True
)

for x_b, y_b in loader:
    print(y_b.squeeze())
    break
\end{codeonly}

\vspace{1mm}
First batch changes every run.

{\tiny\begin{lstlisting}
=== DataLoader WITH shuffling ===
Batch 1: [3, 4, 15, 7, 18, 6]
Batch 2: [11, 16, 13, 17, 9, 1]
Batch 3: [14, 19, 12, 5, 8, 2]
Batch 4: [20, 10]
\end{lstlisting}}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec04.tex
% ================================================================================
% Lecture 4 — Slide 20
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{From Prediction to Understanding}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Prediction is not enough}

\begin{itemize}
  \item Low error $\neq$ understanding
  \item Correct output may hide fragile behavior
  \item Especially risky outside training range
\end{itemize}

\vspace{1mm}
Models can be accurate yet \y{misleading}.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Why gradients matter}

\begin{itemize}
  \item Sensitivity of output to input
  \item Reveal decision boundaries
  \item Identify unstable regions
\end{itemize}

\vspace{1mm}
\[
\nabla_x f(x)
\]
Measures how predictions change locally.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec04.tex
% ================================================================================
% Lecture 4 — Slide 21
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Defining a \y{Classifier} — Simple Version}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.4\textwidth}

\textbf{Binary classification setup}

\begin{itemize}
  \item Input: 2D feature vector $x=(x_1,x_2)$
  \item Output: probability $\hat{y} \in [0,1]$
  \item Decision via threshold
\end{itemize}

\vspace{1mm}
\[
\hat{y} = f_\theta(x)
\]
Class label inferred from $\hat{y}$.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.57\textwidth}

\vspace{-4mm}
\begin{codeonly}{Simple classifier model}
class SimpleClassifier(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(2,1),
            nn.Sigmoid()
        )
    def forward(self,x):
        return self.net(x)
\end{codeonly}

\vspace{1mm}
Minimal nonlinear decision model.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec04.tex
% ================================================================================
% Lecture 4 — Slide 22
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Improving the Classifier — Nonlinear Model}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.4\textwidth}

\textbf{Why improve the model?}

\begin{itemize}
  \item Linear boundary often insufficient
  \item Real data is nonlinear
  \item Need higher expressive power
\end{itemize}

\vspace{1mm}
\[
\hat{y} = \sigma\bigl(W_2\,\phi(W_1 x)\bigr)
\]
Hidden layer enables nonlinear separation.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.58\textwidth}

\vspace{-4mm}
\begin{codeonly}{Better classifier model}
class BetterClassifier(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(2,32),
            nn.ReLU(),
            nn.Linear(32,1),
            nn.Sigmoid()
        )
    def forward(self,x):
        return self.net(x)
\end{codeonly}

\vspace{1mm}
Nonlinear decision boundary.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec04.tex
% ================================================================================
% Lecture 4 — Slide 23
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Applying the Classifier to Data}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.4\textwidth}

\textbf{Training the classifier}

\begin{itemize}
  \item Input: feature vectors $(x_1,x_2)$
  \item Output: class probability $\hat{y}$
  \item Supervised binary classification
\end{itemize}

\vspace{1mm}
\textbf{Goal}

\begin{itemize}
  \item Separate two classes
  \item Learn a decision boundary
  \item Minimize classification error
\end{itemize}

{\tiny\begin{lstlisting}
grid_points = torch.stack([xx.flatten(), yy.flatten()], dim=1)  
grid_points.requires_grad = True
grid_grads = grid_points.grad.detach().numpy()
\end{lstlisting}}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.58\textwidth}

\vspace{-6mm}
\begin{codeonly}{Training loop}
loss_fn = nn.BCELoss()
opt = optim.Adam(model.parameters(), lr=0.01)

for epoch in range(epochs):
    opt.zero_grad()
    y_p = model(X)
    loss = loss_fn(y_p, y_true)
    loss.backward()
    opt.step()
\end{codeonly}

\vspace{1mm}
Prediction $\hat{y}\in[0,1]$ interpreted as probability.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec04.tex
% ================================================================================
% Lecture 4 — Slide 24
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Labels vs.\ Learned Classification}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Ground truth labels}

\begin{itemize}
  \item Classes defined by geometry
  \item Two shifted, rotated ellipses
  \item Labels fixed before learning
\end{itemize}

\vspace{-2mm}
\includegraphics[width=0.8\textwidth]{../../images/img04/points_labled.png}

\vspace{-1mm}
Blue / red = predefined classes

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-8mm}
\textbf{Model prediction}

\begin{itemize}
  \item Network output $\hat{y}\in[0,1]$
  \item Nonlinear decision boundary
  \item Smooth transition between classes
\end{itemize}

\vspace{-1mm}
\includegraphics[width=0.9\textwidth]{../../images/img04/points_classified_with_gradients.png}

\vspace{-1mm}
Colors = prediction, arrows = gradients

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec04.tex
% ================================================================================
% Lecture 4 — Slide 25
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Chapter 4 — Take-Home Messages}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{What AI/ML really is}

\begin{itemize}
  \item Differentiable function approximation
  \item Learned from data, not hard-coded
  \item Optimized via \y{gradients}
\end{itemize}

\vspace{-3mm}
\[
\text{Learn } f_\theta \;\text{s.t.}\;
f_\theta(x) \approx y
\]

\vspace{-2mm}
\hspace*{1.6cm}\includegraphics[width=6cm]{../../images/img04/minimization_visualization.png}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{What really matters}

\begin{itemize}
  \item Tensors + autograd are the core
  \item Loss defines \y{what is learned}
  \item Data handling controls stability
  \item {\bf\color{red}Domain knowledge remains essential}
\end{itemize}

\vspace{1mm}
AI supports decisions —  
it does not replace responsibility.

\end{column}

\end{columns}

\end{frame}
% ================================================================================
% E-AI Tutorial Slides
% Filename: lec04.tex
%
% Roland Potthast 2025/2026
% Licence: CC-BY4.0
% ================================================================================
\documentclass[aspectratio=169]{beamer}

% --- Load lecture macros --------------------------------------------------------
\input{../lec_macros.tex}
\newcommand{\LectureNumber}{Lecture 4}

% --- Document -------------------------------------------------------------------
\begin{document}

\setagendaboxforlecture{4}

\input{../lec_agenda.tex}
\input{lec04_01.tex}
\input{lec04_02.tex}
\input{lec04_03.tex}
\input{lec04_04.tex}
\input{lec04_05.tex}
\input{lec04_06.tex}
\input{lec04_07.tex}
\input{lec04_08.tex}
\input{lec04_09.tex}
\input{lec04_10.tex}
\input{lec04_11.tex}
\input{lec04_12.tex}
\input{lec04_13.tex}
\input{lec04_14.tex}
\input{lec04_15.tex}
\input{lec04_16.tex}
\input{lec04_17.tex}
\input{lec04_18.tex}
\input{lec04_19.tex}
\input{lec04_20.tex}
\input{lec04_21.tex}
\input{lec04_22.tex}
\input{lec04_23.tex}
\input{lec04_24.tex}
\input{lec04_25.tex}

% --- End Document ---------------------------------------------------------------
\end{document}
%!TEX root = lec05.tex
% ================================================================================
% Lecture 5 — Slide 01
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Neural Network Architectures — Why Structure Matters}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Key idea}

\begin{itemize}
  \item Network structure define the \y{inductive framework}
  \item Architecture encodes assumptions
  \item Learning is constrained by connectivity
\end{itemize}

\vspace{1mm}
\textbf{Same data, different models}

\begin{itemize}
  \item Feed Forward Networks
  \item Graph Neural Networks
  \item Convolutional Networks
  \item Recurrent / LSTM models
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Conceptual view}

\begin{itemize}
  \item Architecture = hypothesis space
  \item Optimizer explores this space
  \item Data selects a solution
\end{itemize}

\vspace{2mm}
\[
\mathcal{H}_{\text{model}}
\;\xrightarrow{\text{training}}\;
\hat{f}
\]

\vspace{-5mm}
\begin{eqnarray*}
\mathcal{H}_{\text{linear}} &=& \{\, f(x) = w^\top x + b \mid w,b \in \mathbb{R} \,\} \\
\mathcal{H}_{\text{FFNN}}   &=& \{\, f_\theta(x) = W_2\,\sigma(W_1 x) \,\} \\
\mathcal{H}_{\text{CNN}}    &=& \{\, f_\theta(x) = \sigma( K * x + b ) \,\}  \\
\mathcal{H}_{\text{GNN}}    &=& \{\, f_\theta(G) \mid G=(V,E,X) \,\}
\end{eqnarray*}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec05.tex
% ================================================================================
% Lecture 5 — Slide 02
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Feed Forward Neural Networks (FFNN)}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.4\textwidth}

\textbf{Basic idea}

\begin{itemize}
  \item Directed \y{acyclic} network
  \item Information flows strictly forward
  \item \y{No memory}, no recurrence
\end{itemize}

\vspace{1mm}
\textbf{Typical use cases}

\begin{itemize}
  \item Regression
  \item Classification
  \item Function approximation
\end{itemize}

\vspace{1mm}
Each layer applies a learned transformation.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.58\textwidth}

\vspace{-6mm}
\begin{center}
\includegraphics[width=\textwidth]{../../images/img05/feed_forward_network.png}
\end{center}

\vspace{-2mm}
\centering
Input $\rightarrow$ hidden layers $\rightarrow$ output

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec05.tex
% ================================================================================
% Lecture 5 — Slide 03
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{FFNN as a Mathematical Mapping}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Layer-wise computation}

\begin{itemize}
  \item Affine transformation
  \item Nonlinear activation
  \item Composition of functions
\end{itemize}

\vspace{3mm}
Each layer increases \y{expressiveness}.

\vspace{3mm}
Purely \y{data-driven} mapping.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-6mm}
\begin{eqnarray*}
x^{(0)} &=& x \\[1mm]
x^{(1)} &=& \sigma\!\left(W_1 x^{(0)} + b_1\right) \\[1mm]
x^{(2)} &=& \sigma\!\left(W_2 x^{(1)} + b_2\right) \\[1mm]
\hat{y} &=& W_3 x^{(2)} + b_3
\end{eqnarray*}

\vspace{1mm}
\hspace{1cm}$\sigma$: ReLU, tanh, sigmoid

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec05.tex
% ================================================================================
% Lecture 5 — Slide 04
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Model Capacity and Trainable Parameters}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.4\textwidth}

\textbf{What defines model capacity?}

\begin{itemize}
  \item Number of parameters
  \item Network depth
  \item Width of layers
\end{itemize}

\vspace{1mm}
Higher capacity:
\begin{itemize}
  \item Fits more complex functions
  \item Risk of overfitting
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.56\textwidth}

\textbf{Parameter counting}

\vspace{-2mm}
\begin{eqnarray*}
\text{\y{Each Layer}}(n_{\text{in}}\!\rightarrow\!n_{\text{out}}): &&
n_{\text{in}}\cdot n_{\text{out}} + n_{\text{out}} \\[1mm]
\text{Total parameters} &=& 
\sum_{\ell} \left(
n_{\ell-1} n_{\ell} + n_{\ell}
\right)
\end{eqnarray*}

\vspace{1mm}
Example (1–16–16–1):
\[
(1\!\cdot\!16+16) + (16\!\cdot\!16+16) + (16\!\cdot\!1+1) = 337
\]

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec05.tex
% ================================================================================
% Lecture 5 — Slide 05
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Why Depth Matters}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.4\textwidth}

\textbf{Shallow networks}

\begin{itemize}
  \item Few layers, many neurons
  \item Can approximate any function
  \item Often inefficient
\end{itemize}

\vspace{1mm}
Universal Approximation:
\begin{itemize}
  \item Existence result
  \item Not a statement about efficiency
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.58\textwidth}

\vspace{-6mm}
\textbf{\y{Deep networks}}

\begin{itemize}
  \item Hierarchical feature extraction
  \item Reuse of intermediate representations
  \item Fewer parameters for same accuracy
\end{itemize}

\vspace{1mm}
Compositional structure:
\begin{eqnarray*}
f(x)
&=& f_L\!\left(
      f_{L-1}\!\left(
      \dots f_1(x)
      \right)\right)
\end{eqnarray*}

\vspace{-2mm}
\begin{minipage}{5cm}
{\tiny\begin{lstlisting}
class Deep(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(1, N1),
            nn.Tanh(),
            nn.Linear(N1, N1),
            nn.Tanh(),
            nn.Linear(N1, N1),
            nn.Tanh(),
            nn.Linear(N1, 1)
        )
\end{lstlisting}}
\end{minipage}
\begin{minipage}[b]{3cm}
\raggedright
Depth encodes \y{structure}, not just \y{capacity}.
\end{minipage}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec05.tex
% ================================================================================
% Lecture 5 — Slide 6
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{FFNN as a \y{Function Approximator}}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.42\textwidth}

\vspace{-2mm}
\textbf{Problem setting}

\begin{itemize}
  \item Unknown target function $f(x)$
  \item Discrete training data available
  \item Goal: approximate $f$ using a neural network
\end{itemize}

\vspace{-1mm}
\textbf{Neural-network view}

\begin{itemize}
  \item The network defines a family of functions
  \item Parameters determine the concrete shape
  \item Training = selecting a suitable function
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.56\textwidth}

\vspace{-4mm}
\[
f(x) \;\approx\; f_\theta(x)
\]

\vspace{1mm}
\includegraphics[width=0.48\textwidth]{../../images/img05/deep_nn_function_approximation.png}
\includegraphics[width=0.48\textwidth]{../../images/img05/deep_nn_loss_curve.png}

\vspace{1mm}
\centering
Ground truth (left) vs.\ NN approximation \\
and training history (right)

\vspace{1mm}
\raggedright
\textbf{Intuition}

\begin{itemize}
  \item Each layer further shapes the function
  \item Nonlinearities enable complex forms
  \item A smooth approximation emerges step by step
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec05.tex
% ================================================================================
% Lecture 5 — Slide 7
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Computational Graph and Backpropagation}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\textbf{Forward pass}

\begin{itemize}
  \item Input propagated layer by layer
  \item Linear maps + nonlinear activations
  \item Produces model output $\hat{y}$
\end{itemize}

\vspace{1mm}
\textbf{Backward pass}

\begin{itemize}
  \item \y{Loss gradient flows backward}
  \item Chain rule applied automatically
  \item Gradients stored in parameters
\end{itemize}

\vspace{1mm}
Training adjusts parameters using these gradients.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-8mm}
\begin{minipage}[b]{2cm}
\vspace{1mm}
\centering
Computational graph of a feedforward network
\end{minipage}
\begin{minipage}{4cm}
\hfill\includegraphics[width=0.9\textwidth]{../../images/img05/ffnn_graph.png}
\end{minipage}

\vspace{-2mm}
\raggedright
\textbf{Key idea}

\begin{itemize}
  \item Graph encodes all operations
  \item Enables exact gradient computation
  \item Foundation of learning by optimization
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec05.tex
% ================================================================================
% Lecture 5 — Slide 8
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Why Graph Neural Networks?}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.4\textwidth}

\textbf{When FFNNs are not enough}

\begin{itemize}
  \item Data points are not independent
  \item Relations between entities matter
  \item Ordering is not fixed or meaningful
\end{itemize}

\vspace{1mm}
\textbf{Typical examples}

\begin{itemize}
  \item Physical grids and meshes
  \item Sensor networks
  \item Molecules, social networks
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.58\textwidth}

\vspace{-6mm}
\includegraphics[width=0.99\textwidth]{../../images/img05/gnn_graph.png}

\vspace{1mm}
\centering
Graph structure with nodes and edges

\vspace{1mm}
\raggedright
\textbf{Core idea}

\begin{itemize}
  \item Nodes exchange information
  \item Learning respects graph structure
  \item Inductive bias for relational data
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec05.tex
% ================================================================================
% Lecture 5 — Slide 9
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Basic Graph Concepts}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.4\textwidth}

\textbf{Graph definition}

\begin{itemize}
  \item Graph $G = (V,E)$
  \item Nodes $V$: entities
  \item Edges $E$: relations
\end{itemize}

\vspace{1mm}
\textbf{Node data}

\begin{itemize}
  \item Each node has features $x_i$
  \item Labels $y_i$ for supervision
  \item Features may be physical states
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.58\textwidth}

\vspace{-1cm}
\hfill\includegraphics[width=4.5cm]{../../images/img05/gnn_ikosahedral.png}

\vspace{-1cm}
\hspace*{1cm}Ikosahedral graph

\vspace{5mm}
\raggedright
\textbf{Key distinction}

\begin{itemize}
  \item Data lives on nodes
  \item Structure lives in edges
  \item Learning uses both
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec05.tex
% ================================================================================
% Lecture 5 — Slide 10
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Adjacency and \texttt{edge\_index}}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.4\textwidth}

\textbf{Adjacency matrix}

\begin{itemize}
  \item Matrix $A \in \{0,1\}^{N\times N}$
  \item $A_{ij}=1$ if nodes $i,j$ are connected
  \item Simple, but memory expensive
\end{itemize}

\vspace{1mm}
\begin{minipage}[b]{2.2cm}
$
\begin{pmatrix}
0 & 1 & 0 & 1\\
1 & 0 & 1 & 0\\
0 & 1 & 0 & 1\\
1 & 0 & 1 & 0
\end{pmatrix}
$
\end{minipage}
\begin{minipage}{3.2cm}
\includegraphics[width=3.2cm]{../../images/img05/diff_matrix_smaller_const.png}
\end{minipage}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.58\textwidth}

\vspace{-5mm}
\textbf{\texttt{edge\_index} representation}

\begin{itemize}
  \item Sparse edge list format
  \item Two rows: source and target nodes
  \item Standard in PyTorch Geometric
\end{itemize}

\vspace{1mm}
\[
\texttt{edge\_index} =
\begin{pmatrix}
0 & 1 & 1 & 2 \\
1 & 0 & 2 & 1
\end{pmatrix}
\]

\vspace{1mm}
\raggedright
\textbf{Why this matters}

\begin{itemize}
  \item Scales to large graphs
  \item Efficient message passing
  \item Natural for irregular structures
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec05.tex
% ================================================================================
% Lecture 5 — Slide 11
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{GNN Architecture Principle}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.4\textwidth}

\textbf{Key idea}

\begin{itemize}
  \item Nodes exchange information
  \item Messages flow along edges
  \item Features are updated iteratively
\end{itemize}

\vspace{1mm}
\textbf{One GNN layer}

\begin{itemize}
  \item Collect neighbor features
  \item Aggregate (sum / mean / max)
  \item Apply learnable transform
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.58\textwidth}

\vspace{-8mm}
\textbf{Generic update rule}
\begin{eqnarray*}
h_i^{(k+1)}
&=&
\sigma\!\left(
W^{(k)} \;
\sum_{j \in \mathcal{N}(i)}
h_j^{(k)}
\right)
\end{eqnarray*}

\vspace{-2mm}
\raggedright
\textbf{Interpretation}

\begin{itemize}
  \item $h_i^{(k)} \in \R^{d_{k}}$ : feature vector, node $i$ at layer $k$
  \item $W^{(k)} \in \R^{d_{k+1}\times d_{k}}$: matrix
  \item $\mathcal{N}(i)$ : neighbors of node $i$
  \item $\sigma$ : nonlinearity
\end{itemize}

\vspace{1mm}
\textbf{Consequence}

\begin{itemize}
  \item \y{Local interactions} build global structure
  \item Depth = range of information propagation
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec05.tex
% ================================================================================
% Lecture 5 — Slide 12
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{GNN Application Example — Advection on a Periodic Grid}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-2mm}
\textbf{Physical setup}

\begin{itemize}
  \item Nodes arranged on a periodic ring
  \item Each node holds a scalar field value
  \item Goal: learn one-step time evolution
\end{itemize}

\vspace{1mm}
\textbf{Learning task}

\begin{itemize}
  \item Input: field at time $t$
  \item Output: field at time $t+\Delta t$
  \item Advection-like transport process
\end{itemize}

\vspace{1mm}
Mathematically:
\[
z^{t+1} \;\approx\; f_\theta(G, z^t)
\]

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}

\vspace{-4mm}
\includegraphics[width=0.9\textwidth]{../../images/img05/gnn_test_tds_1.png}

\vspace{1mm}
\centering
Graph structure with periodic connectivity

\vspace{1mm}
\raggedright
\textbf{Why a GNN?}

\begin{itemize}
  \item Local interactions dominate dynamics
  \item Translation invariance on the ring
  \item Same update rule for all nodes
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec05.tex
% ================================================================================
% Lecture 5 — Slide 13
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{GNN Results — Learning Advection Dynamics}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.4\textwidth}

\textbf{Training behaviour}

\begin{itemize}
  \item Loss decreases steadily
  \item Stable convergence for train and test
  \item No explicit physics encoded
\end{itemize}

\vspace{1mm}
\textbf{What is learned?}

\begin{itemize}
  \item Local transport along edges
  \item Approximate shift of the field
  \item Graph-based discretization of dynamics
\end{itemize}

\vspace{1mm}
Interpretation:
\[
\text{message passing} \;\approx\; \text{numerical stencil}
\]

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.58\textwidth}

\vspace{-2mm}
\includegraphics[width=0.99\textwidth]{../../images/img05/gnn_loss_curve.png}

\vspace{1mm}
\centering
Training and test loss over epochs

\vspace{1mm}
\raggedright
\textbf{Limitations}

\begin{itemize}
  \item Short-term prediction only
  \item Error accumulation over time
  \item Stability not guaranteed
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec05.tex
% ================================================================================
% Lecture 5 — Slide 14
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Why Convolutional Neural Networks?}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.4\textwidth}

\textbf{Key idea}

\begin{itemize}
  \item Exploit \y{local structure}
  \item Same operation everywhere
  \item Strong inductive bias
\end{itemize}

\vspace{1mm}
\textbf{Typical data}

\begin{itemize}
  \item Images (2D grids)
  \item Time series (1D signals)
  \item Physical fields on grids
\end{itemize}

\vspace{1mm}
CNNs assume:
\[
\text{locality} + \text{translation invariance}
\]

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.58\textwidth}

\vspace{-2mm}
\textbf{Convolution instead of full connectivity}

\begin{itemize}
  \item Small kernel slides over input
  \item Shared weights across positions
  \item Far fewer parameters than FFNNs
\end{itemize}

\vspace{-1mm}
Mathematically (1D):
\begin{eqnarray*}
y_i &=& \sum_{k=-K}^{K} w_k \, x_{i+k}
\end{eqnarray*}

\vspace{-2mm}
Interpretation:
\begin{itemize}
  \item Learn local patterns
  \item \y{Detect edges, waves, peaks}
  \item Build hierarchy via depth
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec05.tex
% ================================================================================
% Lecture 5 — Slide 15
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Example Setup: \y{Function Classification}}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.4\textwidth}

\textbf{Goal}

\begin{itemize}
  \item Input: sampled 1D function
  \item Output: function class
\end{itemize}

\vspace{1mm}
\textbf{Classes:}
\begin{itemize}
  \item Sine-like
  \item Gaussian
  \item Polynomial
\end{itemize}

\vspace{1mm}
\textbf{Samples:}
\begin{itemize}
  \item Same grid
  \item Different shape
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.58\textwidth}


\vspace{1mm}
\raggedright
\textbf{CNN sees:}
\begin{itemize}
  \item Local patterns
  \item Overall structure
\end{itemize}

\vspace{2mm}
\hspace*{-2cm}\includegraphics[width=10cm]{../../images/img05/cnn_data_samples_selected.png}

\vspace{1mm}
\centering
Example input functions (with noise)

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec05.tex
% ================================================================================
% Lecture 5 — Slide 17
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{CNN Structure for Function Classification}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.3\textwidth}

\textbf{Network structure}

\begin{itemize}
  \item 1D convolutions for local patterns
  \item Nonlinear feature extraction
  \item Fully connected classifier
\end{itemize}

{\footnotesize\begin{lstlisting}
Input:   (B, 1, 50)
Conv1:   (B, 16, 50)
Conv2:   (B, 32, 50)
Flatten: (B, 1600)
FC:      (B, 4)
\end{lstlisting}}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.75\textwidth}

\vspace{-4mm}
\begin{codeonly}{CNN model definition}
class FunctionClassifierCNN(nn.Module):
  def __init__(self):
     super().__init__()
     self.conv1 = nn.Conv1d(1, 16,5, padding=2)
     self.conv2 = nn.Conv1d(16,32,5, padding=2)
     self.fc1   = nn.Linear(32*50, 128)
     self.fc2   = nn.Linear(128, 4)

  def forward(self, x):
     x = torch.relu(self.conv1(x))
     x = torch.relu(self.conv2(x))
     x = x.view(x.size(0), -1)
     x = torch.relu(self.fc1(x))
     return self.fc2(x)
\end{codeonly}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec05.tex
% ================================================================================
% Lecture 5 — Slide 17
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Training the CNN}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.4\textwidth}

\textbf{Training step}

\begin{itemize}
  \item Forward pass
  \item Compute classification loss
  \item Backpropagate gradients
\end{itemize}

\vspace{1mm}
\textbf{Loss \& optimizer}

\begin{itemize}
  \item Cross-entropy for classes
  \item Adam optimizer
\end{itemize}

{\tiny\begin{lstlisting}
Loss: compares logits vs. labels
Grad: flows through conv + FC
Update: adjusts all weights
\end{lstlisting}}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.65\textwidth}

\vspace{-11mm}
\begin{codeonly}{CNN training loop}
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(
    model.parameters(), lr=1e-3)

for epoch in range(num_epochs):
    for xb, yb in train_loader:
        xb = xb.to(device) 
        yb = yb.to(device)
        
        optimizer.zero_grad()
        logits = model(xb)
        loss = criterion(logits, yb)
        loss.backward()
        optimizer.step()
\end{codeonly}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec05.tex
% ================================================================================
% Lecture 5 — Slide 18
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Prediction: Function Classification}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.35\textwidth}

\textbf{Inference mode}

\begin{itemize}
  \item No gradients
  \item Fixed trained weights
  \item Forward pass only
\end{itemize}

\vspace{1mm}
\textbf{Classification}

\begin{itemize}
  \item Output: class logits
  \item Argmax selects class
\end{itemize}

{\tiny\begin{lstlisting}
logits  -> scores per class
argmax  -> predicted label
\end{lstlisting}}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.7\textwidth}

\vspace{-4mm}
\begin{codeonly}{CNN prediction}
model.eval()

with torch.no_grad():
    logits = model(X_test.to(device))
    preds  = torch.argmax(logits, dim=1)

accuracy = (preds == y_test.to(device)).float().mean()
print("Accuracy:", accuracy.item())
\end{codeonly}

\vspace{1mm}
Prediction result:
\begin{itemize}
  \item Each function $\rightarrow$ class
  \item Robust to moderate noise
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec05.tex
% ================================================================================
% Lecture 5 — Slide 19
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{CNN Predictions on Test Data}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.38\textwidth}

\textbf{What is shown?}

\begin{itemize}
  \item Unseen test functions: new samples from random distribution
  \item Higher noise than training
\end{itemize}

\vspace{1mm}
\textbf{Color coding}

\begin{itemize}
  \item Blue: correct classification
  \item Red: misclassification
\end{itemize}

\vspace{1mm}
Interpretation:
\begin{itemize}
  \item CNN recognizes shape
  \item Errors near ambiguous cases
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.60\textwidth}

\vspace{-2mm}
\includegraphics[width=0.99\textwidth]{../../images/img05/cnn_test_predictions.png}

\vspace{1mm}
\centering
Predicted vs. true function classes

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec05.tex
% ================================================================================
% Lecture 5 — Slide 20
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Why LSTMs for Time Series and Anomalies?}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.40\textwidth}

\textbf{Problem setting}

\begin{itemize}
  \item Sequential sensor data
  \item \y{Temporal correlations}
  \item Deviations over time
\end{itemize}

\vspace{1mm}
\textbf{Why not FFNN / CNN?}

\begin{itemize}
  \item No explicit memory
  \item Limited temporal context
\end{itemize}

\vspace{1mm}
\textbf{Key idea:}

anomaly = temporal \\
\hspace{2cm} inconsistency

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.58\textwidth}

\vspace{-5mm}
\includegraphics[width=0.95\textwidth]{../../images/img05/lstm_graph.pdf}

\vspace{-1mm}
\raggedright
LSTM provides:
\begin{itemize}
  \item \y{Explicit memory state}
  \item Controlled information flow
  \item Long-term dependency modeling
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec05.tex
% ================================================================================
% Lecture 5 — Slide 21
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{LSTM Cell: Gated Memory Equations}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.40\textwidth}

\textbf{State variables}

\begin{itemize}
  \item \y{Cell state} $c_t$: long-term memory
  \item \y{Hidden state} $h_t$: exposed state
\end{itemize}

\vspace{1mm}
\textbf{Gate intuition}

\begin{itemize}
  \item Forget: scale past memory
  \item Input: add new information
  \item Output: control exposure
\end{itemize}

\vspace{1mm}
Key property:
\begin{itemize}
  \item Additive update of $c_t$
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.58\textwidth}

\vspace{-12mm}
\begin{eqnarray*}
f_t &=& \sigma(W_f x_t + U_f h_{t-1} + b_f) \\[-1mm]
i_t &=& \sigma(W_i x_t + U_i h_{t-1} + b_i) \\[-1mm]
\tilde c_t &=& \tanh(W_c x_t + U_c h_{t-1} + b_c) \\[-1mm]
c_t &=& f_t \odot c_{t-1} + i_t \odot \tilde c_t \\[-1mm]
o_t &=& \sigma(W_o x_t + U_o h_{t-1} + b_o) \\[-1mm]
h_t &=& o_t \odot \tanh(c_t)
\end{eqnarray*}

\vspace{-2mm}
{\footnotesize
\begin{itemize}
  \item $x_t \in \mathbb{R}^m$ : temporal input at time $t$
  \item $h_t \in \mathbb{R}^n$ : hidden state
  \item $c_t \in \mathbb{R}^n$ : cell state
  \item $f_t, i_t, o_t$ : gates
  \item $\tilde c_t$ : candidate cell update
  \item $W_\ast, U_\ast, b_\ast$ : \y{learnable parameters}
\end{itemize}
}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec05.tex
% ================================================================================
% Lecture 5 — Slide 21b
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{From LSTM States to Reconstruction Error}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.42\textwidth}

\textbf{What goes in}

\begin{itemize}
  \item Input sequence $x_{1:T}$
  \item One value per time step
\end{itemize}

\vspace{1mm}
\textbf{What the LSTM does}

\begin{itemize}
  \item Updates $(h_t, c_t)$ sequentially
  \item Encodes temporal structure
\end{itemize}

\vspace{1mm}
\textbf{What comes out}

\begin{itemize}
  \item Hidden states $h_t$
  \item Latent temporal representation
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.56\textwidth}

\vspace{-2mm}
\textbf{Reconstruction step}

\[
\hat{x}_t = W_y h_t + b_y
\]

\vspace{1mm}
\textbf{Training objective}

\[
\mathcal{L}
= \frac{1}{T} \sum_{t=1}^T
\left\| x_t - \hat{x}_t \right\|^2
\]

\vspace{1mm}
\textbf{Anomaly detection}

\begin{itemize}
  \item Low error: normal sequence
  \item High error: anomalous sequence
\end{itemize}

\vspace{1mm}
\raggedright
$W_y, b_y$ learned jointly with LSTM weights

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec05.tex
% ================================================================================
% Lecture 5 — Slide 22
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{LSTM Autoencoder for Anomaly Detection}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.40\textwidth}

\textbf{Autoencoder principle}

\begin{itemize}
  \item Encode normal behaviour
  \item Reconstruct input sequence
\end{itemize}

\vspace{1mm}
\textbf{Anomaly criterion}

\begin{itemize}
  \item Large reconstruction error
  \item Rare under normal dynamics
\end{itemize}

\vspace{1mm}
Key assumption:
\[
\text{normal} \Rightarrow \text{low error}
\]

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.58\textwidth}

\vspace{-2mm}
\includegraphics[width=0.95\textwidth]{../../images/img05/lstm_sensor_data_samples.png}

\vspace{1mm}
\centering
Normal vs. anomalous sensor sequences

\vspace{3mm}
\raggedright
Model learns:
\begin{itemize}
  \item \y{Typical temporal patterns}
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec05.tex
% ================================================================================
% Lecture 5 — Slide 23
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Coding the LSTM Autoencoder}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.25\textwidth}

\textbf{Model structure}

\begin{itemize}
  \item Encoder LSTM
  \item Decoder LSTM
  \item Linear reconstruction
\end{itemize}

\vspace{0mm}
\textbf{Data flow:}
\begin{itemize}
  \item Sequence $\rightarrow$ hidden state
  \item Hidden state $\rightarrow$ sequence
\end{itemize}

\vspace{-1mm}
{\tiny\begin{lstlisting}
Input:  (B, T, 1)
Hidden: (L, B, H)
Output: (B, T, 1)
\end{lstlisting}}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.75\textwidth}

\vspace{-4mm}
\begin{codeonly}{LSTM autoencoder (PyTorch)}
class LSTMAutoencoder(nn.Module):
  def __init__(self, hidden_dim=32, layers=2):
    super().__init__()
    self.encoder = nn.LSTM(
      1, hidden_dim, layers, batch_first=True)
    self.decoder = nn.LSTM(
      1, hidden_dim, layers, batch_first=True)
    self.out = nn.Linear(hidden_dim, 1)

  def forward(self, x):
    _, (h, c) = self.encoder(x)
    z = torch.zeros_like(x)
    y, _ = self.decoder(z, (h, c))
    return self.out(y)
\end{codeonly}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec05.tex
% ================================================================================
% Lecture 5 — Slide 24
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Detected Anomalies in Sensor Data}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.38\textwidth}

\textbf{What is shown?}

\begin{itemize}
  \item Unseen test sequences
  \item Reconstruction vs. input
\end{itemize}

\vspace{1mm}
\textbf{Color coding}

\begin{itemize}
  \item Blue: normal
  \item Red: anomaly
\end{itemize}

\vspace{1mm}
Interpretation:
\begin{itemize}
  \item Model flags temporal inconsistency
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.60\textwidth}

\vspace{-2mm}
\includegraphics[width=0.99\textwidth]{../../images/img05/lstm_anomaly_detection_samples_selected.png}

\vspace{1mm}
\centering
Original (solid) vs. reconstructed (dashed)

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec05.tex
% ================================================================================
% Lecture 5 — Slide 26
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Neural Network Architectures — Chapter Summary}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Architectures covered}

\begin{itemize}
  \item \y{FFNN}: global function approximation
  \item \y{GNN}: interactions on graphs
  \item \y{CNN}: local pattern extraction
  \item \y{LSTM}: temporal dependencies
\end{itemize}

\vspace{1mm}
\textbf{Inductive bias / framework:}
\begin{itemize}
  \item {\color{red}Structure encoded in connectivity}
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Tasks demonstrated}

\begin{itemize}
  \item FFNN: \y{regression}, classification
  \item GNN: \y{transport} and dynamics
  \item CNN: function \y{classification}
  \item LSTM: \y{anomaly detection}
\end{itemize}

\vspace{1mm}
\textbf{Core message:}
\begin{itemize}
  \item Architecture must match data structure
  \item {\color{red}No universally optimal network}
\end{itemize}

\end{column}

\end{columns}

\end{frame}
% ================================================================================
% E-AI Tutorial Slides
% Filename: lec05.tex
%
% Roland Potthast 2025/2026
% Licence: CC-BY4.0
% ================================================================================
\documentclass[aspectratio=169]{beamer}

% --- Load lecture macros --------------------------------------------------------
\input{../lec_macros.tex}
\newcommand{\LectureNumber}{Lecture 5}

% --- Document -------------------------------------------------------------------
\begin{document}

\setagendaboxforlecture{5}

\input{../lec_agenda.tex}
\input{lec05_01.tex}
\input{lec05_02.tex}
\input{lec05_03.tex}
\input{lec05_04.tex}
\input{lec05_05.tex}
\input{lec05_06.tex}
\input{lec05_07.tex}
\input{lec05_08.tex}
\input{lec05_09.tex}
\input{lec05_10.tex}
\input{lec05_11.tex}
\input{lec05_12.tex}
\input{lec05_13.tex}
\input{lec05_14.tex}
\input{lec05_15.tex}
\input{lec05_16.tex}
\input{lec05_17.tex}
\input{lec05_18.tex}
\input{lec05_19.tex}
\input{lec05_20.tex}
\input{lec05_21.tex}
\input{lec05_22.tex}
\input{lec05_23.tex}
\input{lec05_24.tex}
\input{lec05_25.tex}
\input{lec05_26.tex}

% --- End Document ---------------------------------------------------------------
\end{document}
%!TEX root = lec06.tex
% ================================================================================
% Lecture 6 — Slide 1
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Why Large Language Models?}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-1mm}
\textbf{Traditional NLP}

\begin{itemize}
  \item Separate models for each task
  \item Feature engineering required
  \item Limited transfer between tasks
\end{itemize}

\vspace{1mm}
\textbf{Examples}

\begin{itemize}
  \item Translation
  \item Classification
  \item Question answering
\end{itemize}

\vspace{0mm}
\centering
{\footnotesize
LLMs \y{unify} understanding, generation, and reasoning in a single sequence model.
}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}

\vspace{-4mm}
\textbf{Large Language Models}

\begin{itemize}
  \item One model, many tasks
  \item \y{Learns representations from data}
  \item Includes Sub-Word \rtext{Tokenization}
  \item General-purpose language intelligence
\end{itemize}

\vspace{1mm}
\textbf{Key idea}

\begin{itemize}
  \item Language as a \emph{sequence prediction problem}
  \item Everything reduced to:
\end{itemize}

\vspace{-3mm}
\[
\text{tokens}_{\text{in}} \;\longrightarrow\; \text{tokens}_{\text{out}}
\]

\end{column}

\end{columns}

\vspace{0mm}
\[
\{\rtext{The},\rtext{dog},\rtext{chas},\rtext{ed},\rtext{the},\rtext{cat},\rtext{.}\}
\;\;\longrightarrow\;\;
\{104,\,2871,\,9123,\,214,\,201,\,4421,\,13\}
\]

\end{frame}
%!TEX root = lec06.tex
% ================================================================================
% Lecture 6 — Slide 2
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{LLMs as Sequence-to-Sequence Machines}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-1mm}
\textbf{Core abstraction}

\begin{itemize}
  \item Input: sequence of tokens
  \item Output: sequence of tokens
  \item \y{Tokens} represent words or subwords
\end{itemize}

\vspace{1mm}
\textbf{Mathematical view}

\[
(x_1, \dots, x_n)
\;\longrightarrow\;
(y_1, \dots, y_m)
\]

\vspace{1mm}
\begin{itemize}
  \item Variable-length input
  \item Variable-length output
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}

\vspace{-1mm}
\textbf{Next-token prediction}

\begin{itemize}
  \item Output generated one token at a time
  \item Each step predicts a probability distribution
\end{itemize}

\vspace{-1mm}
\[
p(y_t \mid x_{1:n}, y_{1:t-1})
\]

\vspace{1mm}
\textbf{Consequences}

\begin{itemize}
  \item Same model for all tasks
  \item Tasks differ only by input prompt
  \item No task-specific architecture needed
\end{itemize}

\end{column}

\end{columns}

\vspace{3mm}
\centering
{\footnotesize
LLMs reduce language understanding and generation to \y{probabilistic sequence modeling.}
}

\end{frame}
%!TEX root = lec06.tex
% ================================================================================
% Lecture 6 — Slide 3
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{From Token IDs to Embedding Vectors}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-1mm}
\textbf{What the model actually sees}

\begin{itemize}
  \item Tokens are integers
  \item No words, no strings, no grammar
\end{itemize}

\vspace{1mm}
Example:
\[
\{104,\,2871,\,9123,\,214,\,201,\,4421,\,13\}
\]

\vspace{1mm}
\textbf{Problem}

\begin{itemize}
  \item Integers have no semantic meaning
  \item Distance between IDs is arbitrary
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}

\vspace{-1mm}
\textbf{Solution: embeddings}

Each token ID $i$ is mapped to a vector:
\[
i \;\longrightarrow\; e_i \in \mathbb{R}^{d_{\text{model}}}
\]

\vspace{-2mm}
\textbf{Embedding matrix}

\vspace{-2mm}
\[
E \in \mathbb{R}^{V \times d_{\text{model}}}
\]

\begin{itemize}
  \item $V$: \y{vocabulary size} (number of distinct tokens)
  \item $d_{\text{model}}$: \y{embedding dimension}
  \item $E_i = e_i$: embedding of token $i$
\end{itemize}

\end{column}

\end{columns}

\vspace{3mm}
\centering
{\footnotesize
Meaning is not stored in tokens, but in their \y{learned vector representations.}
}

\end{frame}
%!TEX root = lec06.tex
% ================================================================================
% Lecture 6 — Slide 4
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Why Sequence Order Matters}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-1mm}
\textbf{Problem with embeddings alone}

\begin{itemize}
  \item Embeddings encode token meaning
  \item But \y{ignore position in the sequence}
\end{itemize}

\vspace{1mm}
Example:
\[
\text{dog bites man}
\quad\neq\quad
\text{man bites dog}
\]

\vspace{1mm}
Yet both contain the same tokens.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}

\vspace{-1mm}
\textbf{Key observation}

\begin{itemize}
  \item Transformers process tokens \y{in parallel}
  \item No inherent notion of order
\end{itemize}

\vspace{1mm}
\textbf{Consequence}

\begin{itemize}
  \item Sequence order must be added explicitly
  \item Otherwise:
\end{itemize}
\[
(x_1, x_2, x_3)
\;\equiv\;
(x_3, x_1, x_2)
\]

\vspace{1mm}
\centering
\y{Order information is not optional.}

\end{column}

\end{columns}

\vspace{2mm}
\centering
{\footnotesize
Transformers require an \rtext{explicit mechanism to encode token positions}.
}

\end{frame}
%!TEX root = lec06.tex
% ================================================================================
% Lecture 6 — Slide 5
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Positional Encoding}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-1mm}
\textbf{Goal}

\begin{itemize}
  \item Inject \y{order information} into embeddings
  \item Keep full parallelism
\end{itemize}

\vspace{1mm}
\textbf{Idea}

\begin{itemize}
  \item Assign a position-dependent vector
  \item Add it to the token embedding
\end{itemize}

\vspace{1mm}
\[
x_i \;=\; e_i + p_i
\]

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}

\vspace{-1mm}
\textbf{Positional encoding matrix}

\[
P \in \mathbb{R}^{n \times d_{\text{model}}}
\]

\begin{itemize}
  \item $n$: sequence length
  \item $p_i$: encoding of position $i$
\end{itemize}

\vspace{1mm}
\textbf{Key properties}

\begin{itemize}
  \item Same dimension as embeddings
  \item Fixed (sinusoidal) or learned
  \item Enables attention to use order
\end{itemize}

\end{column}

\end{columns}

\vspace{2mm}
\centering
{\footnotesize
Positional encodings turn a set of tokens into an ordered sequence.
}

\end{frame}
%!TEX root = lec06.tex
% ================================================================================
% Lecture 6 — Slide 6
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Sinusoidal Positional Encoding}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-1mm}
\textbf{Sinusoidal construction}

\begin{itemize}
  \item Fixed, deterministic encoding
  \item Different frequencies per dimension
\end{itemize}

For position $i$ and dimension $j$:

\vspace{-4mm}
\[
p_{i,2j}   = \sin\!\left(\frac{i}{10000^{2j/d_{\text{model}}}}\right)
\]
\[
p_{i,2j+1} = \cos\!\left(\frac{i}{10000^{2j/d_{\text{model}}}}\right)
\]

\vspace{1mm}
\begin{itemize}
  \item Smooth variation with position
  \item Relative distances are encoded
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}

\vspace{-1mm}
\textbf{Why sinusoids?}

\begin{itemize}
  \item Works for arbitrary sequence lengths
  \item No additional parameters
  \item Relative positions can be inferred
\end{itemize}

\vspace{1mm}
\textbf{Why \emph{add}, not concatenate?}

{\scriptsize
\begin{itemize}
  \item Addition keeps dimension at $d_{\text{model}}$
  \item Attention projections expect fixed size
  \item Concatenation doubles dimension
  \item Would require retraining all layers
\end{itemize}
}

\vspace{1mm}
\y{Addition preserves efficiency} 
\y{and model structure.}

\end{column}

\end{columns}

\vspace{1mm}
\centering
{\footnotesize
Positional information is injected without changing model dimensionality.
}

\end{frame}
%!TEX root = lec06.tex
% ================================================================================
% Lecture 6 — Slide 7
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Self-Attention: Core Idea}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-1mm}
\textbf{Key mechanism}

\begin{itemize}
  \item Each token can \y{look at all other tokens}
  \item Importance is computed dynamically
\end{itemize}

\vspace{1mm}
\textbf{Contextual representation}

\begin{itemize}
  \item Token meaning depends on context
  \item Same word, different role
\end{itemize}

\vspace{1mm}
Example:
\[
\text{``The dog chased the cat.''}
\]

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}

\vspace{-10mm}
\textbf{What attention does}

\begin{itemize}
  \item Builds a \y{weighted combination} of tokens
  \item Different focus for each position
\end{itemize}

\vspace{1mm}
For token $i$:
\[
x_i \;\longrightarrow\; 
\sum_j w_{ij}\, x_j
\]

\vspace{-2mm}
\textbf{Why this matters}

\begin{itemize}
  \item Long-range dependencies
  \item No fixed context window
  \item Fully parallel computation
\end{itemize}

\end{column}

\end{columns}

\vspace{4mm}
\centering
{\footnotesize
\rtext{Self-attention allows each token to decide which other tokens matter.}
}

\end{frame}
%!TEX root = lec06.tex
% ================================================================================
% Lecture 6 — Slide 8
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Queries, Keys, and Values — Intuition}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-1mm}
\textbf{Three roles per token}

Each token embedding is projected into:
\begin{itemize}
  \item \y{Query} ($Q$): what am I looking for?
  \item \y{Key} ($K$): what do I offer?
  \item \y{Value} ($V$): what information do I pass on?
\end{itemize}

\vspace{1mm}
All three are learned linear projections.

\vspace{-6mm}
\begin{eqnarray*}
& Q = X W^Q, K = X W^K, V = X W^V
\end{eqnarray*}

\vspace{-5mm}
{\tiny
\begin{eqnarray*}
& X \in \mathbb{R}^{n \times d_{\text{model}}},  
W^Q, W^K \in \mathbb{R}^{d_{\text{model}} \times d_k}, \\ 
& W^V \in \mathbb{R}^{d_{\text{model}} \times d_v}, 
Q, K \in \mathbb{R}^{n \times d_k}, V \in \mathbb{R}^{n \times d_v}
\end{eqnarray*}}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.45\textwidth}

\vspace{-9mm}
\textbf{Attention mechanism}

\begin{itemize}
  \item Compare queries with keys
  \item Compute relevance scores
  \item Use scores to weight values
\end{itemize}

\vspace{1mm}
Conceptually:
\[
\text{\y{attention}}(i,j)
\;\sim\;
Q_i \cdot K_j
\]

\vspace{1mm}
\textbf{Interpretation}

\begin{itemize}
  \item Tokens ask questions (queries)
  \item Other tokens answer (values)
  \item Keys decide relevance
\end{itemize}

\end{column}

\end{columns}

\vspace{3mm}
\centering
{\footnotesize
\rtext{Queries select, keys match, values contribute.}
}

\end{frame}
%!TEX root = lec06.tex
% ================================================================================
% Lecture 6 — Slide 9
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Scaled Dot-Product Attention}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-1mm}
\textbf{Attention scores}

\begin{itemize}
  \item Compare each query with all keys
  \item Dot product measures similarity
\end{itemize}

\vspace{1mm}
\[
S = Q K^{T}
\quad\in\quad \mathbb{R}^{n \times n}
\]

\vspace{1mm}
Each row: relevance of one token to all others.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}

\vspace{-9mm}
\textbf{Scaling and normalization}

\begin{itemize}
  \item Scale by $\sqrt{d_k}$ for numerical stability
  \item Apply softmax row-wise
\end{itemize}

\vspace{-2mm}
\[
A = \operatorname{softmax}
\!\left(
\frac{QK^T}{\sqrt{d_k}}
\right)
\]

\vspace{1mm}
\textbf{Weighted aggregation}

\[
Z = A V
\]

\begin{itemize}
  \item $Z \in \mathbb{R}^{n \times d_v}$
  \item Each token mixes information from others
\end{itemize}

\end{column}

\end{columns}

\vspace{3mm}
\centering
{\footnotesize
Attention computes a \y{context-dependent weighted sum} of values.
}

\end{frame}
%!TEX root = lec06.tex
% ================================================================================
% Lecture 6 — Slide 10
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Why Scale by $\sqrt{d_k}$?}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.4\textwidth}

\vspace{-1mm}
\textbf{Problem without scaling}

\begin{itemize}
  \item Dot products grow with dimension
  \item Large values enter softmax
  \item Gradients become unstable
\end{itemize}

\vspace{1mm}
For random vectors:
\[
Q_i \cdot K_j \sim \mathcal{O}(d_k)
\]

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.56\textwidth}

\vspace{-9mm}
\textbf{Effect of scaling}

\begin{itemize}
  \item Divide by $\sqrt{d_k}$
  \item Keeps variance roughly constant
\end{itemize}

\vspace{1mm}
\[
\frac{QK^T}{\sqrt{d_k}}
\]

\vspace{1mm}
\textbf{Result}

\begin{itemize}
  \item Softmax stays sensitive
  \item Stable gradients during training
  \item Faster convergence
\end{itemize}

\vspace{1mm}
\centering
\y{Scaling is a numerical necessity, not a heuristic.}

\end{column}

\end{columns}

\vspace{2mm}
\centering
{\footnotesize
The scaling factor prevents softmax saturation in high dimensions.
}

\end{frame}
%!TEX root = lec06.tex
% ================================================================================
% Lecture 6 — Slide 11
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Attention Matrix Interpretation}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-1mm}
\textbf{Attention matrix}

\vspace{-4mm}
\[
A = \operatorname{softmax}
\!\left(
\frac{QK^T}{\sqrt{d_k}}
\right)
\quad\in\quad \mathbb{R}^{n \times n}
\]

\vspace{1mm}
\begin{itemize}
  \item Row $i$: attention of token $i$
  \item Columns: which tokens are attended to
\end{itemize}

\vspace{1mm}
\y{\bf Softmax:} Each row sums to 1: 
\[
\sum_j A_{ij} = 1
\]

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}

\vspace{-6mm}
\textbf{Interpretation}

\begin{itemize}
  \item Soft, learned dependency graph
  \item Fully connected
  \item Directional (row-wise)
\end{itemize}

\vspace{1mm}
\textbf{Key insight}

\begin{itemize}
  \item No fixed neighborhood
  \item No predefined structure
  \item Recomputed at every layer
\end{itemize}

\vspace{1mm}
\centering
\y{Attention learns which tokens influence}
\y{each other.}

\end{column}

\end{columns}

\vspace{2mm}
\centering
{\footnotesize
\rtext{Self-attention dynamically constructs a weighted interaction graph.}
}

\end{frame}
%!TEX root = lec06.tex
% ================================================================================
% Lecture 6 — Slide 12
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Why Multi-Head Attention?}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-1mm}
\textbf{Limitation of single attention}

\begin{itemize}
  \item One attention matrix per layer
  \item Focuses on one similarity notion
  \item Mixes all information at once
\end{itemize}

\vspace{1mm}
Example needs:
\begin{itemize}
  \item Syntax (subject–verb)
  \item Semantics (actor–object)
  \item Position and locality
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}

\vspace{-8mm}
\textbf{Multi-head idea}

\begin{itemize}
  \item Run attention \y{in parallel}
  \item Different subspaces
  \item Different focus patterns
\end{itemize}

\vspace{1mm}
Each head learns:
\[
\text{its own } Q_i,\; K_i,\; V_i
\]

\vspace{1mm}
\textbf{Benefit}

\begin{itemize}
  \item Richer representations
  \item Multiple relationships at once
  \item Improved expressiveness
\end{itemize}

\end{column}

\end{columns}

\vspace{2mm}
\centering
{\footnotesize
\rtext{Multi-head attention lets the model attend to different aspects simultaneously.}
}

\end{frame}
%!TEX root = lec06.tex
% ================================================================================
% Lecture 6 — Slide 13
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Multi-Head Attention: Formulation}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-1mm}
\textbf{Per-head projections}

For each head $h = 1,\dots,H$:
\begin{eqnarray*}
Q^{(h)} & = & X W^{Q^{(h)}}, \quad
K^{(h)} = X W^{K^{(h)}}, \\
V^{(h)} & = & X W^{V^{(h)}}
\end{eqnarray*}

\vspace{1mm}
Each head applies scaled dot-product \y{attention}:
\[
Z^{(h)} =
\operatorname{softmax}
\!\left(
\frac{Q^{(h)} K^{(h)T}}{\sqrt{d_k}}
\right)
V^{(h)}
\]

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}

\vspace{-8mm}
\textbf{Concatenation and projection}

\[
Z =
\operatorname{Concat}
\big(
Z^{(1)}, \dots, Z^{(H)}
\big)
\]

\vspace{1mm}
Final linear projection:
\[
\operatorname{MultiHead}(X)
=
Z W^O
\]

\vspace{-2mm}
\begin{itemize}
  \item $H$: number of heads
  \item $W^O$: output projection
  \item Output in $\mathbb{R}^{n \times d_{\text{model}}}$
\end{itemize}

\vspace{1mm}
\y{Multiple attention views are merged}
\y{into one representation.}

\end{column}

\end{columns}

\vspace{2mm}
\centering
{\footnotesize
\rtext{Multi-head attention preserves model dimension while increasing expressiveness.}
}

\end{frame}
%!TEX root = lec06.tex
% ================================================================================
% Lecture 6 — Slide 14
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Position-Wise Feedforward Network (FFN)}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.54\textwidth}

\begin{itemize}
  \item Inside each Transformer block
  \item After self-attention
\end{itemize}

\vspace{1mm}
\textbf{What attention does not do}

\begin{itemize}
  \item Computes weighted averages
  \item Linear combination of values
  \item No feature-wise nonlinearity
\end{itemize}

\vspace{1mm}
\textbf{Why the FFN is needed}

\begin{itemize}
  \item Adds nonlinearity, Recombines features
  \item Increases model expressiveness
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.43\textwidth}

\vspace{-8mm}
\textbf{Feedforward mapping}

For one token vector $x \in \mathbb{R}^{d_{\text{model}}}$:
\[
\operatorname{FFN}(x)
=
\sigma(x W_1 + b_1)\, W_2 + b_2
\]

\vspace{-2mm}
\begin{itemize}
  \item $\sigma(\cdot)$: ReLU or GELU
  \item $W_1 \in \mathbb{R}^{d_{\text{model}} \times d_{\text{ff}}}$
  \item $W_2 \in \mathbb{R}^{d_{\text{ff}} \times d_{\text{model}}}$
\end{itemize}

\vspace{1mm}
Applied to all tokens:

\vspace{-3mm}
\[
Z_{\text{ff}} \in \mathbb{R}^{n \times d_{\text{model}}}
\]

\vspace{-1mm}
{\footnotesize
Same FFN parameters are shared across all positions.
}

\end{column}

\end{columns}

\vspace{2mm}
\centering
\y{Attention mixes tokens; the FFN transforms token features.}

\end{frame}
%!TEX root = lec06.tex
% ================================================================================
% Lecture 6 — Slide 15
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Residual Addition, Layer Normalization}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-1mm}
\textbf{Output of multi-head attention}

\vspace{1mm}
Multi-head attention output (after $W^O$):
\[
Z_{\text{att}}
=
\operatorname{MultiHead}(X)
\in
\mathbb{R}^{n \times d_{\text{model}}}
\]

\vspace{-1mm}
\textbf{Residual connection}

\[
\tilde X
=
X + Z_{\text{att}}
\]

\vspace{-1mm}
\begin{itemize}
  \item Preserves original information
  \item Requires matching dimensions
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.54\textwidth}

\vspace{-9mm}
\quad \textbf{Layer normalization}

Applied \y{after} the residual sum, per token $i$:

\vspace{-6mm}
\begin{eqnarray*}
\mu_i
& = & 
\frac{1}{d_{\text{model}}}
\sum_{k=1}^{d_{\text{model}}}
\tilde X_{ik}
\\
\sigma_i^2
& = & 
\frac{1}{d_{\text{model}}}
\sum_{k=1}^{d_{\text{model}}}
(\tilde X_{ik} - \mu_i)^2
\\
Z_{ik}
& = & 
\gamma_k
\frac{\tilde X_{ik} - \mu_i}{\sqrt{\sigma_i^2 + \varepsilon}}
+ \beta_k
\end{eqnarray*}

\vspace{-4mm}
\begin{itemize}
  \item Normalization across \y{feature dimension}
  \item $\gamma_k, \beta_k$: learned parameters
  \item No mixing between tokens
\end{itemize}

\end{column}

\end{columns}

\vspace{2mm}
\centering
{\footnotesize
\rtext{Residual connections preserve information; LayerNorm stabilizes the representation.}
}

\end{frame}
%!TEX root = lec06.tex
% ================================================================================
% Lecture 6 — Slide 16
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Output Projection to Vocabulary}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-1mm}
\textbf{Final Transformer output}

After all Transformer blocks:
\[
Z \in \mathbb{R}^{n \times d_{\text{model}}}
\]

\vspace{1mm}
Each row corresponds to:
\begin{itemize}
  \item One token position
  \item A contextualized representation
\end{itemize}

\vspace{1mm}
\textbf{Goal}

\begin{itemize}
  \item Predict the next token
  \item From a fixed vocabulary
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}

\vspace{-9mm}
\textbf{Linear projection to logits}

\[
Z_{\text{logits}}
=
Z W_{\text{out}} + b_{\text{out}}
\]

\begin{itemize}
  \item $W_{\text{out}} \in \mathbb{R}^{d_{\text{model}} \times V}$
  \item $b_{\text{out}} \in \mathbb{R}^{V}$
  \item $V$: \y{vocabulary size}
\end{itemize}

\vspace{1mm}
\textbf{Softmax probabilities}

\[
Z_{\text{pred}}
=
\operatorname{softmax}(Z_{\text{logits}})
\]

\vspace{1mm}
\y{Each row is a probability distribution}
\y{over tokens.}

\end{column}

\end{columns}

\vspace{2mm}
\centering
{\footnotesize
\rtext{Logits convert hidden representations into token probabilities.}
}

\end{frame}
%!TEX root = lec06.tex
% ================================================================================
% Lecture 6 — Slide 16
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Cross-Entropy Loss for Language Modeling}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-1mm}
\textbf{Prediction target}

\begin{itemize}
  \item One correct token per position
  \item Stored as an index in the vocabulary
\end{itemize}

\vspace{1mm}
For position $t$: $y_t \in \{1,\dots,V\}$ (token index). 
Equivalent \y{one-hot} representation: 
\[
e_{y_t} \in \mathbb{R}^V.
\]
Model prediction: $p_t = Z_{\text{pred},\,t} \in \R^{V}.$

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}

\vspace{-3mm}
\rtext{\textbf{Cross-entropy loss}}

\vspace{-2mm}
\[
\mathcal{L}
=
- \sum_{t=1}^{n}
\log p_t(y_t)
\]

\vspace{-2mm}
\begin{itemize}
  \item $p_t(y_t)$: probability assigned to the correct token
  \item Uses index $y_t$ to select one entry
\end{itemize}

\vspace{1mm}
\textbf{Interpretation}

\begin{itemize}
  \item High confidence, correct → low loss
  \item Wrong or uncertain → high loss
\end{itemize}

\end{column}

\end{columns}

\vspace{4mm}
\centering
\y{The model is trained to maximize likelihood of the true sequence.} \\
{\footnotesize
Cross-entropy measures how well predicted probabilities match the true tokens.
}

\end{frame}
%!TEX root = lec06.tex
% ================================================================================
% Lecture 6 — Slide 18
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Training the Transformer Model}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-1mm}
\textbf{Training objective}

\begin{itemize}
  \item Minimize cross-entropy loss
  \item Over all tokens in the sequence
\end{itemize}

\vspace{-3mm}
\[
\mathcal{L}
=
- \sum_{t=1}^{n}
\log p_t(y_t)
\]

\vspace{1mm}
\textbf{Learnable parameters}

\begin{itemize}
  \item Embeddings
  \item Attention projections ($W^Q, W^K, W^V, W^O$)
  \item Feedforward weights
  \item Output projection $W_{\text{out}}$
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}

\vspace{-8mm}
\textbf{Gradient-based optimization}

\begin{itemize}
  \item Compute gradients via backpropagation
  \item Update parameters to reduce loss
\end{itemize}

\vspace{1mm}
Generic update rule:

\vspace{-4mm}
\[
\theta
\;\leftarrow\;
\theta
-
\eta
\frac{\partial \mathcal{L}}{\partial \theta}
\]

\vspace{-3mm}
\textbf{In practice}

\begin{itemize}
  \item Adam or AdamW optimizer
  \item Mini-batch training
  \item Many epochs over large corpora
\end{itemize}

\vspace{2mm}
\centering
Training adjusts all parameters to improve \y{next-token prediction.}

\end{column}

\end{columns}


\end{frame}
%!TEX root = lec06.tex
% ================================================================================
% Lecture 6 — Slide 19
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Autoregressive Text Generation}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-1mm}
\textbf{Key idea}

\begin{itemize}
  \item Generate one token at a time
  \item Each new token is fed back as input
\end{itemize}

\vspace{1mm}
At position $t$:
\[
p_t = P(x_t \mid x_1,\dots,x_{t-1})
\]

\vspace{1mm}
\textbf{Training vs inference}

\begin{itemize}
  \item Training: true previous tokens known
  \item Inference: model uses its own output
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.45\textwidth}

\vspace{-8mm}
\textbf{Generation loop}

\begin{enumerate}
  \item Start with a prompt
  \item Compute logits
  \item Apply softmax
  \item Select next token
  \item Append and repeat
\end{enumerate}

\vspace{1mm}
\textbf{Token selection}

\begin{itemize}
  \item Argmax (greedy)
  \item Sampling, repetition penalty
  \item Top-$k$, top-$p$ (nucleus)
\end{itemize}

\end{column}

\end{columns}

\vspace{2mm}
\centering
\y{LLMs are trained once, then generate text step by step.}

\end{frame}
%!TEX root = lec06.tex
% ================================================================================
% Lecture 6 — Slide 20
% ================================================================================
\begin{frame}[t]

\mytitle{A Tiny Language Dataset}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left -------------------------------------------------
\begin{column}[T]{0.45\textwidth}

\textbf{Vocabulary}

\begin{itemize}
  \item Small, fixed word set
  \item Each word mapped to an ID
\end{itemize}

\vspace{1mm}
Example:
\[
\text{``I am hungry''}
\;\longrightarrow\;
[1,\,2,\,43]
\]

\vspace{1mm}
\textbf{Padding}

\begin{itemize}
  \item Fixed sequence length
  \item Padding token = 0
\end{itemize}

\end{column}

% --- Right ------------------------------------------------
\begin{column}[T]{0.54\textwidth}

\vspace{-9mm}
\textbf{Training sentences}

{\footnotesize
\begin{itemize}
  \item I am hungry
  \item you are tired
  \item we are happy
  \item they are sad
  \item the weather is nice
\end{itemize}
}

\vspace{1mm}
\textbf{Training pairs}

\vspace{-3mm}
\[
\text{Input: } (x_1,\dots,x_{n-1})
\quad\rightarrow\quad
\text{Target: } (x_1,\dots,x_n)
\]

\vspace{1mm}
\centering
{\footnotesize
Teacher forcing: true previous tokens are known.
}

\end{column}

\end{columns}

\vspace{2mm}
\centering
\y{The model learns language from very simple sequences.}

\end{frame}
%!TEX root = lec06.tex
% ================================================================================
% Lecture 6 — Slide 19b
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Self-Attention Layer: Class Setup}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.33\textwidth}

\vspace{-1mm}
\textbf{What is defined here}

\begin{itemize}
  \item Learnable weight matrices
  \item Head configuration
  \item No computation yet
\end{itemize}

\vspace{1mm}
\textbf{Key parameters}

\begin{itemize}
  \item $d_{\text{model}}$: embedding dimension
  \item $H$: number of heads
  \item $d_k = d_{\text{model}} / H$
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.66\textwidth}

\vspace{-4mm}
\begin{codeonly}{Self-attention layer (initialization)}
class SelfAttention(nn.Module):
   def __init__(self, d_m, num_heads):
     super().__init__()
     assert d_model % num_heads == 0
     self.num_heads = num_heads
     self.d_k = d_m // num_heads
     
     self.q_linear = nn.Linear(d_m, d_m)
     self.k_linear = nn.Linear(d_m, d_m)
     self.v_linear = nn.Linear(d_m, d_m)
     self.out_linear = nn.Linear(d_m, d_m)
\end{codeonly}
\centering
{\footnotesize
This sets up the attention mechanism structurally.
}

\end{column}

\end{columns}

\vspace{2mm}
\centering
\y{The class defines \emph{what can be learned}, not how it is used.}

\end{frame}
%!TEX root = lec06.tex
% ================================================================================
% Lecture 6 — Slide 22
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Self-Attention — Forward Pass in Code}

\begin{columns}[T,totalwidth=\textwidth]

\begin{column}[T]{0.3\textwidth}

\textbf{Core computation}

\begin{itemize}
  \item Linear projections to $Q,K,V$
  \item Scaled dot-product attention
  \item Weighted value aggregation
  \item Merge heads + output projection
\end{itemize}

\vspace{1mm}
{\tiny \[
Z = \operatorname{softmax}
\!\left(\frac{QK^T}{\sqrt{d_k}}\right)V
\]}

\end{column}

\begin{column}[T]{0.75\textwidth}

\vspace{-3mm}
\begin{codeonly}{Self-attention (PyTorch, condensed)}
def forward(self, x):
    B,T,_ = x.shape
    q = self.q(x).view(B,T,H,D).transpose(1,2)
    k = self.k(x).view(B,T,H,D).transpose(1,2)
    v = self.v(x).view(B,T,H,D).transpose(1,2)

    a = (q @ k.transpose(-2,-1)) / sqrt(D)
    a = softmax(a, dim=-1)

    z = (a @ v).transpose(1,2).reshape(B,T,H*D)
    return self.out(z)
\end{codeonly}

\vspace{2mm}
\centering
\y{This is the attention equation executed in code.}

\end{column}

\end{columns}


\end{frame}
%!TEX root = lec06.tex
% ================================================================================
% Lecture 6 — Slide 23
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Training the Transformer}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left -------------------------------------------------
\begin{column}[T]{0.38\textwidth}

\textbf{Training objective}

\begin{itemize}
  \item Predict the \y{next token}
  \item At every sequence position
\end{itemize}

\vspace{-2mm}
\[
\mathcal{L}
=
- \sum_{t=1}^{n}
\log p_t(y_t)
\]

\vspace{1mm}
\textbf{Learned parameters}

\begin{itemize}
  \item Embeddings
  \item Attention projections
  \item FFN weights
  \item Output projection
\end{itemize}

\end{column}

% --- Right ------------------------------------------------
\begin{column}[T]{0.63\textwidth}

\vspace{-10mm}
\begin{codeonly}{Training loop (PyTorch)}
criterion = CrossEntropyLoss(
    ignore_index=0)
optimizer = Adam(
    model.parameters(), lr=1e-3)

for x, y in dataloader:
    optimizer.zero_grad()
    logits = model(x)
    loss = criterion(
        logits.view(-1, V), y.view(-1))
    loss.backward()
    optimizer.step()
\end{codeonly}

\vspace{1mm}
{\footnotesize
Gradients flow through the entire Transformer.
}

\vspace{2mm}
\centering
\y{Training is standard gradient-based optimization.}

\end{column}

\end{columns}


\end{frame}
%!TEX root = lec06.tex
% ================================================================================
% Lecture 6 — Slide 24
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{What the Model Predicts}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left -------------------------------------------------
\begin{column}[T]{0.45\textwidth}

\textbf{Given input}

\[
\text{``I am''}
\;\longrightarrow\;
[1,\,2]
\]

\vspace{1mm}
\textbf{Model output}

\begin{itemize}
  \item Probability over vocabulary
  \item One distribution per position
\end{itemize}

\vspace{1mm}
\textbf{Prediction}

\[
\arg\max p(\text{token})
\;\Rightarrow\;
\text{``hungry''}
\]

\end{column}

% --- Right ------------------------------------------------
\begin{column}[T]{0.5\textwidth}

\vspace{-8mm}
\begin{codeonly}{Inference (greedy decoding)}
model.eval()
x = [I, am]

logits = model(x)
next = argmax( logits[-1] )

x = append(x, next)
\end{codeonly}

\vspace{1mm}
\textbf{Key point}

\begin{itemize}
  \item Same model as during training
  \item No architecture change
  \item Only token selection differs
\end{itemize}

\end{column}

\end{columns}

\vspace{2mm}
\centering
\y{Generation is just repeated next-token prediction.}

\end{frame}
%!TEX root = lec06.tex
% ================================================================================
% Lecture 6 — Slide 25
% ================================================================================
\begin{frame}[t]

\mytitle{Why Run a Language Model Locally?}

\begin{columns}[T,totalwidth=\textwidth]

\begin{column}[T]{0.48\textwidth}

\textbf{Cloud-based LLMs}

\begin{itemize}
  \item High performance
  \item No setup required
  \item External infrastructure
\end{itemize}

\vspace{1mm}
Typical examples:
\begin{itemize}
  \item ChatGPT
  \item Claude
  \item Gemini
\end{itemize}

\end{column}

\begin{column}[T]{0.48\textwidth}

\textbf{Local LLMs}

\begin{itemize}
  \item Full data privacy
  \item Offline capability
  \item Direct system integration
\end{itemize}

\vspace{1mm}
Use cases:
\begin{itemize}
  \item Prototyping
  \item Teaching \& learning
  \item Domain-specific tools
\end{itemize}

\end{column}

\end{columns}

\vspace{5mm}
\centering
\y{Modern LLMs are small and fast enough to run on a laptop.}

\end{frame}
%!TEX root = lec06.tex
% ================================================================================
% Lecture 6 — Slide 26
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Installing Ollama}

\begin{columns}[T,totalwidth=\textwidth]

\begin{column}[T]{0.42\textwidth}

\textbf{What is Ollama?}

\begin{itemize}
  \item Local LLM runtime
  \item Optimized inference
  \item Simple CLI and API
\end{itemize}

\vspace{1mm}
\textbf{Supported platforms}

\begin{itemize}
  \item Linux
  \item macOS
  \item Windows (WSL)
\end{itemize}

\end{column}

\begin{column}[T]{0.55\textwidth}

\vspace{-6mm}
\begin{codeonly}{Install Ollama (Linux / macOS)}
curl -fsSL https://ollama.com/install.sh | sh
\end{codeonly}

\vspace{1mm}
\begin{codeonly}{Verify installation}
ollama --version
\end{codeonly}

\vspace{1mm}
{\footnotesize
Ollama runs as a local service on \texttt{localhost}.
}

\end{column}

\end{columns}

\vspace{2mm}
\centering
\y{No Python, no GPU setup, no environment management.}

\end{frame}
%!TEX root = lec06.tex
% ================================================================================
% Lecture 6 — Slide 27
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Running a Local LLM with Ollama}

\begin{columns}[T,totalwidth=\textwidth]

\begin{column}[T]{0.45\textwidth}

\textbf{Download a model}

\begin{itemize}
  \item Models are pulled on demand
  \item Stored locally
\end{itemize}

\vspace{1mm}
Examples:
\begin{itemize}
  \item mistral
  \item llama3
  \item deepseek-r1
\end{itemize}

\end{column}

\begin{column}[T]{0.5\textwidth}

\vspace{-10mm}
\begin{codeonly}{Run a model}
ollama pull mistral
ollama run mistral
\end{codeonly}

\vspace{1mm}
\begin{codeonly}{Example prompt}
> Explain self-attention in one paragraph.
\end{codeonly}

\vspace{1mm}
{\footnotesize
Responses are generated locally.
}

\hspace*{-3.5cm}\includegraphics[width=11cm]{../../images/img06/ollama_local_prompt.png}

\end{column}

\end{columns}



\vspace{2mm}
\centering
\y{This is a full LLM running on your machine.}

\end{frame}
%!TEX root = lec06.tex
% ================================================================================
% Lecture 6 — Slide 28
% ================================================================================
\begin{frame}[t]

\mytitle{Streaming Responses from an LLM}

\begin{columns}[T,totalwidth=\textwidth]

\begin{column}[T]{0.48\textwidth}

\textbf{Standard inference}

\begin{itemize}
  \item Request sent
  \item Model computes full response
  \item Response returned at once
\end{itemize}

\vspace{1mm}
\textbf{Drawback}

\begin{itemize}
  \item No intermediate output
  \item Latency feels high
\end{itemize}

\end{column}

\begin{column}[T]{0.48\textwidth}

\textbf{Streaming inference}

\begin{itemize}
  \item Tokens generated sequentially
  \item Output arrives chunk by chunk
  \item Immediate user feedback
\end{itemize}

\vspace{1mm}
\textbf{Key idea}

\[
\text{tokens}_1,\;
\text{tokens}_2,\;
\text{tokens}_3,\;\dots
\]

\vspace{1mm}
\centering
\y{Streaming exposes the autoregressive nature of LLMs.}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec06.tex
% ================================================================================
% Lecture 6 — Slide 29
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Streaming from Ollama using curl}

\begin{columns}[T,totalwidth=\textwidth]

\begin{column}[T]{0.3\textwidth}

\textbf{Ollama REST API}

\begin{itemize}
  \item Local HTTP service
  \item JSON-based requests
  \item Supports streaming
\end{itemize}

\vspace{1mm}
\textbf{Key option}

\vspace{-5mm}
\[
\texttt{"stream": true}
\]

\end{column}

\begin{column}[T]{0.69\textwidth}

\vspace{-3mm}
\begin{codeonly}{Streaming request with curl}
curl -X POST http://localhost:11434/api/generate \
-H "Content-Type: application/json" \
-d '{
  "model": "mistral",
  "prompt": "Explain self-attention.",
  "stream": true }'
\end{codeonly}

\vspace{1mm}
{\footnotesize
The response arrives as a sequence of JSON objects.
}


\end{column}

\end{columns}

\vspace{2mm}
\centering
\y{Each chunk corresponds to newly generated tokens.}

\hspace*{1cm}{\tiny\begin{lstlisting}
{"model":"mistral","created_at":"2025-12-29T13:38:01.545932Z","response":" Self","done":false}
{"model":"mistral","created_at":"2025-12-29T13:38:01.570159Z","response":"-","done":false}
{"model":"mistral","created_at":"2025-12-29T13:38:01.592394Z","response":"att","done":false}
{"model":"mistral","created_at":"2025-12-29T13:38:01.614036Z","response":"ention","done":false}
{"model":"mistral","created_at":"2025-12-29T13:38:01.635585Z","response":",","done":false}
\end{lstlisting}}



\end{frame}
%!TEX root = lec06.tex
% ================================================================================
% Lecture 6 — Slide 30
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Streaming from Ollama using Python}

\begin{columns}[T,totalwidth=\textwidth]

\begin{column}[T]{0.33\textwidth}

\textbf{Why Python streaming?}

\begin{itemize}
  \item Interactive applications
  \item Live UIs 
  \item Custom text processing
\end{itemize}

\vspace{1mm}
\textbf{Mechanism}

\begin{itemize}
  \item HTTP response stream
  \item Incremental JSON decoding
  \item Append text chunks
\end{itemize}

\end{column}

\begin{column}[T]{0.72\textwidth}

\vspace{-3mm}
\begin{codeonly}{Streaming response (Python)}
import requests, json
url = "http://localhost:11434/api/generate"
data = {
  "model": "mistral",
  "prompt": "Explain self-attention.",
  "stream": True }
r = requests.post(url, json=data, stream=True)
for line in r.iter_lines():
    if line:
        msg = json.loads(line)
        print(msg["response"], end="")
\end{codeonly}

\vspace{0mm}
{\footnotesize
Text is printed as soon as tokens arrive.
}

\end{column}

\end{columns}

\vspace{0mm}
\centering
\y{Streaming enables responsive, real-time LLM applications.}

\end{frame}
%!TEX root = lec06.tex
% ================================================================================
% Lecture 6 — Slide 31
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Accessing Ollama via a Local Streaming Server}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.35\textwidth}

\vspace{-1mm}
\textbf{Architecture overview}

\begin{itemize}
  \item Ollama runs the LLM locally
  \item Flask provides a lightweight API
  \item HTML/JS frontend streams responses
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.63\textwidth}

\vspace{-1mm}
\textbf{Starting the streaming server}

\begin{codeonly}{Run the Flask server}
cd code06
python 5_flask_streaming.py
\end{codeonly}

\vspace{1mm}
\textbf{Open the UI in your browser}

\begin{codeonly}{Access the interface}
http://127.0.0.1:5000
\end{codeonly}


\vspace{0mm}
{\footnotesize
Responses are streamed token by token via
\texttt{text/event-stream}.
}

\end{column}

\end{columns}

\vspace{-2mm}
{\color{red}
$ \textbf{Browser}
\;\rightarrow\;
\textbf{Flask server}
\;\rightarrow\;
\textbf{Ollama}
$}

\vspace{1mm}
{\footnotesize
No cloud, no external services, full local control.
}

\vspace{1mm}
\y{This setup turns a local LLM into an interactive application platform.}

\end{frame}
% ================================================================================
% E-AI Tutorial Slides
% Filename: lec06.tex
%
% Roland Potthast 2025/2026
% Licence: CC-BY4.0
% ================================================================================
\documentclass[aspectratio=169]{beamer}

% --- Load lecture macros --------------------------------------------------------
\input{../lec_macros.tex}
\newcommand{\LectureNumber}{Lecture 6}

% --- Document -------------------------------------------------------------------
\begin{document}

\setagendaboxforlecture{6}

\input{../lec_agenda.tex}
\input{lec06_01.tex}
\input{lec06_02.tex}
\input{lec06_03.tex}
\input{lec06_04.tex}
\input{lec06_05.tex}
\input{lec06_06.tex}
\input{lec06_07.tex}
\input{lec06_08.tex}
\input{lec06_09.tex}
\input{lec06_10.tex}
\input{lec06_11.tex}
\input{lec06_12.tex}
\input{lec06_13.tex}
\input{lec06_14.tex}
\input{lec06_15.tex}
\input{lec06_16.tex}
\input{lec06_17.tex}
\input{lec06_18.tex}
\input{lec06_19.tex}
\input{lec06_20.tex}
\input{lec06_21.tex}
\input{lec06_22.tex}
\input{lec06_23.tex}
\input{lec06_24.tex}
\input{lec06_25.tex}
\input{lec06_26.tex}
\input{lec06_27.tex}
\input{lec06_28.tex}
\input{lec06_29.tex}
\input{lec06_30.tex}
\input{lec06_31.tex}

% --- End Document ---------------------------------------------------------------
\end{document}
%!TEX root = lec07.tex
% ================================================================================
% Lecture 7 — Slide 01
% ================================================================================
\begin{frame}[t]

\mytitle{Why Retrieval-Augmented Generation (RAG)?}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Limitations of standalone LLMs}

\begin{itemize}
  \item Fixed knowledge at training time
  \item No access to private or local data
  \item Risk of hallucinated answers
\end{itemize}


\includegraphics[width=7cm]{../../images/img07/hallucinations.png}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{1mm}
LLMs answer from \emph{learned parameters only}. 
\rtext{This can be completely off reality!}

\vspace{3mm}
\textbf{Typical real-world needs}

\begin{itemize}
  \item Large code bases
  \item Technical documentation
  \item Evolving project knowledge
\end{itemize}

\vspace{1mm}
\textbf{Key idea:}  
\y{Bring the knowledge to the model.}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec07.tex
% ================================================================================
% Lecture 7 — Slide 02
% ================================================================================
\begin{frame}[t]

\mytitle{Core Idea of Retrieval-Augmented Generation}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Standard LLM workflow}

\[
\text{Prompt} \;\rightarrow\; \text{LLM} \;\rightarrow\; \text{Answer}
\]

\begin{itemize}
  \item No external knowledge
  \item No verification
\end{itemize}

\vspace{4mm}
\begin{minipage}{7cm}
\fontsize{9pt}{10pt}\selectfont
Pure LLMs work well for general reasoning, language understanding, summarization, and creative text generation when the required knowledge is common and static.
They perform poorly when accurate, up-to-date, proprietary, or highly technical domain knowledge is required, because they cannot verify facts or access external sources.
In such cases, LLMs tend to hallucinate plausible but incorrect answers.
\end{minipage}




\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{RAG workflow}

{\color{red}\bf\[
\text{Query}
\;\rightarrow\;
\text{Retrieve}
\;\rightarrow\;
\text{LLM}
\;\rightarrow\;
\text{Answer}
\]}

\begin{itemize}
  \item Search relevant documents
  \item Inject context into prompt
  \item \y{Grounded answers}
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec07.tex
% ================================================================================
% Lecture 7 — Slide 03
% ================================================================================
\begin{frame}[t]

\mytitle{RAG Architecture Overview}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.45\textwidth}


\rtext{\bf RAG is more than just text search!}

\vspace{5mm}
\textbf{Main \y{components}}

\begin{itemize}
  \item Document collection
  \item Vector database
  \item Retriever
  \item Language model
\end{itemize}

\vspace{2mm}
Each component has a \emph{clear role}.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.55\textwidth}

\vspace{-2mm}
\includegraphics[width=\textwidth]{../../images/img07/RAG.png}

\vspace{1mm}
\centering
Documents provide context for generation

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec07.tex
% ================================================================================
% Lecture 7 — Slide 04
% ================================================================================
\begin{frame}[t]
\begin{tightmath}

\mytitle{Vector Databases and Transformer Embeddings}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{\y{Text to vector mapping}}

Given a tokenized input sequence
\[
(w_1, w_2, \dots, w_n)
\]

a Transformer maps tokens to embeddings:
\[
x_i = E(w_i) \in \mathbb{R}^d
\]

After contextualization (self-attention):
\[
h_i = \mathrm{Transformer}(x_1,\dots,x_n)
\]

\vspace{1mm}
A sentence or paragraph embedding is typically:

\vspace{-7mm}
\[
z = \frac{1}{n}\sum_{i=1}^n h_i
\]

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Vector database view}

Each paragraph is stored as:
\[
z_j \in \mathbb{R}^d
\]

\y{Similarity search} uses a distance measure, e.g.
\[
\mathrm{sim}(z_q, z_j)
=
\frac{z_q \cdot z_j}{\|z_q\|\,\|z_j\|}
\]

or equivalently:
\[
\| z_q - z_j \|_2
\]

\vspace{1mm}
\textbf{Key point:}  
The same embedding space is reused —  
now \emph{outside} the LLM.

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec07.tex
% ================================================================================
% Lecture 7 — Slide 05
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Elementary Vector Database — Setup}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.33\textwidth}

\textbf{Toy example}

\begin{itemize}
  \item Small set of short sentences
  \item Different semantic topics
  \item Some paraphrases, some unrelated
\end{itemize}

\vspace{1mm}
We use this to build intuition  
before scaling to real documents.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.65\textwidth}

\vspace{-3mm}
\begin{codeonly}{Example sentences }
sentences = [
  "The sun is shining brightly today.",
  "Heavy rain is falling over the city.",
  "Neural networks can learn patterns.",
  "Transformers use self-attention."
]
\end{codeonly}

\vspace{1mm}
Each sentence will become  
one vector in a shared space.

\vspace{3mm}
\begin{center}
\rtext{\bf Sentence $\rightarrow {\bf z} \in \R^{d}$}
\end{center}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec07.tex
% ================================================================================
% Lecture 7 — Slide 06
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Text to Vector Space}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Sentence \y{embedding}}

\vspace{3mm}
A sentence $s_{i}$ is mapped to a vector
\[
z_i \in \mathbb{R}^d
\]

using a pretrained Transformer:
\[
z_i = f_{\theta}(s_i)
\]

\vspace{1mm}
In our example:
\[
d = 384
\]

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\y{\textbf{Embedding matrix}}

\vspace{2mm}
For \(N\) sentences, we obtain:
\[
Z =
\begin{bmatrix}
z_1^\top \\
z_2^\top \\
\vdots \\
z_N^\top
\end{bmatrix}
\in \mathbb{R}^{N \times d}
\]

\vspace{3mm}
Each row corresponds to  
\emph{one sentence}.

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec07.tex
% ================================================================================
% Lecture 7 — Slide 07
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Similarity Search}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}

\textbf{Query embedding}

A query sentence is mapped to:
\[
z_q \in \mathbb{R}^d
\]

\vspace{3mm}
\y{\bf Similarity} to stored sentences is
measured using cosine similarity:
\[
\mathrm{sim}(z_q, z_i)
=
\frac{z_q \cdot z_i}
{\|z_q\|\,\|z_i\|}
\]

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.53\textwidth}

\vspace{-8mm}
\begin{codeonly}{Similarity search (conceptual)}
scores = cosine_similarity(
    query_embedding,
    embeddings )

top_k = argsort(scores)[-k:]
\end{codeonly}

\vspace{3mm}
\textbf{Result:}  
\y{Sentences with closest meaning}  
\y{are retrieved — no keywords needed.}

\end{column}

\end{columns}

\vspace{4mm}
\begin{minipage}{\textwidth}
\footnotesize
See example 1\_vector\_db\_elementary.ipynb in the \texttt{code07/} directory carrying out transforms explicitely. The command \texttt{\color{red} SentenceTransformer("all-MiniLM-L6-v2")} loads a pretrained Transformer-based
sentence embedding model that maps each input sentence to a fixed-size vector
\( z \in \mathbb{R}^{384} \) capturing its semantic meaning.
The model is publicly available at
\href{https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2}
{\texttt{huggingface.co/sentence-transformers/all-MiniLM-L6-v2}}.
\end{minipage}

\end{tightmath}
\end{frame}
%!TEX root = lec07.tex
% ================================================================================
% Lecture 7 — Slide 08
% ================================================================================
\begin{frame}[t]

\mytitle{Document Search via Embeddings}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Goal}

\begin{itemize}
  \item Search \emph{inside} a document
  \item Retrieve relevant pages or sections
  \item No keyword matching required
\end{itemize}

\vspace{1mm}
We use the same vector-space idea  
as in the elementary example.

\vspace{1cm}
\raggedleft
\textbf{"temporal pattern"}
$\;\xrightarrow{\text{find pdf}}\;$

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Input}

\begin{itemize}
  \item One lecture PDF (Lecture 05)
  \item Pages as semantic units
  \item Natural-language queries
\end{itemize}

\vspace{1mm}
\textbf{Output:}  
Relevant pages from the PDF

\vspace{3mm}
\includegraphics[width=5cm]{../../images/img07/slide_from_rag}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec07.tex
% ================================================================================
% Lecture 7 — Slide 09
% ================================================================================
\begin{frame}[t, fragile]
\begin{tightmath}

\mytitle{From PDF Pages to Vectors}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.37\textwidth}

\textbf{Decomposition}

The \y{PDF is split into pages:}
\[
\{\text{page}_1, \dots, \text{page}_N\}
\]

\y{Each page is embedded} as:
\[
z_i = f_{\theta}(\text{page}_i)
\in \mathbb{R}^d
\]

\vspace{1mm}
In our example:
\[
d = 384
\]

\textbf{Embedding matrix}

All pages form:
\[
Z \in \mathbb{R}^{N \times d}
\]

\vspace{1mm}
\begin{minipage}{6cm}
\tiny
Each row corresponds to  
one PDF page.

\textbf{Key point:}  
Documents are represented as  
collections of vectors.
\end{minipage}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.63\textwidth}

\vspace{-3mm}
\begin{codeonly}{Extract text from PDF pages}
for i, page in enumerate(reader.pages):
    text = page.extract_text()
    if text and len(text.strip()) > 50:
        pages.append(text.strip())
        page_ids.append(i + 1)
\end{codeonly}

\vspace{2mm}
\begin{codeonly}{Embedding}
page_embeddings = model.encode(
    pages,
    convert_to_numpy=True,
    show_progress_bar=False)
\end{codeonly}


\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec07.tex
% ================================================================================
% Lecture 7 — Slide 10
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Semantic Search inside a PDF}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.30\textwidth}

\textbf{Query embedding}

A user query is mapped to:
\[
z_q \in \mathbb{R}^d
\]

\y{Similarity} to \y{page embeddings} is computed via:
\[
\mathrm{sim}(z_q, z_i)
=
\frac{z_q \cdot z_i}
{\|z_q\|\,\|z_i\|}
\]

\vspace{1mm}
Top-\(k\) most relevant pages are retrieved.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.73\textwidth}

\vspace{-3mm}
\begin{codeonly}{Semantic page search}
def search_pdf(query, model, pages, embeddings, page_ids, top_k=3):
   q_emb = model.encode(
      query, convert_to_numpy=True)
   scores = []
   for i, emb in enumerate(embeddings):
      score = cosine_similarity(q_emb, emb)
      scores.append((page_ids[i], score, pages[i]))

   scores.sort(key=lambda x: x[1], reverse=True)
   return scores[:top_k]
\end{codeonly}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec07.tex
% ================================================================================
% Lecture 7 — Slide 11
% ================================================================================
\begin{frame}[t]

\mytitle{From Retrieval to Evidence}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{What we display}

\begin{itemize}
  \item Retrieved page number
  \item Extracted text snippet
  \item Original PDF page
\end{itemize}

\vspace{1mm}
This allows direct verification  
of the search result.

\vspace{1mm}
\textbf{Why this matters}

\begin{itemize}
  \item Transparent retrieval
  \item No hidden reasoning
  \item Trust through inspectable sources
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-1cm}
\includegraphics[width=7cm]{../../images/img07/pdf-rag-result.png}

\vspace{3mm}
Next: \textbf{Retrieval Augmented Generation:}  
Retrieve first — generate later.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec07.tex
% ================================================================================
% Lecture 7 — Slide 12
% ================================================================================
\begin{frame}[t]
\begin{tightmath}

\mytitle{Why Do We Need FAISS?}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Above approach}

\begin{itemize}
  \item Loop over all embeddings
  \item Compute similarity one by one
  \item \y{Exact but very (!) slow}
\end{itemize}

\vspace{1mm}
Cost of one query:
\[
\mathcal{O}(N \cdot d)
\]

\textbf{Problem size}

\begin{itemize}
  \item \(N\): number of stored vectors  
        (pages, paragraphs, documents)
  \item \(d\): embedding dimension  
        (e.g.\ \(d = 384\))
\end{itemize}
\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-8mm}
Each query compares  
against \emph{all} vectors.

\vspace{2mm}
\textbf{Scaling issue:}  
Large \(N\) makes brute-force search infeasible.

\vspace{2mm}
\textbf{Typical RAG library sizes}

\begin{itemize}
  \item \textbf{Personal projects:}  
        \(10^2\)–\(10^3\) documents  
        \(\rightarrow\; N \sim 10^4\) chunks
  \item \y{\textbf{Team / institutional data:}} 
        \(10^4\)–\(10^5\) documents  
        \(\rightarrow\; N \sim 10^6\)–\(10^7\) chunks
  \item \y{\textbf{Enterprise-scale systems:}}  
        \(10^6+\) documents  
        \(\rightarrow\; N \gg 10^7\) chunks
\end{itemize}

\vspace{1mm}
Chunking multiplies the number of stored vectors \(N\).


\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec07.tex
% ================================================================================
% Lecture 7 — Slide 13
% ================================================================================
\begin{frame}[t]
\begin{tightmath}

\mytitle{FAISS — Vector Search at Scale}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\begin{itemize}
  \item \y{Facebook AI Similarity Search}
  \item Optimized nearest-neighbor search
  \item Designed for large vector collections
\end{itemize}

\vspace{1mm}
Stores vectors:
\[
z_i \in \mathbb{R}^d
\]

\textbf{Key idea}

\begin{itemize}
  \item \y{Build an index once}
  \item Query many times
  \item Fast top-\(k\) retrieval
\end{itemize}

Search replaces explicit loops.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-5mm}
\textbf{Hierarchical search in FAISS}

FAISS accelerates nearest-neighbor search by introducing
a \emph{coarse-to-fine hierarchy} in vector space.

\vspace{3mm}
\textbf{Step 1: Coarse partitioning}

The vector space is partitioned into \(M\) regions
using representative centroids:
\[
\{ c_1, \dots, c_M \}, \quad c_j \in \mathbb{R}^d .
\]

Each stored vector \(z_i\) is assigned to its nearest centroid:
\[
z_i \;\mapsto\; c(z_i).
\]


\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec07.tex
% ================================================================================
% Lecture 7 — Slide 14
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{FAISS in Practice}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.43\textwidth}

\textbf{Index construction}

\begin{itemize}
  \item Choose distance metric
  \item Add all embeddings
  \item Index lives in memory or on disk
\end{itemize} 
Common choice: IndexFlatL2

\vspace{4mm}
\textbf{Step 2: Query routing}

For a query vector \(z_q\), FAISS finds the closest centroids:
\[
\mathcal{C}_q
=
\operatorname*{arg\,top}_{L}
\; \| z_q - c_j \|_2 ,
\quad L \ll M .
\]

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.55\textwidth}

\vspace{-9mm}
\begin{codeonly}{Build and query FAISS index}
import faiss
d = page_embeddings.shape[1]
index = faiss.IndexFlatL2(d)

index.add(page_embeddings)

distances, indices = index.search(
    query_embedding, k)
\end{codeonly}


\vspace{3mm}
\textbf{Step 3: Local search}

Exact distances are computed only for vectors
stored in the selected regions:
\[
z_i \;\text{with}\; c(z_i) \in \mathcal{C}_q .
\]

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec07.tex
% ================================================================================
% Lecture 7 — Slide 15
% ================================================================================
\begin{frame}[t]

\mytitle{Streaming LLM Responses}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Standard LLM interaction}

\[
\text{prompt}
\;\longrightarrow\;
\text{full response}
\]

User waits until generation is finished.

\vspace{2mm}
\textbf{\y{Streaming} interaction}

\[
\text{prompt}
\;\longrightarrow\;
(\delta_1, \delta_2, \dots)
\]

Partial tokens are delivered incrementally.

\vspace{3mm}
\rtext{Recall that \y{\bf LLMs generate tokens incrementally!}}
\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-7mm}
\textbf{What streaming changes}

\begin{itemize}
  \item Faster perceived response
  \item Progressive rendering
  \item Interactive user experience
\end{itemize}

\vspace{2mm}
\textbf{What streaming does not change}

\begin{itemize}
  \item Model architecture
  \item Reasoning capability
  \item Final content
\end{itemize}



\end{column}

\end{columns}

\end{frame}
%!TEX root = lec07.tex
% ================================================================================
% Lecture 7 — Slide 16
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{OpenAI Streaming}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.35\textwidth}

\textbf{Streaming API call}

\begin{itemize}
  \item Same prompt structure
  \item \texttt{stream=True}
  \item Tokens arrive as \y{deltas}
\end{itemize}

\vspace{2mm}
Each chunk contains new text:
\[
\delta_k \subset \text{response}
\]

\begin{minipage}{4cm}
\tiny\color{red}
There are several older OpenAI interface versions that language models may still suggest.
Be careful: to avoid deprecated APIs, it is often necessary to explicitly provide a current code template.
\end{minipage}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.65\textwidth}

\vspace{-9mm}
\begin{codeonly}{OpenAI streaming in Jupyter}
stream = client.chat.completions.create(
  model="gpt-4o-mini", messages=[...],
  stream=True )

accumulated = ""
handle = display(
  Markdown(""), display_id=True)

for chunk in stream:
    delta = chunk.choices[0].delta
    if delta.content:
        accumulated += delta.content
        handle.update(
          Markdown(accumulated))
\end{codeonly}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec07.tex
% ================================================================================
% Lecture 7 — Slide 17
% ================================================================================
\begin{frame}[t]

\mytitle{Streaming with Local LLMs (Ollama)}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Local execution}

\begin{itemize}
  \item Models run on \y{local hardware}
  \item No external API calls
  \item \y{Full data control}
\end{itemize}

\vspace{2mm}
Streaming follows the same principle:
\[
(\delta_1, \delta_2, \dots)
\]

\raggedleft
\includegraphics[width=6cm]{../../images/img07/ollama_interface.png}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Advantages}

\begin{itemize}
  \item \y{Privacy and compliance}
  \item \rtext{\bf Offline usage - train or plane}
  \item No usage-based \y{cost}
\end{itemize}

\vspace{2mm}
\textbf{Trade-offs}

\begin{itemize}
  \item Smaller models
  \item Hardware dependent speed
\end{itemize}

\vspace{5mm}
{\bf List of all available models:}
https://ollama.ai/library
\end{column}

\end{columns}

\end{frame}
%!TEX root = lec07.tex
% ================================================================================
% Lecture 7 — Slide 18
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Ollama Streaming in Python}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.33\textwidth}

\textbf{Ollama streaming call}

\begin{itemize}
  \item Local HTTP interface
  \item Same message format
  \item Streaming enabled
\end{itemize}

\vspace{2mm}
Works with:
\texttt{\y{llama3}}, \texttt{\y{mistral}}, \texttt{\y{mixtral}}, \texttt{\y{deepseek-r1}}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.68\textwidth}

\vspace{-4mm}
\begin{codeonly}{Ollama streaming in Jupyter}
stream = ollama.chat( model="llama3", 
   messages=[...], stream=True )

accumulated = ""
handle = display(
  Markdown(""), display_id=True)

for chunk in stream:
   if "content" in chunk["message"]:
      accumulated += chunk["message"]\
      ["content"] 
      handle.update(Markdown(accumulated))
\end{codeonly}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec07.tex
% ================================================================================
% Lecture 7 — Slide 19
% ================================================================================
\begin{frame}[t]

\mytitle{RAG Implementation: Concrete Steps}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Implemented components}

\begin{itemize}
  \item text chunking (files $\rightarrow$ chunks) \mdcheck
  \item sentence embeddings \mdcheck
  \item FAISS index \mdcheck
  \item metadata tracking \mdcheck
  \item LLM query with context \mdcheck
\end{itemize}

\vspace{3mm}
\begin{minipage}{5cm}
\tiny
\textbf{Execution order}

\begin{enumerate}
  \item build vector database (offline)
  \item embed user query
  \item retrieve top-$k$ chunks
  \item assemble prompt context
  \item generate answer (optional streaming)
\end{enumerate}
\end{minipage}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-9mm}
\includegraphics[width=7.3cm]{../../images/img07/openai_context.png}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec07.tex
% ================================================================================
% Lecture 7 — Slide 20
% ================================================================================
\begin{frame}[t]
\begin{tightmath}

\mytitle{Top-\(k\) Retrieval: What Do We Actually Get?}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{FAISS output}

For a query embedding \(z_q\), FAISS returns:
\[
\{(i_1, d_1), (i_2, d_2), \dots, (i_k, d_k)\}
\]

\begin{itemize}
  \item \(i_j\): index of a stored chunk
  \item \(d_j\): distance or similarity score
\end{itemize}

\vspace{2mm}
These indices refer to:
\[
z_{i_j} \;\leftrightarrow\; \text{chunk}_{i_j}
\]

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Important clarification}

\begin{itemize}
  \item FAISS returns \emph{vectors}, not text
  \item Text is recovered via metadata lookup
  \item Ordering is by similarity score
\end{itemize}

\vspace{2mm}
\textbf{At this stage:}
\begin{itemize}
  \item \y{no LLM involved}
  \item \y{no generation}
  \item \y{no reasoning}
\end{itemize}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec07.tex
% ================================================================================
% Lecture 7 — Slide 21
% ================================================================================
\begin{frame}[t]

\mytitle{From FAISS Indices to Text Chunks}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Stored metadata per chunk}

Each vector \(z_i\) is linked to:
\begin{itemize}
  \item file path
  \item line range or section
  \item raw text content
\end{itemize}

\vspace{2mm}
This mapping is stored outside FAISS  
(e.g.\ Python lists, JSON, databases).

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{\color{red}Lookup step}

\vspace{2mm}
For each returned index \(i_j\):
\[
i_j \;\rightarrow\;
(\text{file}, \text{lines}, \text{text})
\]

\vspace{2mm}
This produces a ranked list:
\[
(\text{chunk}_1, \dots, \text{chunk}_k)
\]

\vspace{2mm}
\textbf{Result:}  
\y{Concrete, inspectable evidence.}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec07.tex
% ================================================================================
% Lecture 7 — Slide 22
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Composing the Retrieval Context}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Context construction}

Retrieved chunks are:
\begin{itemize}
  \item ordered by similarity
  \item concatenated into one context block
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

Typical structure:
\begin{itemize}
  \item file reference
  \item optional score
  \item text snippet
\end{itemize}

\vspace{2mm}
Context size is \y{explicitly limited}.

\end{column}

\end{columns}

\vspace{0mm}
\begin{codeonly}{Context assembly (ICON example)}
context = ""
for r in retrieved_chunks:
  context += (
    f"[{r.file}, lines {r.start}-{r.end}]\n"
    + r.text + "\n\n" )
\end{codeonly}

\end{frame}
%!TEX root = lec07.tex
% ================================================================================
% Lecture 7 — Slide XX
% ================================================================================
\begin{frame}[t]

\mytitle{OpenSearch}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{What is OpenSearch?}

OpenSearch is an open-source,  
distributed search and analytics engine.

\vspace{2mm}
It is designed to index and query
large collections of documents
with low latency.

\vspace{2mm}
Originally derived from Elasticsearch,
OpenSearch is developed under
the Apache~2.0 license.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Core capabilities}

\begin{itemize}
  \item full-text search (inverted index)
  \item metadata filtering and aggregation
  \item persistent, disk-based indices
  \item distributed execution across nodes
  \item \y{\textbf{vector similarity search}}
\end{itemize}

\vspace{2mm}
OpenSearch combines
text-based and vector-based retrieval
in a single system.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec07.tex
% ================================================================================
% Lecture 7 — Slide XX
% ================================================================================
\begin{frame}[t]
\begin{tightmath}

\mytitle{\rtext{Google Search} as Retrieval-Augmented Generation}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Core idea}

Retrieval-Augmented Generation (RAG)
combines an LLM with an
\y{external information source}.

\vspace{2mm}
In classical RAG, retrieval uses:
\begin{itemize}
  \item vector databases (FAISS)
  \item local document collections
\end{itemize}

\vspace{2mm}
\textbf{Google-based RAG}

Here, retrieval is delegated to:
\begin{itemize}
  \item Google Search
  \item live web documents
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Same logical pipeline}

\vspace{-4mm}
\begin{eqnarray*}
&& \text{Query}
\;\rightarrow\;
\text{Retrieve}
\;\rightarrow\; \\
&& \text{Context}
\;\rightarrow\;
\text{LLM}
\;\rightarrow\;
\text{Answer}
\end{eqnarray*}

\vspace{2mm}
\textbf{Key difference}

\begin{itemize}
  \item Local RAG: curated, controlled, static
  \item Google RAG: open, dynamic, up-to-date
\end{itemize}

\vspace{2mm}
\textbf{Interpretation}

The LLM does \emph{not} search —  
\y{it \emph{summarizes retrieved evidence}.}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec07.tex
% ================================================================================
% Lecture 7 — Slide XX+1
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Search to LLM Pipeline}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.4\textwidth}

\textbf{Pipeline steps}

\begin{enumerate}
  \item Issue search query
  \item Retrieve top-$k$ URLs
  \item Scrape page text
  \item Build context block
  \item Ask LLM to answer
\end{enumerate}

\vspace{0mm}
\raggedright
{\color{red}Answer = \\
LLM (Query, Web Evidence)}

\vspace{2mm}
\textbf{Important}

No embeddings are required —  
\y{ranking by Search Engine}.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.58\textwidth}

\vspace{-10mm}
\begin{codeonly}{Google--LLM pipeline (schematic)}
urls = search_google(query)
texts = [ scrape_website(url), 
  for url in urls ]

prompt = f"""
Answer the question using
the sources below.
Question: {query}
Sources: {texts}
"""

response = client.chat.completions.create( model="gpt-4o-mini",
  messages=[{"role":"user", "content":prompt}] )
\end{codeonly}

\end{column}

\end{columns}

\end{frame}
% ================================================================================
% E-AI Tutorial Slides
% Filename: lec07.tex
%
% Roland Potthast 2025/2026
% Licence: CC-BY4.0
% ================================================================================
\documentclass[aspectratio=169]{beamer}

% --- Load lecture macros --------------------------------------------------------
\input{../lec_macros.tex}
\newcommand{\LectureNumber}{Lecture 7}

% --- Document -------------------------------------------------------------------
\begin{document}

\setagendaboxforlecture{7}

\input{../lec_agenda.tex}
\input{lec07_01.tex}
\input{lec07_02.tex}
\input{lec07_03.tex}
\input{lec07_04.tex}
\input{lec07_05.tex}
\input{lec07_06.tex}
\input{lec07_07.tex}
\input{lec07_08.tex}
\input{lec07_09.tex}
\input{lec07_10.tex}
\input{lec07_11.tex}
\input{lec07_12.tex}
\input{lec07_13.tex}
\input{lec07_14.tex}
\input{lec07_15.tex}
\input{lec07_16.tex}
\input{lec07_17.tex}
\input{lec07_18.tex}
\input{lec07_19.tex}
\input{lec07_20.tex}
\input{lec07_21.tex}
\input{lec07_22.tex}
\input{lec07_23.tex}
\input{lec07_24.tex}
\input{lec07_25.tex}

% --- End Document ---------------------------------------------------------------
\end{document}
%!TEX root = lec08.tex
% ================================================================================
% Lecture 08 — Slide 01
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{What is Multimodal Artificial Intelligence?}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-2mm}
\textbf{Single-modality AI}

\begin{itemize}
  \item Classical ML processes one modality at a time
  \item Text-only LLMs operate on sequences of tokens
  \item Images, audio, or fields are handled separately
\end{itemize}

\vspace{2mm}
\textbf{Limitation}

\begin{itemize}
  \item No explicit link between different data modalities
  \item Limited representation of real-world information
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Multimodal AI}

\begin{itemize}
  \item Jointly processes multiple modalities
  \item Learns \rtext{relationships \emph{across} modalities}
  \item Typical inputs:
  \begin{itemize}
    \item text
    \item images
    \item audio
    \item spatial or physical fields
  \end{itemize}
\end{itemize}

\vspace{2mm}
\textbf{Key idea:}  
\y{Meaning emerges} from the \y{interaction of modalities}.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec08.tex
% ================================================================================
% Lecture 08 — Slide 02
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Why Multimodal AI in Weather and Climate?}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Nature of meteorological data}

\begin{itemize}
  \item Numerical model fields
  \item Maps and visualisations
  \item Radar and satellite images
  \item Textual forecasts and warnings
\end{itemize}

\vspace{2mm}
Weather information is inherently multimodal.

\vspace{3mm}
\includegraphics[width=6cm]{../../images/img08/coastal_fcst_00.png}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Human forecasters}

\begin{itemize}
  \item Integrate multiple information sources
  \item Combine perception and physical reasoning
  \item Translate observations into language
\end{itemize}

\vspace{2mm}
\textbf{Key question:}  
How can AI systems learn this integration?

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec08.tex
% ================================================================================
% Lecture 08 — Slide 03
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Example A: Symbolic Multimodality}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Basic idea}

\begin{itemize}
  \item Start from a physical wind field
  \item Extract a small set of \textbf{symbolic descriptors}
  \item Use a language model to generate text
\end{itemize}

\vspace{2mm}
The model does \emph{not} see images or full fields.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Representation pipeline}

\begin{itemize}
  \item Numerical wind field
  \item $\rightarrow$ symbolic spatial summary
  \item $\rightarrow$ text prompt
  \item $\rightarrow$ language model
\end{itemize}

\vspace{2mm}
Multimodality is achieved through \textbf{representation design}.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec08.tex
% ================================================================================
% Lecture 08 — Slide 04
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{From Wind Fields to Symbols}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Physical input}

\begin{itemize}
  \item Two-dimensional wind field
  \item Zonal and meridional components $(u,v)$
  \item Defined on a spatial grid
\end{itemize}

\vspace{2mm}
This information is high-dimensional and continuous.

\textbf{Symbolic reduction}

\begin{itemize}
  \item Mean wind speed
  \item Dominant wind direction
  \item Categorical intensity classes
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-10mm}
Use a small number of \emph{interpretable} features are retained.

\vspace{1mm}
\includegraphics[width=7cm]{../../images/img08/wind01_input_target_text.png}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec08.tex
% ================================================================================
% Lecture 08 — Slide 05
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Text Generation from Symbolic Descriptors}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{LLM input}

\begin{itemize}
  \item Short symbolic prompt
  \item Encodes physical properties
  \item Passed directly to the language model
\end{itemize}

\vspace{1mm}
{\footnotesize
\begin{lstlisting}
Mean wind speed: 15.2 m/s
Dominant direction: northwesterly
Region: North Sea
\end{lstlisting}
}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{LLM output}

\begin{itemize}
  \item Natural-language forecast text
  \item Generated solely from symbolic input
\end{itemize}

\vspace{1mm}
{\footnotesize
\begin{lstlisting}
Strong northwesterly winds with
speeds around 15 m/s over the
North Sea.
\end{lstlisting}
}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec08.tex
% ================================================================================
% Lecture 08 — Slide 06
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Example A: Core Implementation Idea}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.35\textwidth}

\textbf{Step 1: Symbolic preprocessing}

\begin{itemize}
  \item Reduce the wind field to a few key descriptors
  \item Physics-informed, human-designed
  \item Low-dimensional and interpretable
\end{itemize}

\vspace{2mm}
\rtext{This step encodes \emph{what matters} for the language model.}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.66\textwidth}

\textbf{Step 2: Prompt-based text generation}

\begin{codeonly}{Symbolic prompt and text generation}
summary = f"Mean speed: {vmean:.1f} m/s, "
summary += f"Direction: {direction}"

inputs = tokenizer(
    summary,
    return_tensors="pt"
)

outputs = model.generate(**inputs)
\end{codeonly}

\vspace{1mm}
In this example the \y{LLM sees only text, not physics}.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec08.tex
% ================================================================================
% Lecture 08 — Slide 07
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Example A: Result on a Concrete Wind Field}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Physical input}

\begin{itemize}
  \item Synthetic wind field over the North Sea
  \item Used to compute symbolic descriptors
  \item Image shown here for illustration
\end{itemize}

\textbf{Generated text (Example A)}

\begin{itemize}
  \item Language model sees only \rtext{\bf symbolic input}
  \item \y{No image is passed to the model}
\end{itemize}


\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-2mm}
\includegraphics[width=\linewidth]{../../images/img08/wind02_test_case.png}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec08.tex
% ================================================================================
% Lecture 08 — Slide 08
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Example B: Visual Multimodality}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Key difference to Example A}

\begin{itemize}
  \item No symbolic preprocessing
  \item No explicit speed or direction given
  \item The model receives an \textbf{image only}
  \item Converted to RGB pixel values
\end{itemize}

\vspace{2mm}
All physical structure must be inferred visually.

{\tiny
\begin{lstlisting}
# Draw the canvas
fig.canvas.draw()

buf = np.asarray(fig.canvas.buffer_rgba())
image = buf[..., :3]   # drop alpha channel

# Normalize to [0, 1]
return image.astype(np.float32) / 255.0
\end{lstlisting}
}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Multimodal processing pipeline}

\begin{itemize}
  \item Wind field rendered as image
  \item Vision encoder extracts features
  \item Features are mapped to language space
  \item Language model generates text
\end{itemize}

\vspace{2mm}
This is \emph{true} multimodal learning.

\vspace{1mm}
{\tiny
\begin{lstlisting}
# -----------------------------------------
# Render the wind field as an image
# This image is the ONLY input seen by
# the multimodal model.
# -----------------------------------------
img = render_wind_image(LON, LAT, U, V)
\end{lstlisting}
}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec08.tex
% ================================================================================
% Lecture 08 — Slide 09
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{From Image Tensor to Vision Embedding}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.35\textwidth}

\textbf{Vision encoder (ViT)}

\begin{itemize}
  \item Input: \y{image tensor} $(1, 3, 224, 224)$
  \item Image is split into patches
  \item Self-attention models spatial relations
\end{itemize}

\vspace{2mm}
The vision model extracts a \y{high-level representation}
of the entire image.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.63\textwidth}

\vspace{-2mm}
\textbf{Forward pass and feature extraction}

\begin{codeonly}{Vision Transformer}
with torch.no_grad():
    vision_out = vit(
        pixel_values=pixel_values )

# Global image representation
vision_feat = (
    vision_out.last_hidden_state[:,0,:]
)  # CLS token
\end{codeonly}

\vspace{1mm}
The \y{CLS token} summarizes the full image content.

\vspace{3mm}
{\footnotesize
$\texttt{img} \in \mathbb{R}^{224\times224\times3}
\;\rightarrow\;
\texttt{vision\_feat} \in \mathbb{R}^{1\times768}$ \\
$\text{CLS token} \in \mathbb{R}^{768}$ — a learned global image representation
}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec08.tex
% ================================================================================
% Lecture 08 — Slide 10
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{From Vision Embedding to Language Model Input}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.38\textwidth}

\textbf{The modality gap}

\begin{itemize}
  \item Vision encoder outputs \y{visual embeddings}
  \item Language models expect \y{text embeddings}
  \item Both live in different representation spaces
\end{itemize}

\vspace{2mm}
A learned projection is required to connect
vision and language.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.6\textwidth}

\vspace{-2mm}
\textbf{Vision--language bridge}

\begin{codeonly}{Project vision features into language space}
# vision features -> embedding 
encoder_embed = bridge( vision_feat
	).unsqueeze(1)

# Pass embeddings to the T5 encoder
outputs = t5(
    inputs_embeds=encoder_embed,
    labels=labels )
\end{codeonly}

\vspace{1mm}
The language model receives embeddings,
not tokens.

\vspace{3mm}
{\footnotesize
$\text{CLS} \in \mathbb{R}^{768}
\;\xrightarrow{\text{Linear projection}}\;
\text{encoder\_embed} \in \mathbb{R}^{1 \times 1 \times 512}$
}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec08.tex
% ================================================================================
% Lecture 08 — Slide 11
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Example B: Results on Unseen Wind Fields}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}

\textbf{Model input}

\begin{itemize}
  \item Wind field rendered as an image
  \item \y{No symbolic or numerical input}
  \item Image only, unseen during training
\end{itemize}

\vspace{2mm}
\rtext{The model infers direction and strength
{\bf from visual structure alone.}}
\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.54\textwidth}

\vspace{-2mm}
\includegraphics[width=8cm]{../../images/img08/wind05_test_ViT.png}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec08.tex
% ================================================================================
% Lecture 08 — Vision Transformer — Slide A
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Vision Transformer: Patch Embedding}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Image representation}

An \y{input image} is represented as
\[
\mathbf{x} \in \mathbb{R}^{H \times W \times 3}
\]

\begin{itemize}
  \item $H, W$: image height and width (pixels)
  \item $3$: RGB color channels
\end{itemize}

\vspace{2mm}
The image is split into non-overlapping patches
of size $P \times P$.

\vspace{1mm}
Number of patches:
\[
N = \frac{H \cdot W}{P^2}
\]

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Patch embedding}

Each image patch is flattened:
\[
\mathbf{x}_p \in \mathbb{R}^{P^2 \cdot 3}
\]

and projected into an embedding space:
\[
\mathbf{x}_p
\;\xrightarrow{\;E\;}\;
\mathbf{z}_p \in \mathbb{R}^{D}
\]

\vspace{2mm}
The full input sequence is:
\[
\mathbf{Z}_0 =
[\mathbf{z}_{\text{CLS}}, \mathbf{z}_1, \dots, \mathbf{z}_N]
\in \mathbb{R}^{(N+1) \times D}
\]

\vspace{1mm}
$D$ is the \y{transformer embedding} dimension.

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec08.tex
% ================================================================================
% Lecture 08 — Vision Transformer — Slide B
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Vision Transformer: Self-Attention}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{\y{Transformer} processing}

The patch embedding sequence is processed by
$L$ stacked transformer layers:
\begin{eqnarray*}
\mathbf{Z}_{\ell+1}
& = & \text{Transformer}(\mathbf{Z}_{\ell}), \\
&& \quad \ell = 0,\dots,L-1
\end{eqnarray*}

\vspace{2mm}
Each layer consists of:
\begin{itemize}
  \item \rtext{Multi-head self-attention}
  \item \rtext{Feed-forward networks}
  \item \rtext{Residual connections} $x + {\cal F}(x)$
  \item \rtext{Layer normalization}
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-3mm}
\textbf{CLS token as global image embedding}

\vspace{2mm}
Self-attention enables each patch to attend
to all other patches.

\vspace{2mm}
After the final layer, the CLS token is:
\[
\mathbf{z}_{\text{CLS}}^{(L)} \in \mathbb{R}^{D}
\]

\vspace{2mm}
\y{This vector represents the entire image} and
can be used for:
\begin{itemize}
  \item Image classification
  \item Regression tasks
  \item Multimodal conditioning of language models
\end{itemize}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec08.tex
% ================================================================================
% Lecture 08 — Slide 14
% ================================================================================
\begin{frame}[t]

\mytitle{Radar Reflectivity as Multimodal Input}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Weather radar data}

\begin{itemize}
  \item Active remote sensing (microwave)
  \item Measures backscattered power
  \item Proxy for precipitation intensity
\end{itemize}

\vspace{2mm}
Radar reflectivity is expressed in
\[
\text{dBZ} = 10 \log_{10}(Z)
\]

\vspace{1mm}
with $Z$ the radar reflectivity factor.

\vspace{2mm}
Radar images are routinely interpreted visually by forecasters.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-1cm}
\includegraphics[width=7cm]{../../images/img08/radar_map_germany_crop.png}

\vspace{-1mm}
{\footnotesize
DWD radar composite with state borders.
Colors indicate reflectivity intensity (dBZ).
}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec08.tex
% ================================================================================
% Lecture 08 — Slide 15
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{From Radar Product to AI-Readable Image}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.43\textwidth}

\textbf{Operational radar data}

\begin{itemize}
  \item Provided as HDF5 files
  \item Contains data and metadata
  \item Scaling and masking required
\end{itemize}

\vspace{2mm}
Physical decoding:
\begin{itemize}
  \item apply gain and offset
  \item mask undetectable values
  \item remove non-physical signals
\end{itemize}

\vspace{2mm}
Result: a georeferenced reflectivity field.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.55\textwidth}

\begin{codeonly}{Decode radar reflectivity}
raw = f["dataset1/data1/data"][:]

gain   = what.attrs["gain"]
offset = what.attrs["offset"]

data = raw.astype(np.float32) * gain + offset
data[(raw == 0) | (raw == 65535) | (data < 0)] = np.nan
\end{codeonly}

\vspace{2mm}
This step preserves physical meaning before visualization.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec08.tex
% ================================================================================
% Lecture 08 — Slide 16
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Radar as Image Modality}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}

\vspace{-2mm}
\textbf{Why visualization matters}

\begin{itemize}
  \item Radar fields are spatial data
  \item Interpretation relies on patterns
  \item Humans read radar as images
\end{itemize}

\vspace{0mm}
For multimodal AI, the radar field is therefore
converted into a \y{\textbf{visual representation}}:

\begin{itemize}
  \item color encodes intensity (dBZ)
  \item white indicates missing / no signal
  \item borders provide spatial context
\end{itemize}

\vspace{0mm}
The \y{image} becomes the\\ 
\hspace{2cm} \y{AI input modality.}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.58\textwidth}

\vspace{-10mm}
\begin{codeonly}{Render radar reflectivity map}
masked = np.ma.masked_invalid(data)
plt.figure(figsize=(12, 10))
ax = plt.axes(projection=ccrs.PlateCarree())
ax.set_extent([3, 17, 44, 56])
im = ax.imshow(
    masked, origin="lower",
    cmap=cmap, vmin=0, vmax=40,
    transform=ccrs.PlateCarree() )

ax.add_feature(cfeature.BORDERS)
ax.coastlines(resolution="10m")
plt.colorbar(im, ax=ax, label="Reflectivity (dBZ)")
plt.savefig("radar_map_germany.png", dpi=150)
\end{codeonly}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec08.tex
% ================================================================================
% Lecture 08 — Slide 17
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Multimodal AI Interpretation of Radar Images}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.43\textwidth}

\textbf{Multimodal model input}

The AI model receives:
\begin{itemize}
  \item a radar image (\y{visual modality})
  \item a \y{textual instruction} (language modality)
\end{itemize}

\vspace{1mm}
The model jointly reasons over:
\begin{itemize}
  \item spatial precipitation patterns
  \item reflectivity intensity gradients
  \item mesoscale structure
\end{itemize}

\vspace{1mm}
The {\bf output} is a \y{natural-language}
meteorological interpretation.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.56\textwidth}

\vspace{-4mm}
\begin{codeonly}{Multimodal AI request}
query = "Please interpret this radar reflectivity image ..."
response = client.chat.completions.create(
  model="gpt-4-turbo",
  messages=[{ "role": "user",
    "content": [
    {"type": "text", "text": query},
    {"type": "image_url",
    "image_url": {"url": f"data:image/png;base64,{encoded}"
         }} ] }],
  max_tokens=800 )
\end{codeonly}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec08.tex
% ================================================================================
% Lecture 08 — Slide 18
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Example: AI-Generated Radar Interpretation}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.45\textwidth}

\textbf{Input to the model}

\begin{itemize}
  \item Radar reflectivity image (dBZ)
  \item Geographical context (Germany)
  \item Task-oriented meteorological prompt
\end{itemize}

\vspace{2mm}
The AI has no direct access to:
\begin{itemize}
  \item numerical radar grids
  \item timestamps or motion
  \item physical radar equations
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.53\textwidth}

\begin{minipage}{7cm}
\footnotesize\sl
This radar reflectivity image shows precipitation distribution and intensity across Germany and parts of its neighboring countries, indicated by different colors reflecting different reflectivity values measured in dBZ (decibels of Z). Here's a detailed analysis:

\vspace{2mm}
[...]
Stratiform Rainfall: The majority of the precipitation patterns, especially the widespread areas with uniform green shades in the northern and southwestern parts, suggest stratiform precipitation structures. These are typically smooth and consistent patterns associated with frontal systems or broad-scale upward motions that produce persistent and uniform rainfall.
\end{minipage}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec08.tex
% ================================================================================
% Lecture 08 — Slide 19
% ================================================================================
\begin{frame}[t]

\mytitle{Capabilities and Limitations of Multimodal Radar Interpretation}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{What the model can do well}

\begin{itemize}
  \item Identify precipitation regions
  \item Distinguish weak vs.\ strong reflectivity
  \item Recognize spatial patterns
  \item Describe convective vs.\ stratiform structures
\end{itemize}

\vspace{2mm}
This closely mirrors human visual interpretation.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Key limitations}

\begin{itemize}
  \item No access to raw radar measurements
  \item No temporal information (single snapshot)
  \item No physical thresholds or calibration
  \item Interpretation depends on visualization choices
\end{itemize}

\vspace{2mm}
The model provides \emph{descriptive insight},  
not quantitative meteorological analysis.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec08.tex
% ================================================================================
% Lecture 08 — Slide 20
% ================================================================================
\begin{frame}[t]

\mytitle{Cloud Top Height as Multimodal Input}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.49\textwidth}

\vspace{-1mm}
\textbf{What is Cloud Top Height (CTH)?}

\begin{itemize}
  \item Satellite-derived cloud product
  \item Estimates height of the upper cloud boundary
  \item Derived from thermal infrared observations
\end{itemize}

\vspace{0mm}
CTH is typically expressed in meters above sea level
and provides information on:
\begin{itemize}
  \item vertical cloud structure
  \item convective depth
  \item storm intensity
\end{itemize}


\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\includegraphics[width=\linewidth]{../../images/img08/cth_map.png}

\vspace{1mm}
{\footnotesize
Satellite-derived Cloud Top Height (CTH) over Central Europe.
Higher values correspond to deeper cloud systems.
}

\end{column}

\end{columns}

\vspace{1mm}
High CTH values often indicate \y{deep convection}.

\end{frame}
%!TEX root = lec08.tex
% ================================================================================
% Lecture 08 — Slide 21
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Accessing Cloud Top Height (CTH) Data}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.41\textwidth}

\textbf{Operational satellite product}

\begin{itemize}
  \item Provided by DWD Open Data
  \item Derived from geostationary satellites
  \item Updated at regular intervals
\end{itemize}

\vspace{0mm}
CTH data is distributed as:
\begin{itemize}
  \item compressed NetCDF files (\texttt{.nc.bz2})
  \item regular latitude--longitude grids
  \item physical units: meters
\end{itemize}

\vspace{0mm}
\footnotesize
The latest available file is selected automatically.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.61\textwidth}

\vspace{-5mm}
\begin{codeonly}{Download latest CTH product}
base_url = (
  "https://opendata.dwd.de/weather/"
  "satellite/clouds/CTH/")
response = requests.get(base_url)
soup = BeautifulSoup(response.text, "html.parser")
cth_files = sorted([ link.get("href")
  for link in soup.find_all("a")
  if link.get("href", "").endswith(".nc.bz2") ])
my_f = cth_files[-1]
url = urljoin(base_url,my_f)
with open("cth.nc.bz2", "wb") as f:
    f.write(requests.get(url).content)
\end{codeonly}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec08.tex
% ================================================================================
% Lecture 08 — Slide 22
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Multimodal AI Interpretation of Cloud Top Height}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.38\textwidth}

\textbf{Model input}

The AI model receives:
\begin{itemize}
  \item a Cloud Top Height image
  \item a task-oriented text prompt
\end{itemize}

\vspace{0mm}
The task focuses on:
\begin{itemize}
  \item identifying regions of high cloud tops
  \item distinguishing deep convection from stratiform clouds
  \item describing large-scale cloud structures
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.62\textwidth}

\vspace{-3mm}
\begin{codeonly}{Submit CTH image to multimodal LLM}
query = "This is a satellite-derived Cloud Top Height image  [...]"
response = client.chat.completions.create(
  model="gpt-4-turbo",
  messages=[{"role": "user",
   "content": [
    {"type": "text", "text": query},
    {"type": "image_url", "image_url":{
    "url": f"data:image/png;base64,{encoded}" }} ] }],
    max_tokens=800,)
\end{codeonly}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec08.tex
% ================================================================================
% Lecture 08 — Slide 23
% ================================================================================
\begin{frame}[t]

\mytitle{Multimodal AI in Weather: Comparison and Takeaways}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}

\vspace{-2mm}
\textbf{Four \y{multimodal examples}}

\vspace{1mm}
\begin{itemize}
  \item \textbf{Synthetic wind fields (A)}
    \begin{itemize}
      \item physical feature extraction
      \item numerical fields $\rightarrow$ text
    \end{itemize}

  \item \textbf{Synthetic wind fields (B)}
    \begin{itemize}
      \item image-based representation
      \item learned visual perception
    \end{itemize}

  \item \textbf{Radar reflectivity}
    \begin{itemize}
      \item precipitation structure
      \item surface-reaching hydrometeors
    \end{itemize}

  \item \textbf{Cloud Top Height (CTH)}
    \begin{itemize}
      \item vertical cloud structure
      \item deep convection indicators
    \end{itemize}
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.56\textwidth}

\vspace{-2mm}
\textbf{Key insights}

\begin{itemize}
  \item Multimodal AI reasons over images and text
  \item Physical meaning enters via \y{representation}
  \item Visualization choices matter
  \item Models provide \emph{interpretation}, not physics
  \item How \y{Vision Transformers} (ViT) work
\end{itemize}

\vspace{2mm}
\textbf{Outlook}

\begin{itemize}
  \item combining \y{multiple modalities}
  \item adding temporal context
  \item integrating AI with NWP systems
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec08.tex
% ================================================================================
% Lecture 08 — Slide 24
% ================================================================================
\begin{frame}[t]

\mytitle{Multimodal Models Available at OpenAI}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\textbf{GPT-4 family}

\begin{itemize}
  \item First widely deployed multimodal models
  \item Text and image input
  \item Text output
  \item Strong vision-language reasoning
\end{itemize}

\vspace{0mm}
Typical use cases:
\begin{itemize}
  \item image interpretation
  \item document understanding
  \item visual question answering
\end{itemize}

\vspace{2mm}
Used extensively in early multimodal
weather and geoscience applications.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}

\vspace{-7mm}
\textbf{GPT-5 family}

\begin{itemize}
  \item Current OpenAI foundation model generation
  \item Native multimodal reasoning
  \item Text and image input
  \item Text output with improved reasoning depth
\end{itemize}

\vspace{0mm}
Key characteristics:
\begin{itemize}
  \item stronger cross-modal alignment
  \item improved robustness and consistency
  \item better handling of complex visual scenes
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec08.tex
% ================================================================================
% Lecture 08 — Slide XX
% ================================================================================
\begin{frame}[t]

\mytitle{Multimodal AI on IONOS}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{IONOS AI Model Hub}

\vspace{2mm}
Provides a curated set of foundation models via
an OpenAI-compatible API endpoint.

\vspace{2mm}
\textbf{Available model categories}

\begin{itemize}
  \item Text-only language models
  \item Embedding models
  \item Image generation models
  \item \textbf{One vision--language model}
\end{itemize}

\vspace{2mm}
Most models remain text-only.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-8mm}
\textbf{Multimodal image understanding}

\vspace{2mm}
\textbf{Mistral Small 24B}

\begin{itemize}
  \item Input: text + image
  \item Output: text
  \item Tool calling supported
  \item OpenAI-compatible chat schema
\end{itemize}

\vspace{2mm}
Successfully used to interpret:
\begin{itemize}
  \item radar reflectivity images
  \item cloud top height (CTH) maps
\end{itemize}

\vspace{2mm}
\emph{Selective but production-grade multimodality.}

\end{column}

\end{columns}

\end{frame}
% ================================================================================
% E-AI Tutorial Slides
% Filename: lec08.tex
%
% Roland Potthast 2025/2026
% Licence: CC-BY4.0
% ================================================================================
\documentclass[aspectratio=169]{beamer}

% --- Load lecture macros --------------------------------------------------------
\input{../lec_macros.tex}
\newcommand{\LectureNumber}{Lecture 8}

% --- Document -------------------------------------------------------------------
\begin{document}

\setagendaboxforlecture{8}

\input{../lec_agenda.tex}
\input{lec08_01.tex}
\input{lec08_02.tex}
\input{lec08_03.tex}
\input{lec08_04.tex}
\input{lec08_05.tex}
\input{lec08_06.tex}
\input{lec08_07.tex}
\input{lec08_08.tex}
\input{lec08_09.tex}
\input{lec08_10.tex}
\input{lec08_11.tex}
\input{lec08_12.tex}
\input{lec08_13.tex}
\input{lec08_14.tex}
\input{lec08_15.tex}
\input{lec08_16.tex}
\input{lec08_17.tex}
\input{lec08_18.tex}
\input{lec08_19.tex}
\input{lec08_20.tex}
\input{lec08_21.tex}
\input{lec08_22.tex}
\input{lec08_23.tex}
\input{lec08_24.tex}
\input{lec08_25.tex}

% --- End Document ---------------------------------------------------------------
\end{document}
%!TEX root = lec09.tex
% ================================================================================
% Lecture 9 — Slide 01
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Lecture 9 — Diffusion and Flexible Graph Networks}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{From prediction to distributions}

\begin{itemize}
  \item Classical ML: predict a single output
  \item Reality: many plausible outcomes
  \item We need models that \emph{sample}
\end{itemize}

\vspace{2mm}
Weather and climate are inherently:
\begin{itemize}
  \item stochastic
  \item high-dimensional
  \item uncertain
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Two complementary ideas}

\begin{itemize}
  \item \y{Diffusion models}  
        learn how to turn noise into structure
  \item \y{Graph neural networks}  
        learn from \rtext{sparse, irregular observations}
\end{itemize}

\vspace{3mm}
\textbf{Key message}

\begin{itemize}
  \item Learn \emph{distributions}, not just functions
  \item Learn \emph{structure}, not just grids
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec09.tex
% ================================================================================
% Lecture 9 — Slide 02
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Learning to Sample a Distribution}

\begin{columns}[T,totalwidth=\textwidth]

\begin{column}[T]{0.48\textwidth}

\textbf{Regression is not enough}

\begin{itemize}
  \item Regression predicts a single value
  \item Many systems have multiple valid outcomes
  \item We need to model and sample the \y{uncertainty}!
  \item We want samples: $x \sim p(x)$
\end{itemize}

\vspace{2mm}
\textbf{Key idea}

\begin{itemize}
  \item Learn a \emph{mapping from noise to data}
  \item Noise represents uncertainty
\end{itemize}

\end{column}

\begin{column}[T]{0.48\textwidth}

\includegraphics[width=\textwidth]{../../images/img09/1_distribution.png}

\vspace{1mm}
\centering
Target distribution

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec09.tex
% ================================================================================
% Lecture 9 — Slide 03
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Sampling via a Neural Network}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.56\textwidth}

\textbf{Neural sampler: noise $\rightarrow$ data}

\begin{codeonly}{Neural generator mapping noise to samples}
class Generator(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(1, 64),
            nn.ReLU(),
            nn.Linear(64, 64),
            nn.ReLU(),
            nn.Linear(64, 1) )

    def forward(self, z):
        return self.net(z)
\end{codeonly}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.4\textwidth}

\vspace{-9mm}
The network transforms white noise into samples.

\vspace{2mm}
\textbf{What is different from regression?}

\begin{itemize}
  \item No target output for a given input
  \item Input is random noise
  \item Only the \emph{distribution} matters
\end{itemize}

\vspace{2mm}
\textbf{Interpretation}

\begin{itemize}
  \item $z \sim \mathcal{N}(0,1)$
  \item $x = f_\theta(z) \sim p_\theta(x)$
\end{itemize}

\footnotesize
\begin{lstlisting}
z = torch.randn(N, 1) # noise
x = G(z)           # samples
\end{lstlisting}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec09.tex
% ================================================================================
% Lecture 9 — Slide 04
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Training without Targets: Distribution Matching}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.6\textwidth}

\textbf{Key problem}

There is no correct output $x$ \\
for a given noise input $z$.

\vspace{2mm}
\textbf{Solution: \y{compare distributions}}

\vspace{2mm}
\begin{codeonly}{Differentiable distribution loss (1D Wasserstein)}
def wasserstein_1d(x_gen, x_data):
  xg, _ = torch.sort(x_gen.view(-1))
  xd, _ = torch.sort(x_data.view(-1))
  return torch.mean((xg - xd)**2)
\end{codeonly}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.38\textwidth}

\vspace{-2mm}
\textbf{What happens here?}

\begin{itemize}
  \item Draw samples from both distributions
  \item Sort them by value
  \item Compare \emph{quantiles}
\end{itemize}

\vspace{2mm}
\textbf{Interpretation}

\begin{itemize}
  \item We do not match samples
  \item We match \y{ranks / transport}
\end{itemize}

\vspace{2mm}
This turns sampling into a learnable problem.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec09.tex
% ================================================================================
% Lecture 9 — Slide 05
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Learning to Sample a Distribution}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.42\textwidth}

\textbf{Training result}

\begin{itemize}
  \item Network maps noise to samples
  \item Generated samples follow $p(x)$
  \item Multimodal structure is recovered
\end{itemize}

\vspace{2mm}
\textbf{Key point}

\begin{itemize}
  \item No regression target was used
  \item Only a distribution loss
\end{itemize}

\vspace{2mm}
This already enables stochastic modeling.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.56\textwidth}

\includegraphics[width=\textwidth]{../../images/img09/1_sampling.png}

\vspace{1mm}
\centering
Target distribution and generated samples

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec09.tex
% ================================================================================
% Lecture 9 — Slide 06
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Why One-Step Sampling Is Not Enough}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.57\textwidth}

\textbf{What we did so far}

\begin{itemize}
  \item Learn a direct map: noise $\rightarrow$ data
  \item Works well in low dimensions
  \item Works for simple distributions
\end{itemize}

\vspace{2mm}
\textbf{But this has limits}

\begin{itemize}
  \item \y{High-dimensional distributions are complex}
  \item Direct mapping becomes unstable
  \item Hard to represent fine structure
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.4\textwidth}

\vspace{-2mm}
\textbf{Key idea}

\begin{itemize}
  \item Do not sample in one step
  \item \y{Use many small, simple steps}
\end{itemize}

\vspace{2mm}
\textbf{Intuition}

\begin{itemize}
  \item Large transport is hard
  \item Small corrections are easy
\end{itemize}

\vspace{2mm}
This leads to \y{diffusion models}.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec09.tex
% ================================================================================
% Lecture 9 — Slide 07
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Forward Diffusion: Adding Noise Step by Step}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.55\textwidth}

\textbf{Forward process}

We gradually destroy structure by adding noise:
\[
x_t = \sqrt{\bar{\alpha}_t}\,x_0
     + \sqrt{1-\bar{\alpha}_t}\,\epsilon,
\quad \epsilon \sim \mathcal{N}(0,1)
\]

\vspace{2mm}
\begin{itemize}
  \item $t = 0$: clean data
  \item $t \uparrow$: increasing noise
  \item $t = T$: pure noise
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.4\textwidth}

\vspace{-2mm}
\textbf{Important properties}

\begin{itemize}
  \item Process is \y{fixed}
  \item No learning involved
  \item Fully known statistics
\end{itemize}

\vspace{2mm}
\textbf{Why do this?}

\begin{itemize}
  \item Generates training data
  \item Connects data to noise
\end{itemize}

\vspace{2mm}
This defines the learning problem.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec09.tex
% ================================================================================
% Lecture 9 — Slide 08
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Reverse Diffusion: Learning to Denoise}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.6\textwidth}

\textbf{Idea:} Train a network to \\
\hspace{2cm}\y{remove a \emph{small amount of noise}:}
\[
x_t \;\longrightarrow\; x_{t-1}
\]

\vspace{-1mm}
\begin{codeonly}{Denoising step (learned reverse process)}
# x_t : noisy signal at step t
# model learns to predict a less noisy version

for t in reversed(range(1, T)):
  x = model(x, t) # denoise one step
\end{codeonly}

\vspace{1mm}
Each step is simple and stable.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.38\textwidth}

\vspace{-2mm}
\textbf{Training principle}

\begin{itemize}
  \item Start from clean signal $x_0$
  \item Add noise step by step
  \item Train the model to undo each step
\end{itemize}

\vspace{2mm}
\textbf{Key point}

\begin{itemize}
  \item Same network for all steps
  \item Only local corrections
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec09.tex
% ================================================================================
% Lecture 9 — Slide 08
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Diffusion in Action: Example Result}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.55\textwidth}

\vspace{-4mm}
\includegraphics[width=\textwidth]{../../images/img09/2_diffusion_final.png}

\vspace{-2mm}
\includegraphics[width=\textwidth]{../../images/img09/2_diffusion_steps.png}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.4\textwidth}

\textbf{What we see}

\begin{itemize}
  \item Start from pure noise
  \item Apply learned denoising steps
  \item End up with valid samples
\end{itemize}

\vspace{2mm}
\textbf{Key observation}

\begin{itemize}
  \item Samples follow the target distribution
  \item Stochastic but structured
\end{itemize}

\vspace{2mm}
This is \y{sampling by refinement}, not regression.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec09.tex
% ================================================================================
% Lecture 9 — Slide 10
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Forward Diffusion Process}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.62\textwidth}

Let $x_0 \sim p_{\text{data}}(x)$ be a data sample.

\vspace{1mm}
The \y{forward diffusion} process is a Markov chain:
\[
q(x_{1:T} \mid x_0)
= \prod_{t=1}^T q(x_t \mid x_{t-1})
\]

with Gaussian transitions
\[
q(x_t \mid x_{t-1})
= \mathcal{N}\!\left(
x_t;\, \sqrt{1-\beta_t}\,x_{t-1},\, \beta_t I
\right),
\]
with $\beta_t \in (0,1)$. 

\vspace{1mm}
Equivalently, each step can be written as
{\color{red}
\[
x_t = \sqrt{1-\beta_t}\,x_{t-1} + \sqrt{\beta_t}\,\epsilon_t,
\quad \epsilon_t \sim \mathcal{N}(0,I).
\]
}
\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.36\textwidth}

\vspace{-1mm}
\textbf{Consequences}

\begin{itemize}
  \item Mean is damped at each step
  \item Variance increases monotonically
  \item Signal-to-noise ratio decreases
\end{itemize}

\vspace{1mm}
After many steps:
\[
x_T \;\approx\; \mathcal{N}(0,I)
\]

\vspace{1mm}
This \y{connects data} to \y{pure noise}.

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec09.tex
% ================================================================================
% Lecture 9 — Slide 11
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Closed-Form Forward Diffusion}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.62\textwidth}

Because all forward steps are Gaussian, the marginal
distribution of $x_t$ given $x_0$ has a closed form:
\[
q(x_t \mid x_0)
= \mathcal{N}\!\left(
x_t;\, \sqrt{\bar{\alpha}_t}\,x_0,\,
(1-\bar{\alpha}_t) I
\right)
\]

with cumulative noise factor
\[
\bar{\alpha}_t
= \prod_{s=1}^t (1-\beta_s).
\]

\vspace{1mm}
Equivalently, sampling can be written as
\[
x_t
= \sqrt{\bar{\alpha}_t}\,x_0
+ \sqrt{1-\bar{\alpha}_t}\,\epsilon,
\quad \epsilon \sim \mathcal{N}(0,I).
\]

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.36\textwidth}

\vspace{-1mm}
\textbf{Interpretation}

\begin{itemize}
  \item Signal amplitude decays with $\sqrt{\bar{\alpha}_t}$
  \item Noise amplitude grows with $\sqrt{1-\bar{\alpha}_t}$
  \item $t$ directly controls noise level
\end{itemize}

\vspace{1mm}
As $t \to T$:
\[
\bar{\alpha}_t \to 0
\quad \Rightarrow \quad
x_t \sim \mathcal{N}(0,I).
\]

\vspace{1mm}
This matches the example exactly.

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec09.tex
% ================================================================================
% Lecture 9 — Slide 12
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Reverse Diffusion Process}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.62\textwidth}

The reverse process aims to invert the forward diffusion:
\[
p_\theta(x_{0:T})
= p(x_T)\prod_{t=1}^T p_\theta(x_{t-1} \mid x_t),
\]
with $p(x_T)=\mathcal{N}(0,I)$. 

\vspace{1mm}
Each reverse step is modeled as a Gaussian:
\[
p_\theta(x_{t-1} \mid x_t)
= \mathcal{N}\!\left(
x_{t-1};\, \mu_\theta(x_t,t),\, \Sigma_t
\right),
\]
where $\mu_\theta$ is predicted by a neural network.

\vspace{1mm}
The variance $\Sigma_t$ is usually fixed or predefined.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.36\textwidth}

\vspace{-1mm}
\textbf{What is learned?}

\begin{itemize}
  \item Only the conditional mean
  \item One network for all $t$
  \item Local denoising steps
\end{itemize}

\vspace{1mm}
\textbf{Key idea}

Each reverse step removes
\y{a small amount of noise}.

\vspace{1mm}
This turns sampling into a sequence
of simple corrections.

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec09.tex
% ================================================================================
% Lecture 9 — Slide 13
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Why Diffusion Sampling Is Correct}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}

Assume a scalar Gaussian data distribution:
\[
x_0 \sim \mathcal{N}(\mu_0,\sigma_0^2),
\quad x_1 = x_0 + \epsilon,
\]
with $\epsilon \sim \mathcal{N}(0,\sigma^2)$. 

\vspace{1mm}
The optimal denoiser (MSE sense) is:
\[
f^*(x_1) = \mathbb{E}[x_0 \mid x_1]
= \frac{\sigma^2 \mu_0 + \sigma_0^2 x_1}{\sigma_0^2 + \sigma^2}.
\]

This pulls the noisy sample toward $\mu_0$,
but \emph{reduces variance}.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-1mm}
\textbf{Key observation}

\begin{itemize}
  \item Denoising alone shrinks variance
  \item Mean is biased toward $\mu_0$
\end{itemize}

\vspace{1mm}
\textbf{Therefore}

To recover the full distribution,
we must sample:
\[
x_0 = f^*(x_1) + \sqrt{\sigma_{\text{post}}^2}\,\xi,
\quad \xi \sim \mathcal{N}(0,1).
\]

\vspace{1mm}
This is exactly what diffusion does
at every step.

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec09.tex
% ================================================================================
% Lecture 9 — Slide 14
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Why Graph Networks?}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.55\textwidth}

\textbf{The problem}

\begin{itemize}
  \item \y{Data is sparse, irregular, incomplete}
  \item Classical grids assume full coverage
  \item Interpolation rules are often fixed
\end{itemize}

\vspace{2mm}
In many applications, we only know values at
\begin{itemize}
  \item a few locations,
  \item irregular positions,
  \item changing resolutions.
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.4\textwidth}

\vspace{-6mm}
\textbf{The graph perspective}

\begin{itemize}
  \item Nodes represent \y{locations}
  \item Edges represent \y{influence} / neighborhood
  \item Features store values and metadata
\end{itemize}

\vspace{2mm}
\textbf{Key idea}

\begin{itemize}
  \item \y{Geometry} is encoded in the graph
  \item \rtext{Learning happens locally}
  \item Same model works on different domains
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec09.tex
% ================================================================================
% Lecture 9 — Slide 15
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Graph Example: Reconstructing a Function from Sparse Data}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.55\textwidth}

\textbf{Setup}

\begin{itemize}
  \item 1D spatial domain discretized into nodes
  \item True function $f(x)$ defined on all nodes
  \item Observations available only at few locations
\end{itemize}

\vspace{2mm}
Each node carries:
\begin{itemize}
  \item observed value (or zero if missing)
  \item a binary observation mask
\end{itemize}

\vspace{2mm}
The task is to reconstruct $f(x)$ at \emph{all} nodes.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.4\textwidth}

\includegraphics[width=\textwidth]{../../images/img09/gnn_obs_naive_j1_jj1_0.png}

\vspace{1mm}
\centering
Sparse observations and GNN reconstruction

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec09.tex
% ================================================================================
% Lecture 9 — Slide 16
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Message Passing: How Information Flows}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.55\textwidth}

\textbf{Local updates}

Each node updates its state by combining:
\begin{itemize}
  \item its own current value,
  \item information from neighboring nodes.
\end{itemize}

\vspace{2mm}
This update is \emph{learned}, not prescribed.

\vspace{2mm}
\textbf{Key mechanism}

\begin{itemize}
  \item Same update rule for all nodes
  \item Shared parameters across the graph
  \item Repeated over multiple layers
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.4\textwidth}

\textbf{Interpretation}

\begin{itemize}
  \item Observations act as sources
  \item Information spreads gradually
  \item Missing values are inferred
\end{itemize}

\vspace{2mm}
\textbf{Why this matters}

\begin{itemize}
  \item No fixed interpolation stencil
  \item Flexible neighborhood influence
  \item Scales to new domains
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec09.tex
% ================================================================================
% Lecture 9 — Slide 17
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Message Passing: Minimal Code Example}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.64\textwidth}

\vspace{-3mm}
\begin{codeonly}{One GNN message-passing layer (conceptual)}
class GNNLayer(nn.Module):
  def __init__(self, dim):
    super().__init__()
    self.self_lin  = nn.Linear(dim, dim)
    self.neigh_lin = nn.Linear(dim, dim)

  def forward(self, x, edge_index):
    row, col = edge_index
    agg = torch.zeros_like(x)
    agg.index_add_(0, row, x[col])
    return F.relu(
        self.self_lin(x) +
        self.neigh_lin(agg) )
\end{codeonly}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.34\textwidth}

\vspace{-1cm}
\textbf{What this shows}

\begin{itemize}
  \item Neighbor features are summed
  \item Same weights used everywhere
  \item Graph defines information flow
\end{itemize}

\vspace{2mm}
\textbf{Key insight}

\begin{itemize}
  \item No coordinates needed
  \item No stencil prescribed
  \item Structure comes from edges
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec09.tex
% ================================================================================
% Lecture 9 — Slide 18
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Generalization: Same Network, Different Domain}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.45\textwidth}

\textbf{What changes}

\begin{itemize}
  \item Number of nodes $N$
  \item Physical domain length
  \item Resolution of the grid
\end{itemize}

\vspace{2mm}
\textbf{What stays the same}

\begin{itemize}
  \item Network architecture
  \item Trainable parameters
  \item Message-passing rule
\end{itemize}

\vspace{2mm}
Trained on $[0, \pi]$, applied on $[0, 4\pi]$. 
Only the \emph{graph} is rebuilt.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-4mm}
\centering
\includegraphics[width=5cm]{../../images/img09/gnn_obs_naive_j1_jj4_0.png}

\vspace{-1mm}
{\footnotesize Failed reconstruction (absolute coordinates)}
\vspace{0mm}
\includegraphics[width=6cm]{../../images/img09/gnn_obs_no_pos_j3_jj4_0.png}

\vspace{-1mm}
{\footnotesize Successful (coordinate-free, graph-based)}


\end{column}

\end{columns}

\end{frame}
%!TEX root = lec09.tex
% ================================================================================
% Lecture 9 — Slide 19
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Why PyTorch Lightning?}

\begin{columns}[T,totalwidth=\textwidth]

\begin{column}[T]{0.55\textwidth}

\textbf{Problem with raw PyTorch}

\begin{itemize}
  \item Training loops get long and repetitive
  \item Device handling (CPU/GPU) is manual
  \item Logging and checkpoints are ad hoc
\end{itemize}

\vspace{2mm}
Code quickly becomes hard to read and maintain.

\tiny
\begin{lstlisting}
from torch_geometric.loader import DataLoader

# Create dataset
dataset = [generate_sample_graph(n_nodes=64, dn=8, k=3) for _ in range(200)]
loader = DataLoader(dataset, batch_size=16, shuffle=True)

# Train
model = GNNInterpolator()
trainer = pl.Trainer(max_epochs=200, logger=False, enable_checkpointing=False)
trainer.fit(model, loader)
\end{lstlisting}

\end{column}

\begin{column}[T]{0.4\textwidth}

\textbf{Lightning idea}

\begin{itemize}
  \item Separate \emph{what} from \emph{how}
  \item Model logic vs. training mechanics
  \item Convention over configuration
\end{itemize}

\vspace{2mm}
Lightning is \emph{PyTorch}, not a replacement.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec09.tex
% ================================================================================
% Lecture 9 — Slide 20
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{LightningModule: Clean Structure}

\begin{columns}[T,totalwidth=\textwidth]

\begin{column}[T]{0.6\textwidth}

\begin{codeonly}{Minimal Lightning module structure}
class Model(pl.LightningModule):
    def forward(self, x):
        ...

    def training_step(self, batch, batch_idx):
        ...
        return loss

    def configure_optimizers(self):
        return torch.optim.Adam(self.parameters())
\end{codeonly}

\end{column}

\begin{column}[T]{0.35\textwidth}

\textbf{Key idea}

\begin{itemize}
  \item No explicit training loop
  \item No device checks
  \item No boilerplate code
\end{itemize}

\vspace{2mm}
Focus stays on the model and the loss.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec09.tex
% ================================================================================
% Lecture 9 — Slide 21
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{What Lightning Handles for You}

\begin{columns}[T,totalwidth=\textwidth]

\begin{column}[T]{0.56\textwidth}

\y{\textbf{Automatically}}

\begin{itemize}
  \item CPU / GPU / multi-GPU
  \item Epoch and batch loops
  \item Gradient handling
  \item Logging
\end{itemize}

\tiny
\begin{lstlisting}
class GNNInterpolator(pl.LightningModule):
    def __init__(self):
        super().__init__()
        self.gcn1 = GCNConv(2, n1)  # 2 input features
        self.gcn2 = GCNConv(n1, n2)
        self.out = GCNConv(n2, 1)

    def forward(self, data):
        x = data.x_feat
        x = F.relu(self.gcn1(x, data.edge_index))
        x = F.relu(self.gcn2(x, data.edge_index))
        return self.out(x, data.edge_index)
\end{lstlisting}

\end{column}

\begin{column}[T]{0.45\textwidth}

\vspace{-7mm}
\textbf{You still \y{control}}

\begin{itemize}
  \item Model architecture
  \item Loss functions
  \item Optimizers
  \item Data handling
\end{itemize}

\vspace{2mm}
Lightning \y{enforces structure} — not constraints.

\vspace{3mm}
\tiny
\begin{lstlisting}
def training_step(self, batch, batch_idx):
   pred = self(batch)
   mask = ~torch.isnan(batch.y_obs)
   loss = F.mse_loss(pred[~mask], batch.y[~mask])
   self.log("train_loss", loss)
   return loss

def configure_optimizers(self):
   return torch.optim.Adam(self.parameters(),lr=0.01)
\end{lstlisting}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec09.tex
% ================================================================================
% Lecture 9 — Slide 22
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Why PyTorch Geometric?}

\begin{columns}[T,totalwidth=\textwidth]

\begin{column}[T]{0.55\textwidth}

\textbf{Graph-specific challenges}

\begin{itemize}
  \item Variable graph sizes
  \item Sparse connectivity
  \item Efficient message passing
\end{itemize}

\vspace{2mm}
Helps implementing this efficiently.

\vspace{2mm}
\end{column}

\begin{column}[T]{0.4\textwidth}

\textbf{PyTorch Geometric}

\begin{itemize}
  \item Native graph data structures
  \item Optimized message passing
  \item Many standard GNN layers
\end{itemize}

\vspace{2mm}
Built directly on PyTorch tensors.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec09.tex
% ================================================================================
% Lecture 9 — Slide 23
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Graphs in PyTorch Geometric}

\begin{columns}[T,totalwidth=\textwidth]

\begin{column}[T]{0.6\textwidth}

\begin{codeonly}{Basic PyG data object}
from torch_geometric.data import Data

data = Data(
    x = node_features,
    edge_index = edge_index,
    y = targets
)
\end{codeonly}

\end{column}

\begin{column}[T]{0.35\textwidth}

\textbf{Key concept}

\begin{itemize}
  \item Nodes = rows of \texttt{x}
  \item Edges define message flow
  \item Graph size is flexible
\end{itemize}

\vspace{2mm}
No grid assumptions required.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec09.tex
% ================================================================================
% Lecture 9 — Slide 24
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{PyTorch Geometric + Lightning}

\begin{columns}[T,totalwidth=\textwidth]

\begin{column}[T]{0.55\textwidth}

\textbf{Why combine them?}

\begin{itemize}
  \item PyG: graph operations
  \item Lightning: clean training
\end{itemize}

\vspace{2mm}
Each library does one thing well.

\end{column}

\begin{column}[T]{0.4\textwidth}

\textbf{Result}

\begin{itemize}
  \item Clean, readable code
  \item Scales to large graphs
  \item Easy experimentation
\end{itemize}

\vspace{2mm}
Ideal for research and teaching.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec09.tex
% ================================================================================
% Lecture 9 — Slide XX
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Graph Neural Network Structure}

\vspace{2mm}

\centering
\includegraphics[width=\textwidth]{../../images/img09/graph_structure.pdf}

Example structure with latent dimension 64 times number of nodes. 

\end{frame}
%!TEX root = lec09.tex
% ================================================================================
% Lecture 9 — Slide XX
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Graph Representation: Data vs Structure}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\textbf{Node data}

\vspace{-4mm}
\begin{eqnarray*}
& X \in \mathbb{R}^{N \times d} \\
& \mathbf{x}_i \in \mathbb{R}^d
\quad (i = 1,\dots,N)
\end{eqnarray*}

\begin{itemize}
\item $N$: number of \y{nodes}
\item $d$: \y{features} per node
\item One feature vector per node
\end{itemize}

\medskip
\textbf{Interpretation}

\begin{itemize}
\item Rows correspond to nodes
\item Columns correspond to features
\item Node order is arbitrary
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}

\vspace{-1cm}
\textbf{Graph structure}

\[
\texttt{edge\_index} \in \mathbb{N}^{2 \times E}
\]

Each column defines one directed \y{edge}:
\[
(j \rightarrow i)
\]

\vspace{0mm}
\begin{itemize}
\item Encodes connectivity only
\item No numerical weights
\item No trainable parameters
\end{itemize}

\medskip
\textbf{Separation of roles}

\begin{itemize}
\item Data: $X$
\item Structure: \texttt{edge\_index}
\item Learning: weights (later)
\end{itemize}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec09.tex
% ================================================================================
% Lecture 9 — Slide XX
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Node-wise Feature Transformation}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\textbf{Input}

\vspace{-3mm}
\[
X \in \mathbb{R}^{N \times d},
\quad
\mathbf{x}_i \in \mathbb{R}^d
\]

\medskip
\textbf{Learned \y{feature map}}

\begin{eqnarray*}
&&
\mathbf{h}_i =  
\sigma\!\left(
W \mathbf{x}_i + \mathbf{b}
\right) 
\\
&& 
W \in \mathbb{R}^{h \times d},
\quad
\mathbf{b} \in \mathbb{R}^h
\\ 
&&
H \in \mathbb{R}^{N \times h}
\end{eqnarray*}

\medskip
\textbf{Key property}

Same transformation for every node.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}

\vspace{-8mm}
\begin{codeonly}{Node-wise linear layer}
self.lin = nn.Linear(d, h)
h = F.relu(self.lin(x))
\end{codeonly}

\medskip
\textbf{What happens here}

\begin{itemize}
\item Feature extraction
\item Dimensionality change
\item No neighbor interaction
\end{itemize}

\medskip
\textbf{What does \emph{not} happen}

\begin{itemize}
\item No graph usage
\item No message passing
\item No dependence on $N$
\end{itemize}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec09.tex
% ================================================================================
% Lecture 9 — Slide XX
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Message Passing: Injecting Graph Structure}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-2mm}
\textbf{Latent node features}

\vspace{-3mm}
\begin{eqnarray*}
&& H \in \mathbb{R}^{N \times h}, \\
&& \mathbf{h}_i \in \mathbb{R}^h
\end{eqnarray*}

\vspace{0mm}
\textbf{\y{Neighborhood aggregation}}

\vspace{-3mm}
\begin{eqnarray*}
&& \mathbf{a}_i
= \sum_{j \in \mathcal{N}(i)} \mathbf{h}_j, \\
&& A \in \mathbb{R}^{N \times h}
\end{eqnarray*}

\vspace{0mm}
\textbf{Graph-aware update}

\vspace{-3mm}
\begin{eqnarray*}
&& \mathbf{h}_i'
= \sigma\!\left(
W_{\text{self}} \mathbf{h}_i
+
W_{\text{neigh}} \mathbf{a}_i
\right)
\end{eqnarray*}

\vspace{1mm}
\footnotesize
Graph affects \emph{which terms are summed},  
not the number of parameters.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}

\vspace{-4mm}
\begin{codeonly}{Edge-based aggregation}
row, col = edge_index
agg = torch.zeros_like(h)
agg.index_add_(0, row, h[col])
\end{codeonly}

\begin{itemize}
\item \y{Uses \texttt{edge\_index} only}
\item No learnable graph parameters
\item Permutation invariant
\end{itemize}

\textbf{Effect}

\begin{itemize}
\item Information exchange
\item Local propagation
\item \y{One-hop interaction}
\end{itemize}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec09.tex
% ================================================================================
% Lecture 9 — Slide XX
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Stacking Message Passing and Output Projection}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}

\textbf{\y{Layer stacking}}

\begin{eqnarray*}
&& H^{(0)} \in \mathbb{R}^{N \times d}, \\
&& H^{(1)} = \Phi(H^{(0)}, \texttt{edge\_index}), \\
&& H^{(2)} = \Phi(H^{(1)}, \texttt{edge\_index})
\end{eqnarray*}

Each layer expands the receptive field:
\begin{itemize}
\item 1 layer: 1-hop neighbors
\item 2 layers: 2-hop neighbors
\end{itemize}

\medskip
\textbf{Final node representation}

\vspace{-2mm}
\begin{eqnarray*}
&& H^{(L)} \in \mathbb{R}^{N \times h}
\end{eqnarray*}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\textbf{\y{Output projection}}

\vspace{-3mm}
\begin{eqnarray*}
&& \hat{y}_i
= w^\top \mathbf{h}_i^{(L)} + b, \\
&& w \in \mathbb{R}^{h}, \quad b \in \mathbb{R} \\
&& \hat{y} \in \mathbb{R}^{N}
\end{eqnarray*}

\begin{codeonly}{Final linear layer}
self.out = nn.Linear(h, 1)
y_hat = self.out(h).squeeze(-1)
\end{codeonly}

\textbf{Key properties}

\begin{itemize}
\item Same output map for all nodes
\item Independent of graph size
\item Fully permutation invariant
\end{itemize}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec09.tex
% ================================================================================
% Lecture 9 — Slide 25
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Lecture 9 — Big Picture}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{What we learned}

\begin{itemize}
  \item \textbf{Sampling} instead of regression
  \item Explicit modeling of \y{uncertainty}
  \item Generating distributions, not point estimates
\end{itemize}

\vspace{2mm}
\textbf{Diffusion networks}

\begin{itemize}
  \item Noise $\rightarrow$ data via iterative refinement
  \item Correct sampling through stochastic reverse steps
  \item Strong theoretical foundation
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}

\vspace{-1cm}
\textbf{Graph networks}

\begin{itemize}
  \item Flexible representation of structure
  \item Learning from sparse, irregular data
  \item Strong generalization across domains
\end{itemize}

\vspace{2mm}
\textbf{Order, structure, efficiency}

\begin{itemize}
  \item Inductive bias through graphs and locality
  \item Separation of geometry and learning
  \item Scalable implementations with
    \begin{itemize}
      \item PyTorch Lightning
      \item PyTorch Geometric
    \end{itemize}
\end{itemize}

\vspace{1mm}
\begin{minipage}{8cm}
\footnotesize
\raggedright\color{red}
Modern ML combines \y{sampling}, \y{structure}, and \y{efficient tooling} to build flexible, generalizable models.
\end{minipage}

\end{column}

\end{columns}

\vspace{2mm}


\end{frame}
% ================================================================================
% E-AI Tutorial Slides
% Filename: lec09.tex
%
% Roland Potthast 2025/2026
% Licence: CC-BY4.0
% ================================================================================
\documentclass[aspectratio=169]{beamer}

% --- Load lecture macros --------------------------------------------------------
\input{../lec_macros.tex}
\newcommand{\LectureNumber}{Lecture 9}

% --- Document -------------------------------------------------------------------
\begin{document}

\setagendaboxforlecture{9}

\input{../lec_agenda.tex}
\input{lec09_01.tex}
\input{lec09_02.tex}
\input{lec09_03.tex}
\input{lec09_04.tex}
\input{lec09_05.tex}
\input{lec09_06.tex}
\input{lec09_07.tex}
\input{lec09_08.tex}
\input{lec09_09.tex}
\input{lec09_10.tex}
\input{lec09_11.tex}
\input{lec09_12.tex}
\input{lec09_13.tex}
\input{lec09_14.tex}
\input{lec09_15.tex}
\input{lec09_16.tex}
\input{lec09_17.tex}
\input{lec09_18.tex}
\input{lec09_19.tex}
\input{lec09_20.tex}
\input{lec09_21.tex}
\input{lec09_22.tex}
\input{lec09_23.tex}
\input{lec09_24.tex}
\input{lec09_25.tex}
\input{lec09_26.tex}
\input{lec09_27.tex}
\input{lec09_28.tex}
\input{lec09_29.tex}
\input{lec09_30.tex}

% --- End Document ---------------------------------------------------------------
\end{document}
%!TEX root = lec10.tex
% ================================================================================
% Lecture 10 — Slide 01
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Why Function Calling Exists}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.56\textwidth}

\vspace{-2mm}
\begin{itemize}
  \item Pure text generation is insufficient
  \item Real systems need \y{actions}, not prose
  \item \rtext{\bf To make the LLM productive, \\
  it needs a link to reality!}
  \item \y{Let it call functions!}
\end{itemize}

\textbf{Key idea}

\vspace{1mm}
\begin{quote}
\raggedright
The model should decide \emph{what to do},  
the system should decide \emph{how to do it}.
\end{quote}


\vspace{1mm}
\textbf{Goal:}
\begin{itemize}
  \item separate \y{reasoning} from \y{execution}
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-13mm}
\begin{minipage}{6cm}
\footnotesize \color{red}
\begin{lstlisting}
{
  "tool_call": {
    "name": "<function name>",
    "arguments": { ... }
  }
}
\end{lstlisting}
\end{minipage}

\vspace{1mm}
Typical problems:
\begin{itemize}
  \item fragile JSON parsing
  \item ambiguous intent
  \item mixed explanation and action
\end{itemize}
\vspace{2mm}
Function calling introduces:
\begin{itemize}
  \item explicit actions
  \item typed arguments
  \item machine-readable decisions
\end{itemize}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec10.tex
% ================================================================================
% Lecture 10 — Slide 02
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Tool Contracts and Schemas}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\vspace{-2mm}
A tool is defined by:
\begin{itemize}
  \item name
  \item description
  \item input schema
\end{itemize}

\vspace{1mm}
Schemas specify:
\begin{itemize}
  \item required arguments
  \item data types
  \item allowed structure
\end{itemize}

\vspace{1mm}
\textbf{Important:}
\begin{itemize}
  \item tools are defined by the \y{system}
  \item never invented by the model
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Example (conceptual)}

\vspace{-10mm}
\begin{codeonly}{Tool schema}
name: get_temperature
arguments:
  location: string
  leadtime: integer
\end{codeonly}

\vspace{1mm}
The model learns:
\begin{itemize}
  \item when this tool applies
  \item how to fill arguments
\end{itemize}

\footnotesize\color{red}
\begin{lstlisting}
{
  "tool_call": {
    "name": "<function name>",
    "arguments": { ... }
  }
}
\end{lstlisting}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec10.tex
% ================================================================================
% Lecture 10 — Slide 03
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Tool Calls in Model Output}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\vspace{-2mm}
Modern LLMs can output:
\begin{itemize}
  \item normal assistant text
  \item \y{structured tool calls}
\end{itemize}

\vspace{1mm}
A tool call contains:
\begin{itemize}
  \item tool name
  \item arguments
  \item no natural language
\end{itemize}

\vspace{1mm}
This decision is:
\begin{itemize}
  \item made by the model
  \item enforced by the API
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Conceptual output}

\vspace{-10mm}
\begin{codeonly}{LLM output}
tool_call:
  name: get_temperature
  arguments:
    location: "Berlin"
    leadtime: 24
\end{codeonly}

\vspace{1mm}
No parsing of prose required.

\hspace*{-2.8cm}
\begin{minipage}{6cm}
\footnotesize\color{red}
\begin{lstlisting}
try:
    tool_call = json.loads(raw_output)["tool_call"]
    print("Parsed tool call:")
    print("Tool name:", tool_call["name"])
    print("Arguments:", tool_call["arguments"])
except Exception as e:
    print("Failed to parse JSON output")
    print("Error:", e)
\end{lstlisting}
\end{minipage}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec10.tex
% ================================================================================
% Lecture 10 — Slide 04
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Streaming and Open-Source Models}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\vspace{-2mm}
In streaming APIs:
\begin{itemize}
  \item \rtext{\y{tool calls}} appear \y{inside the stream}
  \item mixed with text tokens
\end{itemize}

\vspace{1mm}
Open-source models (e.g.\ LLaMA):
\begin{itemize}
  \item emit structured patterns
  \item still require system-side handling
\end{itemize}

\vspace{1mm}
Common fallback:
\begin{itemize}
  \item detect JSON blocks
  \item interpret intent manually
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Historical context}

\vspace{1mm}
\begin{itemize}
  \item Older Framework: JSON scanning
  \item Claude UI: similar hybrid behavior
\end{itemize}

\vspace{1mm}
Native tool calling reduces:
\begin{itemize}
  \item ambiguity
  \item parsing complexity
\end{itemize}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec10.tex
% ================================================================================
% Lecture 10 — Slide 05
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{From JSON Parsing to \rtext{\y{Native Tool Calling}}}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\vspace{-2mm}
Old approach:
\begin{itemize}
  \item prompt for JSON
  \item parse model output
  \item recover from errors
\end{itemize}

\vspace{1mm}
Modern approach:
\begin{itemize}
  \item tools defined explicitly
  \item model selects tool
  \item system executes tool
\end{itemize}

\vspace{1mm}
\textbf{Key shift:}
\begin{itemize}
  \item from text parsing to \y{action selection}
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Architectural consequence}

\vspace{1mm}
\begin{itemize}
  \item cleaner agent design
  \item safer execution
  \item better testability
\end{itemize}

\vspace{1mm}
This enables:
\begin{itemize}
  \item LangChain tools
  \item LangGraph nodes
  \item reliable agents
\end{itemize}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec10.tex
% ================================================================================
% Lecture 10 — Slide 06
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{From Scripts to Agents: Why AI Agents Exist}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.45\textwidth}

\textbf{Classical scripts and pipelines}

\begin{itemize}
  \item Deterministic execution
  \item Fixed control flow
  \item Explicit inputs and outputs
\end{itemize}

\vspace{0mm}
They work well if:
\begin{itemize}
  \item tasks are fully specified
  \item all cases are known in advance
\end{itemize}

\vspace{0mm}
\textbf{Limitations}

\begin{itemize}
  \item No interpretation of intent
  \item Poor handling of ambiguity
  \item Fragile when requirements change
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.55\textwidth}

\vspace{1mm}
\textbf{Where this moves today}

\begin{itemize}
  \item Natural-language problem descriptions
  \item Large, evolving code bases
  \item Underspecified or incomplete tasks
\end{itemize}

\vspace{3mm}
\centering
\includegraphics[width=0.75\textwidth]{../../images/img10/scripts_vs_agents.png}

\vspace{1mm}
\centering
From rigid pipelines to \rtext{\y{\bf adaptive systems}}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec10.tex
% ================================================================================
% Lecture 10 — Slide 07
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{What Is an AI Agent? — Core Mental Model}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.45\textwidth}

\textbf{Agent as a closed loop}

\vspace{-4mm}
\begin{eqnarray*}
&& \text{perception} \\
&\rightarrow& \text{reasoning (LLM)} \\
&\rightarrow& \text{action} \\
&\rightarrow& \text{environment / state}
\end{eqnarray*}

\vspace{2mm}
Key ingredients:
\begin{itemize}
  \item internal \y{state}
  \item access to \y{tools}
  \item explicit \y{control flow}
\end{itemize}

\vspace{2mm}
An agent is \emph{active}, not passive.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.55\textwidth}

\textbf{LLM vs tool vs agent}

\begin{itemize}
  \item \textbf{LLM:} maps text to text
  \item \textbf{Tool:} executes a fixed function
  \item \textbf{Agent:} decides \emph{what to do next}
\end{itemize}

\vspace{0mm}
\begin{minipage}{5cm}
\includegraphics[width=4cm]{../../images/img10/agent_loop_crop.png}
\end{minipage}
\begin{minipage}{2cm}
\raggedright
Decision-making loop with state and actions
\end{minipage}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec10.tex
% ================================================================================
% Lecture 10 — Slide 08
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{LLM Capabilities and Limits in Practice}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{What LLMs are good at}

\begin{itemize}
  \item Understanding natural language
  \item Generating plausible code and text
  \item Pattern completion and refactoring
  \item Explaining existing code
\end{itemize}

\vspace{2mm}
LLMs approximate
\begin{eqnarray*}
&& p(\text{next token} \mid \text{context})
\end{eqnarray*}
from large training corpora.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Systematic limitations}

\begin{itemize}
  \item No ground truth or verification
  \item Hallucinated but plausible outputs
  \item Overconfidence in incorrect answers
  \item Sensitivity to prompt phrasing
\end{itemize}

\vspace{2mm}
\textbf{Sampling matters}

\begin{eqnarray*}
&& \text{temperature } T \uparrow
\;\Rightarrow\;
\text{variance of outputs } \uparrow
\end{eqnarray*}

\vspace{1mm}
Low \(T\): reproducible but rigid \\
High \(T\): creative but unstable

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec10.tex
% ================================================================================
% Lecture 10 — Slide 09
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Prompting for Code Generation}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-2mm}
\begin{itemize}
  \item Unambiguous task description
  \item Explicit constraints
  \item Predictable output format
\end{itemize}

\vspace{0mm}
\textbf{Critical constraints}

\begin{itemize}
  \item Code-only output
  \item No explanations or markdown
  \item Explicit library choices
\end{itemize}

\vspace{0mm}
Poor prompts lead to:
\begin{itemize}
  \item mixed prose and code
  \item missing imports
  \item implicit assumptions
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.55\textwidth}

\vspace{-1cm}
\textbf{Example: strict \y{system prompt}}

\vspace{1mm}
\begin{codeonly}{System message}
You are an AI coder.
Output ONLY valid Python code.
No markdown. No explanations.
Assume Python 3.10.
\end{codeonly}

\vspace{2mm}
\textbf{\y{User prompt} pattern}

\vspace{1mm}
\begin{codeonly}{User message}
Write a Python function f(x)
using numpy that returns a
polynomial with |f(x)| < 10
for x in [-10, 10].
\end{codeonly}

\vspace{1mm}
\textbf{Key point:}  
Prompting is part of the program.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec10.tex
% ================================================================================
% Lecture 10 — Slide 10
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Manual Coding with LLMs (\y{Human in the Loop})}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-2mm}
\textbf{Typical workflow}

\begin{itemize}
  \item Prompt LLM for code
  \item Inspect generated output
  \item Edit or correct manually
  \item Execute and test
\end{itemize}

\vspace{0mm}
\textbf{Why humans stay involved}

\begin{itemize}
  \item Detect logical errors
  \item Spot missing assumptions
  \item Judge correctness, not plausibility
\end{itemize}

\vspace{0mm}
LLMs \y{assist}, they do not decide.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.55\textwidth}

\vspace{-1mm}
\textbf{Trust boundaries}

\begin{itemize}
  \item Never execute blindly
  \item Always read generated code
  \item Treat LLM output as a draft
\end{itemize}

\vspace{2mm}
\textbf{Productive collaboration}

\begin{itemize}
  \item LLM: speed, syntax, structure
  \item Human: intent, validation, responsibility
\end{itemize}

\vspace{1mm}
\textbf{Key point:}  
\y{Responsibility stays with the human.}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec10.tex
% ================================================================================
% Lecture 10 — Slide 11
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Manual Coding with LLMs — Example UI Interaction}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.3\textwidth}

\vspace{-2mm}
\textbf{Human in the loop}

\begin{itemize}
  \item Natural-language prompt
  \item Code suggestion by LLM
  \item Human inspection
  \item Manual correction
\end{itemize}

\vspace{2mm}
This is the \y{baseline} mode of working with LLMs.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.65\textwidth}

\vspace{-2mm}
\includegraphics[width=\textwidth]{../../images/img10/claude_ui.png}

\vspace{1mm}
\footnotesize
Typical web-based LLM interface used for interactive coding

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec10.tex
% ================================================================================
% Lecture 10 — Slide 12
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Executing Generated Code Safely}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-2mm}
\textbf{Execution options}

\begin{itemize}
  \item \texttt{exec} inside current process
  \item Separate process via \texttt{subprocess}
  \item File-based execution
\end{itemize}

\vspace{0mm}
\textbf{Trade-offs}

\begin{itemize}
  \item \texttt{exec}: fast, \y{unsafe}
  \item \texttt{subprocess}: isolated, slower
  \item Files: traceable, debuggable
\end{itemize}

\vspace{0mm}
\textbf{Rule of thumb}

Never execute LLM code  
\y{without isolation or inspection}.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.55\textwidth}

\vspace{-1cm}
\textbf{Minimal example}

\vspace{1mm}
\begin{codeonly}{File-based execution}
with open("gen.py","w") as f:
    f.write(code)

import subprocess
subprocess.run(
  ["python", "gen.py"],
  check=True)
\end{codeonly}

\vspace{2mm}
\textbf{Security risks}

\begin{itemize}
  \item File system access
  \item Network calls
  \item Infinite loops
\end{itemize}

\vspace{1mm}
Mitigation requires \y{process isolation}.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec10.tex
% ================================================================================
% Lecture 10 — Slide 13
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Error Handling and Feedback Loops}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-2mm}
\textbf{Why errors are central}

\begin{itemize}
  \item LLM-generated code is often incomplete
  \item Small syntax or logic errors are common
  \item First attempt rarely works
\end{itemize}

\vspace{0mm}
Errors provide \y{structured feedback}:
\begin{itemize}
  \item missing imports
  \item wrong assumptions
  \item invalid API usage
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.55\textwidth}

\vspace{-1cm}
\textbf{Typical feedback loop}

\vspace{1mm}
\begin{codeonly}{Error capture and retry}
try:
    exec(code)
    success = True
except Exception as e:
    error = traceback.format_exc()
    success = False
\end{codeonly}

\vspace{2mm}
\textbf{Key design choices}

\begin{itemize}
  \item feed back full traceback
  \item limit number of retries
  \item detect repeating failures
\end{itemize}

\vspace{1mm}
\textbf{Key point:}  
Errors drive \y{self-correction}.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec10.tex
% ================================================================================
% Lecture 10 — Slide 14
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{The First Coding Agent: \\ \hspace*{1cm}\y{Self-Correcting Loops}}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.4\textwidth}

\vspace{-2mm}
\textbf{Core idea}

\begin{itemize}
  \item LLM generates code
  \item Code is executed
  \item Errors are captured
  \item LLM is prompted to fix them
\end{itemize}

\vspace{0mm}
This creates an \y{autonomous correction loop}.

\vspace{1mm}
\textbf{Minimal success criteria}

\begin{itemize}
  \item Code executes without error
  \item Output matches basic expectations
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.59\textwidth}

\vspace{-15mm}
\textbf{Minimal agent loop}

\vspace{1mm}
\begin{codeonly}{Self-correcting loop}
for attempt in range(max_tries):
  code = llm(prompt)
  try:
    exec(code)
    break
  except Exception as e:
    prompt += traceback.format_exc()
\end{codeonly}

\vspace{1mm}
\rtext{\bf Why this is already an agent}

\begin{itemize}
  \item autonomous retries
  \item internal state (prompt history)
  \item decision: retry vs stop
\end{itemize}

\vspace{1mm}
No framework required.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec10.tex
% ================================================================================
% Lecture 10 — Slide 15
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{From Prompts to Programs: \y{Abstraction Boundaries}}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{0mm}
\textbf{The core problem}

\begin{itemize}
  \item Prompts mix intent and execution
  \item Small wording changes alter behavior
  \item Logic is implicit and fragile
\end{itemize}

\vspace{0mm}
This leads to \y{prompt brittleness}:
\begin{itemize}
  \item hard to debug
  \item hard to reuse
  \item hard to test
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.55\textwidth}

\vspace{-1mm}
\textbf{Separating responsibilities}

\begin{itemize}
  \item Prompt: \y{what} should be done
  \item Code: \y{how} it is executed
  \item Control flow: \y{when} to retry or stop
\end{itemize}

\vspace{2mm}
\textbf{Design principle}

\begin{itemize}
  \item Prompts describe intent
  \item Programs enforce structure
\end{itemize}

\vspace{1mm}
\textbf{Key point:}  
LLMs belong \y{inside} programs, not around them.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec10.tex
% ================================================================================
% Lecture 10 — Slide 16
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Why Agent Frameworks Exist}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{0mm}
\textbf{Scaling problems of ad-hoc agents}

\begin{itemize}
  \item Prompts grow uncontrollably
  \item Control logic becomes implicit
  \item Error handling is duplicated
\end{itemize}

\vspace{0mm}
As systems grow:
\begin{itemize}
  \item code becomes unstructured
  \item behavior is hard to reproduce
  \item debugging is expensive
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.55\textwidth}

\vspace{-8mm}
\textbf{What frameworks provide}

\begin{itemize}
  \item Explicit control flow
  \item Reusable abstractions
  \item Tool and memory interfaces
  \item Observability and logging
\end{itemize}

\vspace{2mm}
\textbf{What they do \emph{not} provide}

\begin{itemize}
  \item Correct reasoning
  \item Ground truth
  \item Guaranteed success
\end{itemize}

\vspace{1mm}
\textbf{Key point:}  
Frameworks add \y{structure}, not intelligence.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec10.tex
% ================================================================================
% Lecture 10 — Slide 17
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Survey of Agent Frameworks (\y{Critical View})}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.4\textwidth}

\vspace{2mm}
\textbf{Why so many frameworks?}

\begin{itemize}
  \item \rtext{\bf No standard agent abstraction}
  \item \rtext{Rapidly evolving LLM APIs}
  \item Different design philosophies
\end{itemize}

\vspace{0mm}
\textbf{Main categories}

\begin{itemize}
  \item Loop-based agents
  \item Chain-based frameworks
  \item Graph-based workflows
  \item Multi-agent orchestration
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.6\textwidth}

\vspace{-1mm}
\textbf{Typical examples}

\begin{itemize}
  \item \y{LangChain}: chaining + tools
  \item \y{LangGraph}: explicit control flow
  \item \y{CrewAI}: role-based agents
  \item AutoGPT-style: autonomous loops
\end{itemize}

\vspace{2mm}
\textbf{Practical assessment}

\begin{itemize}
  \item Most are \y{experimental}
  \item APIs change quickly
  \item Production use needs caution
\end{itemize}

\vspace{1mm}
\textbf{Rule:}  
Use frameworks to \y{clarify}, not to hide logic.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec10.tex
% ================================================================================
% Lecture 10 — Slide 18
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{LangChain: Motivation and Architecture}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{2mm}
\textbf{What LangChain targets}

\begin{itemize}
  \item Reusable prompt templates
  \item Standardized tool access
  \item Simple memory abstractions
\end{itemize}

\vspace{0mm}
LangChain focuses on:
\begin{itemize}
  \item \y{composition}
  \item \y{integration}
  \item rapid prototyping
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.55\textwidth}

\vspace{-3mm}
\textbf{Core building blocks}

\begin{itemize}
  \item LLM interface
  \item PromptTemplate
  \item Chain
  \item Tool
  \item Memory
\end{itemize}

\vspace{2mm}
\textbf{Limitation}

\begin{itemize}
  \item Linear execution model
  \item Limited explicit control flow
\end{itemize}

\vspace{1mm}
\textbf{Key point:}  
LangChain \y{glues components}, it does not control logic.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec10.tex
% ================================================================================
% Lecture 10 — Slide 19
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Prompt Templates and Tool Integration (LangChain)}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.47\textwidth}

\vspace{-2mm}
\begin{itemize}
  \item Separates instructions and variables
  \item Enforces a fixed structure
  \item Improves reuse and testing
\end{itemize}

\vspace{1mm}
\begin{codeonly}{PromptTemplate example}
from langchain.prompts import PromptTemplate

prompt = PromptTemplate(
  input_variables=["x"],
  template=
  "Write Python code computing f(x) "
  "such that |f(x)| < 10." )
\end{codeonly}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\vspace{-1mm}
\textbf{Tool integration}

\vspace{1mm}
\begin{codeonly}{Tool definition}
from langchain.tools import tool

@tool
def square(x: float) -> float:
    return x * x
\end{codeonly}

\vspace{1mm}
\textbf{Critical limitations}

\begin{itemize}
  \item LLM may select wrong tool
  \item Arguments may be malformed
\end{itemize}

\vspace{1mm}
\textbf{Rule:}  
Tool calls must be \y{validated outside} the LLM.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec10.tex
% ================================================================================
% Lecture 10 — Slide 20
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Autonomous Coding Agent — Self-Correcting Loop}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.38\textwidth}

\vspace{-2mm}
\textbf{Agent task}

\begin{itemize}
  \item Natural-language goal
  \item LLM generates full script
  \item Script is executed
  \item Errors are fed back automatically
\end{itemize}

\vspace{1mm}
This is already a \y{true agent}:
\begin{itemize}
  \item autonomous retries
  \item internal state (prompt history)
  \item stop criterion
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.6\textwidth}

\vspace{-3mm}
\begin{codeonly}{Autonomous code agent (excerpt)}
def autonomous_code_agent(task):
  for attempt in range(5):
    code = llm.invoke(task).content
    try:
      exec(code)
      return True
    except Exception as e:
      task += traceback.format_exc()
  return False
\end{codeonly}

\vspace{1mm}
\textbf{Key point:}  
No framework required —  
this is \y{pure control logic} around an LLM.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec10.tex
% ================================================================================
% Lecture 10 — Slide 21
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Autonomous Agent Output — 3D Polynomial Visualization}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.450\textwidth}

\vspace{-2mm}
\textbf{Task executed}

\begin{itemize}
  \item Generate 2D polynomial
  \item Evaluate on grid
  \item Create 3D visualization
  \item Save result as image
\end{itemize}

\vspace{2mm}
\textbf{Important}

\begin{itemize}
  \item Code was \y{generated}
  \item Code was \y{executed}
  \item Output was \y{validated}
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}

\vspace{-2mm}
\includegraphics[width=0.8\textwidth]{../../images/img10/my2d_crop.png}

\vspace{1mm}
\centering
3D surface plot generated by an autonomous LLM coding agent

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec10.tex
% ================================================================================
% Lecture 10 — Slide 22
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Memory and Context Management in Agents}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{2mm}
\textbf{Why agents need memory}

\begin{itemize}
  \item Remember past attempts
  \item Accumulate errors and feedback
  \item \rtext{\bf Maintain task continuity}
\end{itemize}

\vspace{0mm}
Without memory:
\begin{itemize}
  \item repeated failures
  \item no learning across steps
  \item brittle behavior
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.55\textwidth}

\vspace{-1mm}
\textbf{Types of memory}

\begin{itemize}
  \item Prompt memory  
        (growing instruction and error history)
  \item File-based memory  
        (saved code, plots, logs)
  \item Explicit state  
        (variables passed between steps)
\end{itemize}

\vspace{2mm}
\textbf{Key distinction}

\begin{itemize}
  \item Chat history != agent state
  \item State must be \y{explicit and inspectable}
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec10.tex
% ================================================================================
% Lecture 10 — Slide 23
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Memory Management in LangGraph}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.54\textwidth}

\vspace{-2mm}
\begin{itemize}
  \item No hidden chat history
  \item No implicit conversation memory
  \item No prompt accumulation
\end{itemize}

\vspace{0mm}
Instead:
\begin{itemize}
  \item All memory lives in a \y{typed state object}
  \item Each node reads and updates this state
  \item State is passed explicitly between nodes
\end{itemize}

\vspace{0mm}
\textbf{Consequence:}
\begin{itemize}
  \item Deterministic execution
  \item Fully inspectable memory
  \item Reproducible agent behavior
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}

\textbf{Example: Agent state schema}

\vspace{-14mm}
\begin{codeonly}{LangGraph state}
class MyState(TypedDict):
  query: str
  fc_datetime: str
  fc_reference_datetime: str
  fc_leadtime: str
  fc_location_of_interest: str
  fc_variable: str
  temperature_data: Any
  output: str
\end{codeonly}

\vspace{0mm}
In LangGraph, chat history, tool memory, and agent scratchpads are replaced by a single typed state object. Memory is \y{explicit data}, not implicit text.

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec10.tex
% ================================================================================
% Lecture 10 — Slide 24
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Control Flow in LangGraph}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.4\textwidth}

\vspace{-2mm}
\begin{itemize}
  \item No hidden agent loops
  \item No implicit retries
  \item No LLM-driven control decisions
\end{itemize}

\vspace{0mm}
Instead:
\begin{itemize}
  \item Execution follows a \y{directed graph}
  \item Nodes are pure Python functions
  \item Edges define allowed transitions
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.6\textwidth}

\textbf{Example: Execution graph}

\vspace{-14mm}
\begin{codeonly}{LangGraph control flow}
builder.set_entry_point("extract_forecast_datetime")
builder.add_edge(
  "extract_forecast_datetime",
  "get_latest_forecast_reference_time")
builder.add_edge(
  "get_latest_forecast_reference_time",
  "calculate_lead_time" )
[...]
builder.set_finish_point("plot_temperature")
\end{codeonly}

\vspace{0mm}
The graph itself defines \y{what happens next}.  
There is no hidden agent controller.

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec10.tex
% ================================================================================
% Lecture 10 — Slide 25
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{LLMs as Nodes in LangGraph}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.42\textwidth}

\vspace{-2mm}
\begin{itemize}
  \item LLMs do \emph{not} control execution
  \item LLMs do \emph{not} manage memory
  \item LLMs do \emph{not} decide termination
\end{itemize}

\vspace{0mm}
Instead:
\begin{itemize}
  \item LLMs are used for \y{local reasoning tasks}
  \item Each call has a well-defined input
  \item Each call produces a bounded output
\end{itemize}


\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.59\textwidth}

\vspace{-8mm}
\hspace{1cm}\begin{minipage}{5cm}
\textbf{Typical LLM roles:}
\begin{itemize}
  \item information extraction
  \item classification
  \item summarization
\end{itemize}
\end{minipage}

\vspace{2mm}
\begin{codeonly}{LangGraph node}
def extr_loc_node(state: MyState) -> MyState:
  location = extr_loc(state["query"])
  state["fc_location"] = location
  return state
\end{codeonly}

\vspace{0mm}
The LLM acts as a \y{pure transformation}  
from input fields to output fields.

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec10.tex
% ================================================================================
% Lecture 10 — Slide 26
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{LangGraph Weather Forecast Assistant}

\vspace{-2mm}
\begin{center}
  \includegraphics[width=0.8\textwidth]{../../images/img10/langgraph_weather_forecast.png}
\end{center}

\vspace{-1mm}
\begin{center}
\small
End-to-end agent pipeline: natural language → structured state → tools → visualization
\end{center}

\end{tightmath}
\end{frame}
%!TEX root = lec10.tex
% ================================================================================
% Lecture 10 — Slide 27
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Failure Handling and Robustness}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.36\textwidth}

\vspace{-2mm}
\begin{itemize}
  \item LLM extraction errors
  \item Missing or delayed data
  \item Tool execution failures
  \item Invalid intermediate state
\end{itemize}

\vspace{0mm}
\footnotesize
{\bf LangGraph strategy} \\
Each node handles \y{local failure} \\
State records partial results \\
Graph execution remains controlled

\normalsize
\vspace{2mm}
\textbf{Key principle}
\begin{itemize}
  \item \rtext{Failures are \y{data}, not crashes}
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.68\textwidth}

\textbf{Example: guarded node}

\vspace{-6mm}
\begin{codeonly}{Failure-aware node}
def plot_temperature_node(state: MyState) -> MyState:
  if state.get("temperature_data") is None:
    state["output"] = "No data available"
    return state

  plot_t2m_EU(state["temperature_data"], save_plot=True)
  state["output"] = "Plot created"
  return state
\end{codeonly}

\vspace{2mm}
Failures do not break the agent.  
They update the state and allow the graph to terminate safely.

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec10.tex
% ================================================================================
% Lecture 10 — Slide 28
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Why This Scales: From Prototype to System}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.54\textwidth}

\vspace{-2mm}
\textbf{Problems with classic agent loops}
\begin{itemize}
  \item hidden prompt growth
  \item non-reproducible behavior
  \item difficult debugging
  \item unclear failure causes
\end{itemize}

\vspace{0mm}
\textbf{LangGraph advantages}
\begin{itemize}
  \item explicit state evolution
  \item deterministic control flow
  \item inspectable intermediate results
  \item testable nodes
\end{itemize}


\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}

\vspace{0mm}
\textbf{Engineering outcome}
\begin{itemize}
  \item agents become \y{systems}
  \item not demos or experiments
\end{itemize}

\vspace{0mm}
\textbf{What becomes possible}

\vspace{0mm}
\begin{itemize}
  \item unit tests per node
  \item regression tests on state
  \item logging and metrics
  \item CI/CD integration
\end{itemize}

\vspace{1mm}
\textbf{Key insight}

\vspace{1mm}
\begin{quote}
Agents scale when they obey  
the same rules as software.
\end{quote}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec10.tex
% ================================================================================
% Lecture 10 — Slide 29
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{When Multi-Agent Systems Make Sense}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.54\textwidth}

\vspace{-2mm}
\textbf{One agent is sufficient when}
\begin{itemize}
  \item tasks are sequential
  \item state is compact
  \item logic is well-defined
  \item tools dominate execution
\end{itemize}

\vspace{1mm}
\textbf{Multiple agents are useful when}
\begin{itemize}
  \item \y{responsibilities} are clearly separable
  \item different reasoning styles are needed
  \item tasks can proceed independently
  \item \y{software components} can be done independently
\end{itemize}


\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}

\vspace{-5mm}
\textbf{Key warning}
\begin{itemize}
  \item multi-agent systems are \y{not} better by default
\end{itemize}

\textbf{Typical multi-agent roles}

\vspace{0mm}
\begin{itemize}
  \item planner / coordinator
  \item \rtext{\bf domain expert}
  \item \rtext{\y{\bf tool executor}}
  \item verifier or critic
\end{itemize}

\vspace{1mm}
\textbf{Design principle}

\vspace{1mm}
\begin{quote}
Add agents only when  
you can explain their responsibility.
\end{quote}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec10.tex
% ================================================================================
% Lecture 10 — Slide 30
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{CrewAI: Role-Based Agent Collaboration}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.54\textwidth}

\vspace{-2mm}
\textbf{What CrewAI provides}
\begin{itemize}
  \item explicit agent roles
  \item task delegation
  \item simple coordination logic
  \item readable high-level structure
\end{itemize}

\vspace{0mm}
\textbf{Typical use cases}
\begin{itemize}
  \item document analysis
  \item research workflows
  \item report generation
  \item exploratory automation
\end{itemize}



\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}

\vspace{0mm}
\textbf{Strength}
\begin{itemize}
  \item fast prototyping of multi-agent ideas
\end{itemize}

\vspace{1mm}
\textbf{Limitations}
\begin{itemize}
  \item implicit memory handling
  \item limited state visibility
  \item weak failure control
  \item hard to test systematically
\end{itemize}

\vspace{1mm}
\textbf{Key takeaway}

\vspace{1mm}
\begin{quote}
\raggedright
CrewAI is useful for \y{coordination demos},  
not for operating critical systems.
\end{quote}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec10.tex
% ================================================================================
% Lecture 10 — Slide 31
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{CrewAI Demo: Internal Achievements Report}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.55\textwidth}

\vspace{-2mm}
\textbf{Scenario}

\begin{itemize}
  \item 3--4 months of AI-related achievements
  \item Research and software development
  \item Target: internal newsletter or ministry
\end{itemize}

\vspace{1mm}
\textbf{Agent roles}

\begin{itemize}
  \item Planner: report structure
  \item Scientific writer: technical accuracy
  \item Impact translator: non-expert framing
  \item Editor: clarity and consistency
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.45\textwidth}

\textbf{Notebook flow}

\vspace{1mm}
\begin{itemize}
  \item raw bullet-point inputs
  \item sequential task execution
  \item agent-to-agent refinement
  \item final Markdown output
\end{itemize}

\vspace{2mm}
\textbf{What this demonstrates}

\begin{itemize}
  \item realistic knowledge work
  \item role separation
  \item human-facing automation
\end{itemize}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec10.tex
% ================================================================================
% Lecture 10 — Slide 32
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{AI Agent Landscape — January 2026}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.55\textwidth}

\vspace{-2mm}
\textbf{What has stabilized}

\begin{itemize}
  \item \rtext{\bf LLMs as reasoning engines}
  \item \y{Tool calling} as standard interface
  \item Explicit \y{state and control flow}
  \item Strong separation of roles
\end{itemize}

\vspace{1mm}
\textbf{What is fading}

\begin{itemize}
  \item prompt-only agents
  \item hidden scratchpads
  \item uncontrolled self-loops
  \item purely conversational systems
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.45\textwidth}

\textbf{Dominant design patterns}

\vspace{1mm}
\begin{itemize}
  \item Graph-based agents (LangGraph)
  \item \y{Tool-driven execution}
  \item \rtext{\bf Typed, inspectable state}
  \item Human-in-the-loop checkpoints
\end{itemize}

\vspace{2mm}
\textbf{Reality check}

\begin{itemize}
  \item Agents are \y{software systems}
  \item Not autonomous intelligence
  \item Require engineering discipline
\end{itemize}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
% ================================================================================
% E-AI Tutorial Slides
% Filename: lec10.tex
%
% Roland Potthast 2025/2026
% Licence: CC-BY4.0
% ================================================================================
\documentclass[aspectratio=169]{beamer}

% --- Load lecture macros --------------------------------------------------------
\input{../lec_macros.tex}
\newcommand{\LectureNumber}{Lecture 10}

% --- Document -------------------------------------------------------------------
\begin{document}

\setagendaboxforlecture{10}

\input{../lec_agenda.tex}
\input{lec10_01.tex}
\input{lec10_02.tex}
\input{lec10_03.tex}
\input{lec10_04.tex}
\input{lec10_05.tex}
\input{lec10_06.tex}
\input{lec10_07.tex}
\input{lec10_08.tex}
\input{lec10_09.tex}
\input{lec10_10.tex}
\input{lec10_11.tex}
\input{lec10_12.tex}
\input{lec10_13.tex}
\input{lec10_14.tex}
\input{lec10_15.tex}
\input{lec10_16.tex}
\input{lec10_17.tex}
\input{lec10_18.tex}
\input{lec10_19.tex}
\input{lec10_20.tex}
\input{lec10_21.tex}
\input{lec10_22.tex}
\input{lec10_23.tex}
\input{lec10_24.tex}
\input{lec10_25.tex}
\input{lec10_26.tex}
\input{lec10_27.tex}
\input{lec10_28.tex}
\input{lec10_29.tex}
\input{lec10_30.tex}
\input{lec10_31.tex}
\input{lec10_32.tex}

% --- End Document ---------------------------------------------------------------
\end{document}
%!TEX root = lec11.tex
% ================================================================================
% Lecture 11 — Slide 01
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{DAWID in Action}

\vspace{-2mm}
\begin{center}
  \includegraphics[width=0.6\textwidth]{../../images/img11/dawid_in_action.png}
\end{center}

\vspace{-4mm}
\begin{center}
\small
Interactive DAWID assistant session with live streaming responses and tool integration
\end{center}

\end{frame}
%!TEX root = lec11.tex
% ================================================================================
% Lecture 11 — Slide 02
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{AI Centre Client–Server Architecture}

\vspace{-2mm}
\begin{center}
  \includegraphics[width=0.7\textwidth]{../../images/img11/AI_Centre_Client_Server_Architecture.png}
\end{center}

\vspace{-1mm}
\begin{center}
\small
Frontend UI, backend orchestration, language models, tools, and data sources
\end{center}

\end{frame}
%!TEX root = lec11.tex
% ================================================================================
% Lecture 11 — Slide 03
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{DAWID System Architecture — Frontend Stack}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-3mm}
\textbf{User Interface Layer}

\begin{itemize}
  \item \textbf{HTML5}  
        Page structure, forms, UI elements
  \item \textbf{CSS}  
        Layout, styling, responsive design
  \item \textbf{JavaScript}  
        Interaction logic and event handling
  \item \textbf{Fetch API}  
        Asynchronous requests and streaming
\end{itemize}

\vspace{2mm}
\textbf{Dynamic Content}

\begin{itemize}
  \item \textbf{Markdown rendering}  
        \rtext{Incremental formatting of streamed output}
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Browser Capabilities}

\begin{itemize}
  \item \y{Audio} recording via Web APIs
  \item Clipboard access
  \item Local UI state and session handling
\end{itemize}

\vspace{2mm}
\textbf{Design Principle}

\begin{itemize}
  \item No heavy frontend frameworks
  \item No client-side AI logic
  \item Frontend as thin interaction layer
  \item Works on \y{Laptop}, Workstation, \y{Mobile Device}
\end{itemize}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec11.tex
% ================================================================================
% Lecture 11 — Slide 04
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{DAWID System Architecture — Server and Backend}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Web and Gateway Layer}

\begin{itemize}
  \item \textbf{Web Server} (Apache / Nginx)  
        \y{TLS termination}, static content, routing
  \item \textbf{PHP Gateway}  
        Sessions, uploads, request forwarding
  \item \textbf{Security Boundary}  
        \rtext{No direct access} to backend services
\end{itemize}

\vspace{0mm}
\textbf{Role}

\begin{itemize}
  \item Separates public UI from compute backend
  \item Enforces access control and isolation
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Backend and Compute Layer}

\begin{itemize}
  \item \textbf{Python Backend (FastAPI)}  
        Central orchestration logic
  \item \textbf{Uvicorn Server}  
        Async execution, streaming responses
  \item \textbf{LLM Backends}  
        Local and cloud-based models
\end{itemize}

\vspace{0mm}
\textbf{Key Principle}

\begin{itemize}
  \item Backend owns \y{state}, \y{context}, and \y{tools}
  \item Frontend remains stateless and simple
\end{itemize}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec11.tex
% ================================================================================
% Lecture 11 — Slide 05
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{File Upload Workflow in the DAWID Frontend}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{User Interaction}

\begin{itemize}
  \item File selected via HTML form
  \item \y{Automatic submission} on selection
  \item No explicit upload button required
\end{itemize}

\vspace{2mm}
\textbf{Frontend Logic}

\begin{itemize}
  \item JavaScript listens to file change events
  \item Uses \textbf{Fetch API} for upload
  \item Asynchronous, non-blocking UI
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.54\textwidth}

\textbf{Gateway Interaction}

\begin{itemize}
  \item Upload sent to PHP gateway
  \item File stored in session-specific folder
  \item Backend notified of new resource
\end{itemize}

\vspace{2mm}
\textbf{Minimal JavaScript Logic}

\begin{codeonly}{Automatic upload on file selection}
fileInput.addEventListener("change", () => {
    uploadForm.requestSubmit();
});
\end{codeonly}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec11.tex
% ================================================================================
% Lecture 11 — Slide 06
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Streaming LLM Responses in the Browser}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Why Streaming?}

\begin{itemize}
  \item Immediate user feedback
  \item Reduced perceived latency
  \item Long answers remain usable
\end{itemize}

\vspace{0mm}
\textbf{Frontend Mechanism}

\begin{itemize}
  \item \textbf{Fetch API} with streamed response
  \item \textbf{ReadableStream} reader
  \item Chunk-by-chunk text processing
\end{itemize}

\vspace{0mm}
\textbf{Key UX Effect}

\begin{itemize}
  \item User sees \y{partial results} instantly
  \item No blocking on full completion
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Incremental Rendering}

\begin{itemize}
  \item Accumulate streamed text
  \item Re-render on each new chunk
  \item Markdown parsed continuously
\end{itemize}

\vspace{2mm}
\begin{minipage}{7cm}
\tiny
\begin{lstlisting}
const reader = response.body.getReader();
while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  partial += decoder.decode(value);
  responseDiv.innerHTML = marked.parse(partial);
}
\end{lstlisting}
\end{minipage}

\vspace{2mm}
\textbf{Design Choice}

\begin{itemize}
  \item Simple, robust rendering
  \item \rtext{No WebSockets required}
\end{itemize}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec11.tex
% ================================================================================
% Lecture 11 — Slide 07
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Frontend Capabilities: Math Rendering and Sessions}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Streaming Mathematical Content}

\vspace{1mm}
\begin{center}
  \includegraphics[width=0.95\textwidth]{../../images/img11/dawid_maths.png}
\end{center}

\vspace{1mm}
\small
Mathematical expressions rendered live during streamed responses using
\y{Markdown} and \y{MathJax}.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Session Display and Management}

\vspace{1mm}
\begin{center}
  \includegraphics[width=0.8\textwidth]{../../images/img11/dawid_session_choice.png}
\end{center}

\vspace{1mm}
\small
Multiple interaction sessions with selectable history and clear
\y{context separation} at the frontend level.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec11.tex
% ================================================================================
% Lecture 11 — Slide 08
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{DAWID Backend: Central Uvicorn Server}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Role of the Backend Server}

\begin{itemize}
  \item Single \y{central entry point} for all requests
  \item Receives queries from the frontend gateway
  \item Handles sessions and user context
  \item Streams responses back to the client
\end{itemize}

\vspace{2mm}
\textbf{Key Responsibilities}

\begin{itemize}
  \item Model selection and routing
  \item Context assembly (history, RAG)
  \item Tool and workflow execution
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{FastAPI + Uvicorn}

\begin{itemize}
  \item \textbf{FastAPI}: API definition and validation
  \item \textbf{Uvicorn}: async, high-performance server
  \item Multi-worker capable deployment
\end{itemize}

\vspace{2mm}
\textbf{Design Principle}

\begin{itemize}
  \item Backend owns \y{state}, \y{logic}, and \y{control}
  \item LLMs are \rtext{subsystems}, not the system
\end{itemize}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec11.tex
% ================================================================================
% Lecture 11 — Slide 09
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Backend Route Overview}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Main Route Categories}

\begin{itemize}
  \item \textbf{LLM Routes}  
        Prompt handling, streaming responses
  \item \textbf{Upload Routes}  
        File transfer, storage, metadata
  \item \textbf{Audio Routes}  
        Speech upload and transcription
\end{itemize}

\vspace{2mm}
\textbf{Supporting Routes}

\begin{itemize}
  \item Dataspace and document access
  \item Session and user management
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{API Routes}

\begin{itemize}
  \item OpenAI-compatible chat API
  \item Streaming and non-streaming endpoints
  \item Programmatic access for external tools
\end{itemize}

\vspace{2mm}
\textbf{Design Principles}

\begin{itemize}
  \item Clear \y{separation of concerns}
  \item Explicit routing and ownership
  \item Routes reflect system capabilities
\end{itemize}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec11.tex
% ================================================================================
% Lecture 11 — Slide 10
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{LLM Streaming Routes}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Purpose of LLM Routes}

\begin{itemize}
  \item Accept user queries from the gateway
  \item Build prompts from session history
  \item Integrate retrieved context (RAG)
  \item Return responses as \y{streams}
\end{itemize}

\vspace{2mm}
\textbf{Streaming Logic}

\begin{itemize}
  \item Token-wise or chunk-wise output
  \item Immediate forwarding to frontend
  \item Non-blocking async execution
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}

\vspace{-8mm}
\textbf{Unified Interface}

\begin{itemize}
  \item Same route for local and cloud models
  \item OpenAI, Claude, Gemini, LLaMA, etc.
  \item Model chosen at runtime
\end{itemize}

\vspace{2mm}
\textbf{Interception Points}

\begin{itemize}
  \item Function call detection
  \item Tool execution triggers
  \item Session state updates
\end{itemize}

\vspace{2mm}
\textbf{Key Insight}

\begin{itemize}
  \item LLM output is \rtext{not final}
  \item It is an intermediate signal
\end{itemize}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec11.tex
% ================================================================================
% Lecture 11 — Slide 11
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Upload and File Management Routes}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Purpose of Upload Routes}

\begin{itemize}
  \item Receive files from the frontend gateway
  \item Store data in \y{session- or user-specific} folders
  \item Register files for later access by tools
\end{itemize}

\vspace{2mm}
\textbf{File Types}

\begin{itemize}
  \item Documents (PDF, text, Markdown)
  \item Data files (NetCDF, images)
  \item Audio recordings
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-8mm}
\textbf{Backend Handling}

\begin{itemize}
  \item Controlled directory structure
  \item Metadata stored with session context
  \item Optional indexing for retrieval
\end{itemize}

\vspace{2mm}
\textbf{Integration Points}

\begin{itemize}
  \item Retrieval-Augmented Generation (RAG)
  \item Tool execution (plots, analysis)
  \item Download and reuse in workflows
\end{itemize}

\vspace{2mm}
\textbf{Key Principle}

\begin{itemize}
  \item Uploaded files become \y{first-class resources}
\end{itemize}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec11.tex
% ================================================================================
% Lecture 11 — Slide 12
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Audio Routes: Speech-to-Text}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Motivation}

\begin{itemize}
  \item Natural user interaction via speech
  \item Hands-free input for complex queries
  \item Multimodal access without UI complexity
\end{itemize}

\vspace{2mm}
\textbf{Frontend Interaction}

\begin{itemize}
  \item Audio recorded in the browser
  \item File uploaded via gateway
  \item Treated like any other uploaded resource
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-5mm}
\textbf{Backend Processing}

\begin{itemize}
  \item Local or remote speech-to-text engine
  \item Conversion to plain text
  \item Injected into standard LLM pipeline
\end{itemize}

\vspace{2mm}
\textbf{Design Principle}

\begin{itemize}
  \item Audio is a \y{preprocessing step}
  \item All downstream logic remains text-based
  \item No special cases for speech afterwards
\end{itemize}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec11.tex
% ================================================================================
% Lecture 11 — Slide 13
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{User Management and Dataspaces}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{User and Session Model}

\begin{itemize}
  \item Each interaction tied to a \y{session ID}
  \item Optional persistent user identity
  \item Separation of short-term and long-term context
\end{itemize}

\vspace{2mm}
\textbf{Access Control}

\begin{itemize}
  \item User-specific private areas
  \item Controlled access to shared resources
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Dataspaces}

\begin{itemize}
  \item Private document folders per user
  \item Group-shared knowledge spaces
  \item Clear ownership and responsibility
\end{itemize}

\vspace{2mm}
\textbf{Purpose}

\begin{itemize}
  \item Organize documents and data
  \item Provide \y{structured context} to the LLM
  \item Enable collaborative workflows
\end{itemize}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec11.tex
% ================================================================================
% Lecture 11 — Slide 14
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Retrieval-Augmented Generation (RAG)}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Motivation}

\begin{itemize}
  \item LLMs do not know user-specific documents
  \item Uploaded data must influence responses
  \item Context must be \y{selected}, not dumped
\end{itemize}

\vspace{2mm}
\textbf{Local Retrieval}

\begin{itemize}
  \item Document chunks embedded locally
  \item Similarity search via \textbf{FAISS}
  \item No external data transfer
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Context Assembly}

\begin{itemize}
  \item Detect when documents are relevant
  \item Retrieve top-matching chunks
  \item Inject into prompt before generation
\end{itemize}

\vspace{2mm}
\textbf{Key Principle}

\begin{itemize}
  \item RAG augments \y{knowledge}, not reasoning
  \item The LLM remains the decision engine
\end{itemize}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec11.tex
% ================================================================================
% Lecture 11 — Slide 15
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Available LLM Models and Capability Tiers}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\textbf{Capability Tiers}

\begin{itemize}
  \item \textbf{FAST}  
        Lightweight, fast, cost-efficient
  \item \textbf{CORE}  
        Strong general-purpose models
  \item \textbf{PRO}  
        Heavy reasoning, coding, long context
  \item \textbf{ULTRA}  
        Highest available model capability
\end{itemize}

\vspace{2mm}
\textbf{Design Choice}

\begin{itemize}
  \item One \y{best model} per tier and supplier
  \item No artificial or redundant model options
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}

\vspace{-5mm}
\textbf{Supported Model Families}

\begin{itemize}
  \item OpenAI {\tiny (Gpt5.2, GPT5.1, GPT-4o, GPT-5-mini)}
  \item Claude (Anthropic)
  \item Gemini (Google)
  \item LLaMA (local and remote)
  \item Mistral / Mixtral
  \item GPT-OSS
\end{itemize}

\vspace{2mm}
\textbf{Key Principle}

\begin{itemize}
  \item Users select \y{capability}, not internals
  \item Backend resolves tier to concrete model
\end{itemize}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec11.tex
% ================================================================================
% Lecture 11 — Slide 16
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{DAWID Model Aliases and Routing}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Internal Model Aliases}

\begin{itemize}
  \item Abstract names used by the frontend
  \item Examples:
  \begin{itemize}
    \item \texttt{openai-fast}, \texttt{openai-core}
    \item \texttt{claude-pro}
    \item \texttt{llama-fast}
  \end{itemize}
  \item Aliases encode \y{capability tier}
\end{itemize}

\vspace{2mm}
\textbf{Why Aliases?}

\begin{itemize}
  \item Stable interface for users
  \item Models can change transparently
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-8mm}
\textbf{Backend Resolution}

\begin{itemize}
  \item Alias mapped to concrete model name
  \item Mapping defined centrally in settings
  \item Supplier-specific resolution
\end{itemize}

\vspace{2mm}
\textbf{Routing Logic}

\begin{itemize}
  \item Backend checks model ownership
  \item Selects local or remote backend
  \item Routes request to correct engine
\end{itemize}

\vspace{2mm}
\textbf{Key Principle}

\begin{itemize}
  \item Frontend never sees real model IDs
  \item Backend retains \y{full control}
\end{itemize}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec11.tex
% ================================================================================
% Lecture 11 — Slide 17
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Function Calling in DAWID: \rtext{Weather Service Productivity}}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\textbf{DAWID as a Productivity Platform}

\begin{itemize}
  \item DAWID supports \y{internal and external} weather services
  \item Focus on operational and scientific workflows
  \item Integration of data, models, and tools
\end{itemize}

\vspace{2mm}
\textbf{Typical Weather-Service Tasks}

\begin{itemize}
  \item Access and process NWP data
  \item Generate plots, maps, and diagnostics
  \item Perform domain-specific analyses
  \item Support decision-making and reporting
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}

\textbf{Role of Function Calling}

\begin{itemize}
  \item LLM suggests \y{domain-relevant actions}
  \item DAWID executes approved functions
  \item Actions are embedded in workflows
\end{itemize}

\vspace{2mm}
\textbf{Key Principle}

\begin{itemize}
  \item Function calls increase \y{efficiency}, not autonomy
  \item \rtext{DAWID {\bf augments expert work}, it does not replace it}
\end{itemize}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec11.tex
% ================================================================================
% Lecture 11 — Slide 18
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Classical Function Calling in DAWID (JSON-Based)}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{What “Classical” Means in DAWID}

\begin{itemize}
  \item Function calls encoded explicitly in text
  \item Usually formatted as \y{JSON blocks}
  \item Independent of specific LLM providers
\end{itemize}

\vspace{2mm}
\textbf{Why DAWID Still Supports This}

\begin{itemize}
  \item Works with \y{all models} \\ (local and remote)
  \item Robust fallback mechanism
  \item Easy to debug and inspect
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\textbf{Example: Function Proposal by the LLM}

\begin{codeonly}{JSON-style function call}
{"function_calls": [{
      "name": "get_icon_forecast",
      "arguments": {
        "variable": "t2m",
        "region": "Germany" }}]}
\end{codeonly}

\vspace{2mm}
\textbf{DAWID Interpretation}

\begin{itemize}
  \item JSON is \y{parsed and validated}
  \item Function is checked against allow-list
  \item Execution only happens in backend
\end{itemize}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec11.tex
% ================================================================================
% Lecture 11 — Slide 19
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Native Function Calling in DAWID}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{What “Native” Means}

\begin{itemize}
  \item Functions declared via explicit schemas
  \item Typed arguments and clear signatures
  \item Direct support by modern LLM APIs
\end{itemize}

\vspace{2mm}
\textbf{Advantages in DAWID}

\begin{itemize}
  \item \y{No JSON parsing} from free text
  \item Fewer hallucinated calls
  \item Safer execution path
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-5mm}
\textbf{DAWID Integration}

\begin{itemize}
  \item Functions registered centrally
  \item Only allowed tools are exposed
  \item Backend controls execution order
\end{itemize}

\vspace{2mm}
\textbf{Typical Use Cases}

\begin{itemize}
  \item Plot generation
  \item Data download and extraction
  \item Model-based diagnostics
\end{itemize}

\vspace{2mm}
\textbf{Design Principle}

\begin{itemize}
  \item Native calls are \y{preferred}
  \item Classical calls remain a fallback
\end{itemize}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec11.tex
% ================================================================================
% Lecture 11 — Slide 20
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Function Calling inside DAWID: Execution Paths}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.47\textwidth}

\textbf{Internal Execution: LangGraph}

\begin{itemize}
  \item Functions organized as \y{LangGraph nodes}
  \item Explicit shared state passed between nodes
  \item Deterministic execution order
  \item Suitable for multi-step workflows
\end{itemize}

\vspace{2mm}
\textbf{Typical Internal Tasks}

\begin{itemize}
  \item Data preprocessing and analysis
  \item Plot and image generation
  \item Chained scientific workflows
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\vspace{-3mm}
\textbf{External Execution: HTTP Endpoints}

\begin{itemize}
  \item Functions exposed via REST endpoints
  \item Called from DAWID via HTTP requests
  \item External services remain isolated
\end{itemize}

\vspace{0mm}
\textbf{Typical External Tasks}

\begin{itemize}
  \item Access to targeted data services
  \item Specialized model inference
  \item \rtext{\bf enables modular service development}
\end{itemize}

\vspace{0mm}
\textbf{Key Principle}

\begin{itemize}
  \item \y{function can run on various computers}
  \item Execution remains controlled and auditable, 
  flexible, cloud ready
\end{itemize}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec11.tex
% ================================================================================
% Lecture 11 — Slide 21
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{External Function Calls inside DAWID}


\begin{center}
  \includegraphics[width=0.8\textwidth]{../../images/img11/dawid_external_functions.png}
\end{center}

\vspace{1mm}
\small
Integration of \y{external function calls} within the DAWID backend through REQUESTS.


\end{frame}
%!TEX root = lec11.tex
% ================================================================================
% Lecture 11 — Slide 22
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{AI-Based Feature Detection: Weather Fronts}

\vspace{-3mm}
\begin{center}
\begin{tabular}{ccc}
  \includegraphics[width=0.30\textwidth]{../../images/img11/plot_000.png} &
  \includegraphics[width=0.30\textwidth]{../../images/img11/plot_001.png} &
  \includegraphics[width=0.30\textwidth]{../../images/img11/plot_002.png} \\
  \includegraphics[width=0.30\textwidth]{../../images/img11/plot_003.png} &
  \includegraphics[width=0.30\textwidth]{../../images/img11/plot_004.png} &
  \includegraphics[width=0.30\textwidth]{../../images/img11/plot_005.png}
\end{tabular}
\end{center}

\vspace{-4.5cm}
\footnotesize
AI-detected weather fronts applied to ICON forecast fields at successive lead times.
\y{Warm fronts (red)}, \y{cold fronts (blue)}, and \y{occluded fronts (violet)} are overlaid with
mean sea-level pressure contours.

\end{frame}
%!TEX root = lec11.tex
% ================================================================================
% Lecture 11 — Slide 23
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Input Data and Preprocessing}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Meteorological Input Fields}

\begin{itemize}
  \item Mean sea-level pressure (\textbf{PMSL})
  \item 2\,m temperature (\textbf{T2M})
  \item 2\,m relative humidity (\textbf{RH2M})
  \item 10\,m wind components (\textbf{U10M}, \textbf{V10M})
  \item Land--sea mask (\textbf{FRLAND})
\end{itemize}

\vspace{2mm}
\textbf{Data Source}

\begin{itemize}
  \item ICON analysis and forecast fields
  \item Regular latitude--longitude grid
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}

\vspace{-8mm}
\textbf{Preprocessing Steps}

\begin{itemize}
  \item Channel-wise normalization
  \item Scaling to comparable numerical ranges
  \item Binary encoding of land--sea mask
\end{itemize}

\vspace{2mm}
\textbf{Resulting Tensor}

\begin{itemize}
  \item Shape: \y{[6, lat, lon]}
  \item Stored in NetCDF format
  \item One file per analysis or forecast time
\end{itemize}

\vspace{2mm}
\textbf{Design Principle}

\begin{itemize}
  \item Preserve physical meaning
  \item Avoid unnecessary feature engineering
\end{itemize}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec11.tex
% ================================================================================
% Lecture 11 — Slide 24
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Model Architecture and Training}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Model Architecture}

\begin{itemize}
  \item U-Net for semantic segmentation
  \item Encoder--decoder with skip connections
  \item Preserves spatial detail
\end{itemize}

\vspace{2mm}
\textbf{Input / Output}

\begin{itemize}
  \item Input channels: \y{6}
  \item Output classes: \y{4}
  \item Pixel-wise classification
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\vspace{-8mm}
\textbf{PyTorch Model Setup}

{\footnotesize
\begin{lstlisting}[language=Python]
model = UNet(
    in_channels=6,
    out_channels=4,
    init_features=64
).to(device)

loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.AdamW(
    model.parameters(),
    lr=1e-4 )
\end{lstlisting}
}

\vspace{0mm}
\textbf{Training Setup}

\begin{itemize}
  \item Supervised learning
  \item Labeled frontal maps
  \item Early stopping and validation
\end{itemize}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec11.tex
% ================================================================================
% Lecture 11 — Slide 25
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Operational Front Detection in Forecast Practice}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}

\textbf{From Research to Operations}

\begin{itemize}
  \item AI-based front detection is \y{operationally deployed}
  \item Integrated into \y{NinJo service stations}
  \item Available directly in the forecasters’ workflow
\end{itemize}

\vspace{2mm}
\textbf{Operational Value}

\begin{itemize}
  \item Fast, consistent front analysis
  \item Supports situational awareness
  \item Reduces manual drawing effort
\end{itemize}



\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\vspace{-2mm}
\textbf{User Acceptance}

\begin{itemize}
  \item Widely used by weather forecasters
  \item Particularly helpful in complex synoptic situations
  \item Acts as \y{decision support}, not automation
\end{itemize}

\vspace{-1mm}
\begin{center}
  \includegraphics[width=0.5\textwidth]{../../images/img11/plot_000.png}
\end{center}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec11.tex
% ================================================================================
% Lecture 11 — Summary
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Lecture 11 — Summary}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.54\textwidth}

\textbf{DAWID Platform}

\begin{itemize}
  \item \rtext{\bf Productivity platform} for NHMS 
  \item Supports \y{internal and external} users
  \item Lightweight web frontend
  \item Streaming interaction and session management
\end{itemize}

\vspace{0mm}
\textbf{Backend Architecture}

\begin{itemize}
  \item Modular FastAPI backend
  \item Unified access to \y{multiple LLM families}
  \item \y{Controlled function} execution
  \item Local and external services integrated
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}

\vspace{-8mm}
\textbf{AI Integration}

\begin{itemize}
  \item \y{Function calling} via LangGraph workflows
  \item \y{External tools} accessed through validated APIs
  \item Retrieval-Augmented Generation \y{RAG using FAISS}
\end{itemize}

\vspace{4mm}
\color{darkgreen}
\textbf{Operational Feature Detection}

\begin{itemize}
  \item \color{darkgreen}AI-based feature detection in operations
  \item Front detection integrated into \y{NinJo}
  \item High acceptance among forecasters
\end{itemize}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
% ================================================================================
% E-AI Tutorial Slides
% Filename: lec11.tex
%
% Roland Potthast 2025/2026
% Licence: CC-BY4.0
% ================================================================================
\documentclass[aspectratio=169]{beamer}

% --- Load lecture macros --------------------------------------------------------
\input{../lec_macros.tex}
\newcommand{\LectureNumber}{Lecture 11}

% --- Document -------------------------------------------------------------------
\begin{document}

\setagendaboxforlecture{11}

\input{../lec_agenda.tex}
\input{lec11_01.tex}
\input{lec11_02.tex}
\input{lec11_03.tex}
\input{lec11_04.tex}
\input{lec11_05.tex}
\input{lec11_06.tex}
\input{lec11_07.tex}
\input{lec11_08.tex}
\input{lec11_09.tex}
\input{lec11_10.tex}
\input{lec11_11.tex}
\input{lec11_12.tex}
\input{lec11_13.tex}
\input{lec11_14.tex}
\input{lec11_15.tex}
\input{lec11_16.tex}
\input{lec11_17.tex}
\input{lec11_18.tex}
\input{lec11_19.tex}
\input{lec11_20.tex}
\input{lec11_21.tex}
\input{lec11_22.tex}
\input{lec11_23.tex}
\input{lec11_24.tex}
\input{lec11_25.tex}
\input{lec11_26.tex}

% --- End Document ---------------------------------------------------------------
\end{document}
%!TEX root = lec12.tex
% ================================================================================
% Chapter 12 — Slide 01
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Live Experiment Tracking — Minimal Example}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-2mm}
\textbf{Goal}

\begin{itemize}
  \item Run a simple Python script
  \item Log values every second
  \item \y{Observe results \emph{live} in MLflow}
\end{itemize}

\vspace{2mm}
\textbf{Key idea}

\begin{itemize}
  \item No model
  \item No training
  \item Just time-dependent metrics
\end{itemize}

\vspace{2mm}
This example uses the notebook:
\begin{itemize}
  \item \texttt{1\_live\_tracking.ipynb}
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-4mm}
\includegraphics[width=0.95\textwidth]{../../images/img12/sine_cosine_track1.png}

\vspace{1mm}
\footnotesize
Live metrics appearing during execution

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec12.tex
% ================================================================================
% Chapter 12 — Slide 02
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{What Is Logged — And What Is Not}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\vspace{-2mm}
\textbf{Logged quantities}

\begin{itemize}
  \item Time step (logical step index)
  \item $\sin(t) \cdot \cos(t/10)$
\end{itemize}

\vspace{2mm}
\textbf{Not logged}

\begin{itemize}
  \item No loss
  \item No gradients
  \item No model parameters
\end{itemize}

\vspace{2mm}
\textbf{Interpretation}

\begin{itemize}
  \item MLflow tracks \emph{numbers over time}
  \item \y{The meaning is entirely user-defined}
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}

\vspace{-9mm}
\includegraphics[width=0.95\textwidth]{../../images/img12/sine_cosine_track2.png}

\vspace{1mm}
\footnotesize
Two metrics, same run, shared step axis

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec12.tex
% ================================================================================
% Chapter 12 — Slide 03
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{What This Example Demonstrates}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\vspace{-2mm}
\textbf{MLflow is passive}

\begin{itemize}
  \item \rtext{Python code runs independently}
  \item MLflow only records what it is told
\end{itemize}

\vspace{2mm}
\textbf{Live monitoring}

\begin{itemize}
  \item \y{Metrics appear while code is running}
  \item UI polls the backend periodically
\end{itemize}

\vspace{2mm}
\textbf{Key separation}

\begin{itemize}
  \item Execution $\neq$ visualization
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Mental model}

\vspace{-2mm}
{\color{darkgreen}
\begin{eqnarray*}
&& \text{Python code} \\
&\rightarrow& \text{MLflow tracking backend} \\
&\leftarrow& \text{MLflow Web UI}
\end{eqnarray*}
}

\vspace{2mm}
No direct coupling between:
\begin{itemize}
  \item execution
  \item user interface
\end{itemize}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec12.tex
% ================================================================================
% Chapter 12 — Slide 04
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Why Experiment Tracking?}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}

\begin{itemize}
  \item \y{Repeated training runs}
  \item Changing \y{hyperparameters}
  \item Evolving \y{code versions}
  \item Different \y{datasets}
\end{itemize}

\vspace{2mm}
\textbf{Core requirement}

\begin{itemize}
  \item \y{reproducibility}
  \item \y{transparency}
\end{itemize}

\vspace{-1cm}
\raggedleft
\includegraphics[width=3.5cm]{../../images/img12/MLFlow.png}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}

\vspace{-2mm}
\textbf{Typical problems without tracking}

\begin{itemize}
  \item \rtext{Best parameter settings get lost}
  \item Results cannot be \rtext{reproduced}
  \item \rtext{Missing or incomplete metadata}
  \item Knowledge is \rtext{locked in scripts}
\end{itemize}

\vspace{2mm}
Common symptoms:
\begin{itemize}
  \item many scripts with \rtext{unclear differences}
  \item results that cannot be \rtext{explained later}
\end{itemize}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec12.tex
% ================================================================================
% Chapter 12 — Slide 06
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Artifacts: Persisting Results Beyond Numbers}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.58\textwidth}

\vspace{-2mm}
\textbf{What are artifacts?}

\begin{itemize}
  \item Files produced during or after an experiment
  \item Stored together with parameters and metrics
  \item Provide \y{context} and \y{interpretability}
\end{itemize}

\vspace{2mm}
\textbf{Typical artifacts in ML applications}

\begin{itemize}
  \item Trained model files (\texttt{.pt}, \texttt{.onnx}, \texttt{.pkl})
  \item Diagnostic plots (loss curves, skill scores)
  \item Evaluation outputs (tables, reports)
  \item Configuration snapshots (YAML, JSON)
  \item Logs and summaries
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.38\textwidth}

\vspace{-8mm}

\textbf{Why artifacts matter}

\begin{itemize}
  \item Results are \y{explainable}
  \item Decisions become \y{auditable}
  \item Knowledge is not \rtext{lost in scripts}
\end{itemize}

\vspace{2mm}
\begin{minipage}{6cm}
\tiny
\textbf{How artifacts fit into the workflow}

\begin{itemize}
  \item Research and development
  \item Repeated experimentation
  \item Comparison and selection of models
  \item Preparing models for later use
\end{itemize}
\end{minipage}

\vspace{2mm}
\textbf{Key idea}

\begin{itemize}
  \item Metrics answer \y{\emph{how well}}
  \item Artifacts answer \y{\emph{why}}
\end{itemize}



\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec12.tex
% ================================================================================
% Chapter 12 — Slide 06
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Core Objects: Experiments and Runs}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.54\textwidth}

\vspace{-2mm}
\textbf{Experiment}

\begin{itemize}
  \item Logical \y{container} for related executions
  \item Identified by name
  \item Groups comparable runs
\end{itemize}

\vspace{2mm}
\textbf{Run}

\begin{itemize}
  \item One concrete execution of code
  \item Has a unique ID
  \item Records parameters, metrics, files
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}

\vspace{-8mm}
\textbf{Key properties}

\begin{itemize}
  \item Named
  \item Timestamped
  \item \y{Reproducible}
\end{itemize}

\vspace{2mm}
\textbf{Mental model}

\begin{eqnarray*}
&& \text{Experiment} \\
&\supset& \text{Run}_1, \text{Run}_2, \ldots
\end{eqnarray*}

\vspace{2mm}
Runs differ by:
\begin{itemize}
  \item parameters
  \item code state
  \item data
\end{itemize}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec12.tex
% ================================================================================
% Chapter 12 — Demo Slide (before Slide 06)
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Comparing Parallel Runs}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}

\vspace{-2mm}
\textbf{Setup}

\begin{itemize}
  \item One experiment
  \item Two independent runs
  \item Same metric, same step axis
\end{itemize}

\vspace{2mm}
\textbf{Difference between runs}

\begin{itemize}
  \item Single parameter: \y{phase}
  \item Everything else identical
\end{itemize}

\vspace{2mm}
\textbf{Key observation}

\begin{itemize}
  \item MLflow overlays both curves automatically
  \item No plotting code required
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\vspace{-10mm}
\includegraphics[width=7cm]{../../images/img12/sine_cosine_comparison.png}

\hspace{-1.3cm}\begin{minipage}{5cm}
\tiny
\begin{lstlisting}
def run_sine(phase, name):
  mlflow.set_tracking_uri("http://localhost:5000")
  mlflow.set_experiment("Parallel Sine Comparison")

  with mlflow.start_run(run_name=name):
    mlflow.log_param("phase", phase)
    for step in range(240):
      t = step * 0.1
      value = math.sin(t + phase)*math.cos((t+phase)/10)
      mlflow.log_metric("sine", value, step=step)
      time.sleep(1)

if __name__ == "__main__":
  Process(target=run_sine, args=(0.0, "phase_0")).start()
  Process(target=run_sine, args=(math.pi/4, "phase_pi_over_4")).start()
\end{lstlisting}
\end{minipage}
        
\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec12.tex
% ================================================================================
% Chapter 12 — Slide 08
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Tracking URI}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-2mm}
\footnotesize
\textbf{Definition}

\begin{itemize}
  \item URI = \texttt{Uniform Resource Identifier}
  \item \y{address} of the MLflow tracking backend
  \item Decides \y{where} runs are written
\end{itemize}

\begin{itemize}
  \item Destination of
    \begin{itemize}
      \item experiments
      \item runs
      \item metrics
      \item artifacts
    \end{itemize}
\end{itemize}

\vspace{2mm}
\textbf{Keep untouched:}

\begin{itemize}
  \item Training code
  \item Logging calls
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\vspace{-6mm}
\footnotesize
\textbf{How it is set in code}

\begin{codeonly}{}
import mlflow

mlflow.set_tracking_uri(
    "http://localhost:5000")
\end{codeonly}

\vspace{2mm}
\textbf{Typical values}

\begin{itemize}
  \item \texttt{file:./mlruns} for local storage only
  \item \texttt{http://localhost:5000} for using the mlflow server
\end{itemize}

\vspace{2mm}
\tiny
The MLflow tracking behavior is fully determined by the tracking URI.
If the URI is set to \texttt{sqlite:///mlflow.db}, the Python process writes
experiment metadata directly into a local SQLite database, without using
any HTTP communication or server process.
In contrast, if the URI is set to \texttt{http://localhost:5000}, all tracking
data is sent via HTTP to a running MLflow server, which then stores the
results using its configured backend store (e.g.\ SQLite).


\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec12.tex
% ================================================================================
% Chapter 12 — Slide 09
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Minimal Logging Example}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}

\vspace{-2mm}
\footnotesize
\textbf{Essential steps}

\begin{itemize}
  \item Select an experiment
  \item Start a run
  \item Log parameters
  \item Log metrics
\end{itemize}

\vspace{2mm}
\textbf{Key idea}

\begin{itemize}
  \item One run = one execution
  \item Everything else is optional
\end{itemize}

\vspace{2mm}
\begin{codeonly}{Upload Artefact}
mlflow.log_artifact("a.png")
\end{codeonly}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.56\textwidth}

\vspace{-8mm}
\footnotesize
\begin{codeonly}{Minimal MLflow code}
import mlflow

mlflow.set_experiment("Demo")

with mlflow.start_run():
    mlflow.log_param("lr", 1e-3)
    mlflow.log_metric("loss", 0.42)
\end{codeonly}

\vspace{1mm}
\hspace{5mm}
\begin{minipage}{6cm}
\footnotesize
\textbf{What this code does}

\begin{itemize}
  \item Creates or selects the experiment \texttt{Demo}
  \item Opens a new run with a unique ID
  \item Stores one parameter and one metric
  \item Makes the run visible in the MLflow UI
\end{itemize}
\end{minipage}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec12.tex
% ================================================================================
% Chapter 12 — Slide 10
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Inspecting Results in the MLflow UI}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-2mm}
\footnotesize
\textbf{Grouping principle}

\begin{itemize}
  \item Runs are grouped by \y{experiment}
  \item Experiment name defines the comparison scope
\end{itemize}

\vspace{2mm}
\textbf{Within one experiment}

\begin{itemize}
  \item Select one or more runs
  \item Compare metrics
  \item Inspect parameters
  \item Browse artifacts
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\vspace{-3mm}
\includegraphics[width=\textwidth]{../../images/img12/sine_cosine_comparison.png}

\vspace{1mm}
\footnotesize
Comparison of two runs within one experiment

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec12.tex
% ================================================================================
% Chapter 12 — Slide 11
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Example Problem: Wind Chill Regression}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\footnotesize
\textbf{Problem setup}

\begin{itemize}
  \item Supervised regression task
  \item Two inputs: temperature, wind speed
  \item One target: wind chill
\end{itemize}

\vspace{2mm}
\textbf{Why this example}

\begin{itemize}
  \item Simple but non-trivial
  \item Continuous target variable
  \item Suitable for long training runs
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\includegraphics[width=\textwidth]{../../images/img12/windchill_surface.png}

\footnotesize
Wind Chill Surface
\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec12.tex
% ================================================================================
% Chapter 12 — Slide 12
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Data Generation and Preprocessing}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\footnotesize
\textbf{Synthetic dataset}

\begin{itemize}
  \item Random temperature values
  \item Random wind speed values
  \item Wind chill computed from physical formula
\end{itemize}

\vspace{2mm}
\textbf{Preparation}

\begin{itemize}
  \item Stack inputs into feature vectors
  \item Convert to tensors
  \item No normalization tricks required
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\includegraphics[width=\textwidth]{../../images/img12/windchill_training_data.png}

\footnotesize
Input–output relationship

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec12.tex
% ================================================================================
% Chapter 12 — Slide 13
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Model Definition}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\footnotesize
\textbf{Neural network}

\begin{itemize}
  \item Feedforward architecture
  \item Two hidden layers
  \item Scalar regression output
\end{itemize}

\vspace{2mm}
\textbf{Design choice}

\begin{itemize}
  \item Model kept intentionally simple
  \item Focus is on tracking, not architecture
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-9mm}
\includegraphics[width=5cm]{../../images/img12/windchill_prediction_training.png}
\includegraphics[width=5cm]{../../images/img12/windchill_prediction_surface.png}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec12.tex
% ================================================================================
% Chapter 12 — Slide 14
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Training with MLflow Logging}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\footnotesize
\textbf{What is logged}

\begin{itemize}
  \item Model hyperparameters
  \item Training loss per epoch
  \item Continuous progress information
\end{itemize}

\vspace{2mm}
\textbf{Key benefit}

\begin{itemize}
  \item Training is observable while running
  \item Long runs become transparent
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\includegraphics[width=\textwidth]{../../images/img12/windchill_loss.png}

\footnotesize
Live loss tracking in MLflow UI

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec12.tex
% ================================================================================
% Chapter 12 — Slide 15
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Persisting Results: Artifacts and Models}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\footnotesize
\textbf{Artifacts}

\begin{itemize}
  \item Loss curves
  \item Diagnostic plots
  \item Configuration snapshots
\end{itemize}

\vspace{2mm}
\textbf{Models}

\begin{itemize}
  \item Serialized network weights
  \item Input–output signature
  \item Reusable for later deployment
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-8mm}
\includegraphics[width=4.5cm]{../../images/img12/windchill_loss.png}
\includegraphics[width=5cm]{../../images/img12/windchill_prediction_surface.png}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec12.tex
% ================================================================================
% Lecture 12 — Slide 16
% ================================================================================
\begin{frame}[t]

\mytitle{\y{Local} UI Mode}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Purpose}

\begin{itemize}
  \item Inspect completed or running experiments
  \item Visualize metrics and parameters
  \item Single-user exploration
\end{itemize}

\vspace{2mm}
\textbf{Command}

\begin{itemize}
  \item \texttt{mlflow ui}
\end{itemize}

\vspace{2mm}
\textbf{Key property}

\begin{itemize}
  \item \y{Read-only visualization}
  \item No training happens here
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-10mm}
\includegraphics[width=7cm]{../../images/img12/mlflow_ui_local1.png}

\vspace{2mm}
\footnotesize
By default, the UI reads from the locally configured tracking backend
(e.g.\ \texttt{mlruns/} or a local SQLite database).

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec12.tex
% ================================================================================
% Lecture 12 — Slide 17
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{\y{Server Mode} for Collaboration}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Why server mode?}

\begin{itemize}
  \item \y{Multiple users}
  \item Multiple machines
  \item Shared experiment history
\end{itemize}

\vspace{2mm}
\textbf{Command}

\begin{itemize}
  \item \texttt{mlflow server}
\end{itemize}

\vspace{2mm}
\textbf{Important point}

\begin{itemize}
  \item Training code stays \y{unchanged}
  \item Only the tracking URI changes
\end{itemize}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-2mm}
\begin{codeonly}{Server startup}
mlflow server \\
  --host 0.0.0.0 \\
  --port 5000
\end{codeonly}

\vspace{2mm}
\footnotesize
Clients connect via \texttt{http://<server>:5000}
and log runs remotely.

\vspace{4mm}
\rtext{
{\bf Server Setup}

An MLflow server can run on any host reachable by domain name or IP address; clients only need the tracking URI to connect.
}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec12.tex
% ================================================================================
% Lecture 12 — Slide 18
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Background and \y{Persistent Execution}}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\textbf{Why this matters}

\begin{itemize}
  \item Long-running experiments
  \item Remote machines
  \item Logout-safe operation
\end{itemize}

\vspace{2mm}
\rtext{\bf Servers must survive terminals.}

\vspace{4mm}
\footnotesize
These mechanisms are \y{generic system tools} for running long-lived services;
MLflow behaves like any other server process.

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-8mm}
\begin{codeonly}{Common patterns}
mlflow server ... &

nohup mlflow server ... &

screen -S mlflow
\end{codeonly}

\vspace{2mm}
\footnotesize
Use \texttt{screen} or \texttt{tmux} for
interactive re-attachment and monitoring.

\vspace{4mm}
\tiny\color{darkgreen}
\begin{lstlisting}
tmux new -s mlflow          # start a persistent session
mlflow server --host 0.0.0.0 --port 5000
Ctrl+B  D                  # detach from session
tmux attach -t mlflow      # reconnect later
\end{lstlisting}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec12.tex
% ================================================================================
% Lecture 12 — Slide 19
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Authentication and Credentials}

\begin{columns}[T,totalwidth=\textwidth]

% --- Left column ---------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}

\textbf{Why authentication?}

\begin{itemize}
  \item Shared infrastructure
  \item Access control
  \item Separation of users
\end{itemize}

\vspace{2mm}
\textbf{MLflow support}

\begin{itemize}
  \item Basic authentication
  \item Server-side user management
\end{itemize}


\footnotesize
{\bf In auth\_config.ini:}
\color{darkgreen}
\begin{lstlisting}
export MLFLOW_AUTH_CONFIG_PATH=auth_config.ini
export MLFLOW_FLASK_SERVER_SECRET_KEY='8346918649864986498'
mlflow server --host 0.0.0.0 --port 5000 --app-name basic-auth
\end{lstlisting}

\end{column}

% --- Right column --------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\textbf{Credential handling}

\begin{itemize}
  \item Server: auth configuration
  \item Client: credential file
\end{itemize}

\vspace{2mm}
\footnotesize
{\bf In auth\_config.ini:}
\color{darkgreen}
\begin{lstlisting}
[mlflow]
auth_enabled = true
database_uri = sqlite:///mlflow_auth.db
admin_username = admin
admin_password = ChangeThisPassword888!
\end{lstlisting}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec12.tex
% ================================================================================
% Chapter 12 — Slide 20
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Using a Trained Model from MLflow}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.47\textwidth}

\vspace{-2mm}
\footnotesize
\textbf{Key idea}

\begin{itemize}
  \item Trained models are stored as \y{MLflow artifacts}
  \item A model can be loaded in \y{any notebook or script}
  \item No access to training code is required
\end{itemize}

\vspace{2mm}
\textbf{Workflow}

\begin{itemize}
  \item Identify the model via its \y{run ID}
  \item \rtext{\bf Load the model using an MLflow URI}
  \item Apply forward inference on new data
  \item Optionally log new artifacts back to the same run
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}

\vspace{-10mm}
\begin{center}
\includegraphics[width=0.95\textwidth]{../../images/img12/model_from_mlflow.png}
\end{center}

\vspace{-5mm}
\footnotesize
Loading a model directly from MLflow

\vspace{4mm}
\textbf{Reproducibility}

\begin{itemize}
  \item Architecture, weights, environment stored
  \item Input/output signature enforced
  \item Full traceability to the training run
\end{itemize}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec12.tex
% ================================================================================
% Slide 21
% ================================================================================
\begin{frame}[t,fragile]
\mytitle{Model Registry: What Is Stored}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize
\textbf{Core concept}

\begin{itemize}
  \item A registered model version references exactly \y{one run}
  \item Model versions are immutable
  \item Full traceability to data and code
\end{itemize}

\vspace{2mm}
\textbf{Stored per model version}

\begin{itemize}
  \item Trained parameters (weights)
  \item Model architecture
  \item MLFlow flavor metadata
  \item Environment specification
  \item Optional input/output signature
\end{itemize}
\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}

\vspace{-8mm}

\footnotesize
\textbf{How the architecture is stored}

\begin{itemize}
  \item Serialized via the \y{MLFlow flavor}
  \item For PyTorch:
    \begin{itemize}
      \item Python class structure
      \item State dictionary (parameter tensors)
      \item Loader reference (\texttt{mlflow.pytorch})
    \end{itemize}
  \item Architecture is reconstructed at load time
\end{itemize}

\vspace{4mm}
\rtext{
When a model is logged from PyTorch, MLFlow stores all information needed to
reconstruct the complete neural network at the PyTorch level, including the
network structure, trained parameters, and the code required to load the model.
}

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec12.tex
% ================================================================================
% Slide 22
% ================================================================================
\begin{frame}[t,fragile]
\mytitle{Model Versions and Parallel Development}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize
\textbf{Versioning principle}

\begin{itemize}
  \item Each model version corresponds to one run
  \item Versions are ordered but independent
  \item Older versions remain accessible
\end{itemize}

\vspace{2mm}
\textbf{What changes between versions}

\begin{itemize}
  \item Training data
  \item Hyperparameters
  \item Network architecture
  \item Optimization settings
\end{itemize}
\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize
\textbf{Why this matters}

\begin{itemize}
  \item Multiple ideas explored in parallel
  \item No overwriting of previous results
  \item Safe comparison and rollback
\end{itemize}

\vspace{2mm}
\y{Model evolution is additive, not destructive.}

\vspace{4mm}
\textbf{What ``safe rollback'' means}

\begin{itemize}
  \item \color{red}Older model versions remain unchanged
  \item Switching back requires no retraining
  \item Deployment can point to any previous version
\end{itemize}


\end{column}

\end{columns}
\end{frame}
%!TEX root = lec12.tex
% ================================================================================
% Slide 23
% ================================================================================
\begin{frame}[t,fragile]
\mytitle{Model Lineage and Training Continuation}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize
\textbf{What MLFlow tracks automatically}

\begin{itemize}
  \item Each run has a unique identifier
  \item Each model version points to exactly one run
  \item Parameters, metrics, artifacts are immutable
\end{itemize}

\vspace{2mm}
\textbf{What MLFlow does not infer}

\begin{itemize}
  \item No automatic parent-child model tree
  \item No implicit notion of fine-tuning or continuation
\end{itemize}
\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize
\textbf{How lineage is expressed explicitly}

\begin{itemize}
  \item \rtext{\bf Log the parent run ID as a parameter or tag}
  \item Log the source model URI when continuing training
  \item Use naming and tagging conventions
\end{itemize}

\vspace{2mm}
\textbf{Example intent}

\begin{itemize}
  \item ``run B continues training from run A''
  \item ``model v3 fine-tuned from model v1''
\end{itemize}

\vspace{2mm}
\y{Lineage is recorded by metadata, not guessed.}

\hspace{-5cm}
\begin{minipage}{8cm}
\tiny\color{red}
\begin{lstlisting}
import mlflow
with mlflow.start_run():
    mlflow.set_tag("parent_run_id", "50848f8f09f1471bb4070ea8de9076e3")
    mlflow.set_tag("source_model", "runs:/50848f8f09f1471bb4070ea8de9076e3/model")
    mlflow.set_tag("training_type", "fine_tuning")
\end{lstlisting}
\end{minipage}

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec12.tex
% ================================================================================
% Slide 24
% ================================================================================
\begin{frame}[t,fragile]
\mytitle{What MLFlow Stores (and What It Does Not)}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize
\textbf{Stored explicitly}

\begin{itemize}
  \item Parameters and metrics
  \item Artifacts (plots, files, models)
  \item Model binaries (framework-specific)
  \item \y{Environment YAML files} \\
        \hspace{2mm}(only when a model is logged)
\end{itemize}

\vspace{2mm}
\textbf{YAML handling}

\begin{itemize}
  \item Generated during \texttt{log\_model}
  \item Stored as part of the model artifact
  \item Enables reproducible loading
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize
\textbf{Not stored automatically}

\begin{itemize}
  \item Full runtime environment
  \item OS-level dependencies
  \item GPUs, drivers, system libraries
\end{itemize}

\vspace{2mm}
\textbf{Important boundary}

\begin{itemize}
  \item MLFlow does \rtext{not infer} environments
  \item Reproducibility requires explicit logging
\end{itemize}

\vspace{2mm}
\y{MLFlow records what you declare, not what it guesses.}

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec12.tex
% ================================================================================
% Slide 25
% ================================================================================
\begin{frame}[t,fragile]
\mytitle{From Tracking to Operations}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize
\textbf{What MLFlow enables}

\begin{itemize}
  \item Versioned model artifacts
  \item Stable model identifiers
  \item Promotion via registry stages
  \item Rollback to known-good models
\end{itemize}

\vspace{2mm}
\textbf{Operational contract}

\begin{itemize}
  \item Training produces runs
  \item Registry exposes deployable models
  \item Inference consumes model URIs
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize
\textbf{What MLFlow is not}

\begin{itemize}
  \item \color{red}Not a deployment platform
  \item Not a monitoring system
  \item Not a CI/CD engine
\end{itemize}

\vspace{2mm}
\textbf{Typical integration}

\begin{itemize}
  \item MLFlow for model lifecycle
  \item External systems for serving
  \item External monitoring and alerts
\end{itemize}

\vspace{2mm}
\y{MLFlow provides the training state of a model,}
\y{not its operational execution.}

\end{column}

\end{columns}
\end{frame}
% ================================================================================
% E-AI Tutorial Slides
% Filename: lec12.tex
%
% Roland Potthast 2025/2026
% Licence: CC-BY4.0
% ================================================================================
\documentclass[aspectratio=169]{beamer}

% --- Load lecture macros --------------------------------------------------------
\input{../lec_macros.tex}
\newcommand{\LectureNumber}{Lecture 12}

% --- Document -------------------------------------------------------------------
\begin{document}

\setagendaboxforlecture{12}

\input{../lec_agenda.tex}
\input{lec12_01.tex}
\input{lec12_02.tex}
\input{lec12_03.tex}
\input{lec12_04.tex}
\input{lec12_05.tex}
\input{lec12_06.tex}
\input{lec12_07.tex}
\input{lec12_08.tex}
\input{lec12_09.tex}
\input{lec12_10.tex}
\input{lec12_11.tex}
\input{lec12_12.tex}
\input{lec12_13.tex}
\input{lec12_14.tex}
\input{lec12_15.tex}
\input{lec12_16.tex}
\input{lec12_17.tex}
\input{lec12_18.tex}
\input{lec12_19.tex}
\input{lec12_20.tex}
\input{lec12_21.tex}
\input{lec12_22.tex}
\input{lec12_23.tex}
\input{lec12_24.tex}
\input{lec12_25.tex}

% --- End Document ---------------------------------------------------------------
\end{document}
%!TEX root = lec13.tex
% ================================================================================
% Lecture 13 — Slide 01
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{MLOps: From Machine Learning to Operations}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\textbf{Why this lecture}

\begin{itemize}
  \item Machine learning models are \rtext{\bf no longer research prototypes}
  \item AI systems increasingly enter \y{operational} environments
  \item Reliability, reproducibility and traceability become critical
\end{itemize}

\vspace{2mm}
Traditional ML focuses on \emph{training}.\\
Operations focus on \emph{stability}.\\[1mm]

\textbf{MLOps connects both worlds.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\textbf{Key question}

\begin{itemize}
  \item How do we turn ML code into an operational system?
\end{itemize}

\vspace{2mm}
\textbf{This includes}

\begin{itemize}
  \item controlled software environments
  \item automated build and deployment
  \item clear separation of roles and responsibilities
  \item safe execution on HPC and production systems
\end{itemize}

\vspace{2mm}
This lecture focuses on \emph{processes}, not algorithms.
But also lots of \y{continuous integration} (CI).

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec13.tex
% ================================================================================
% Lecture 13 — Slide 02
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Why Machine Learning Needs Operations}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\textbf{Classical software assumptions}

\begin{itemize}
  \item \y{Code fully defines behavior}
  \item Same input $\rightarrow$ same output
  \item Changes are \y{explicit and infrequent}
\end{itemize}

\vspace{2mm}
Once deployed, behavior is largely predictable and stable.

\includegraphics[height=2cm]{../../images/img13/mlops1.png}
\includegraphics[height=2cm]{../../images/img13/mlops2.png}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}
\footnotesize

\textbf{Machine learning reality}

\begin{itemize}
  \item Behavior emerges from \rtext{data}
  \item Outputs are \rtext{statistical, not deterministic}
  \item Models \rtext{degrade as data distributions change}
\end{itemize}

\vspace{2mm}
\textbf{Operational consequences}

\begin{itemize}
  \item \y{Retraining becomes part of operations}
  \item Monitoring must include \rtext{model performance}
  \item Reproducibility extends {\bf beyond source code}
\end{itemize}

\includegraphics[height=1.3cm]{../../images/img13/mlops3.png}
\includegraphics[height=1.3cm]{../../images/img13/mlops4.png}
\includegraphics[height=1.3cm]{../../images/img13/mlops5.png}


\end{column}

\end{columns}

\vspace{0mm}
\footnotesize
\rtext{\bf Machine learning systems require operational control from the very beginning.}

\end{frame}
%!TEX root = lec13.tex
% ================================================================================
% Lecture 13 — Slide 03
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{What Is MLOps?}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\textbf{Basic idea}

\begin{itemize}
  \item MLOps extends \y{DevOps principles} to machine learning
  \item Focus shifts from code alone to \y{data and models}
  \item The full \y{model lifecycle} becomes operational
\end{itemize}

\vspace{2mm}
MLOps treats ML systems as \emph{long-lived services}, not one-off experiments.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\vspace{-4mm}
\textbf{What MLOps manages}

\begin{itemize}
  \item \y{Data pipelines} and preprocessing
  \item \y{Training and validation} workflows
  \item \y{Model versions} and metadata
  \item Deployment, monitoring and rollback
\end{itemize}

\vspace{2mm}
\textbf{Why this is necessary}

\begin{itemize}
  \item ML behavior changes even when code does not
  \item Manual processes \rtext{do not scale}
  \item Missing control leads to \rtext{silent failures}
\end{itemize}

\end{column}

\end{columns}

\vspace{2mm}
\footnotesize
\rtext{\bf MLOps is not a tool — it is an engineering discipline.}

\end{frame}
%!TEX root = lec13.tex
% ================================================================================
% Lecture 13 — Slide 04
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{DevOps vs MLOps: What Really Changes}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize

\textbf{DevOps perspective}

\begin{itemize}
  \item Software behavior defined by \y{source code}
  \item Releases are \y{explicit and controlled}
  \item Bugs are fixed by changing code
\end{itemize}

\vspace{2mm}
\begin{minipage}{3cm}
\raggedright
How do we monitor systems, and control changes, fixes, improvements?

\end{minipage}
\hspace{5mm}
\begin{minipage}{3cm}
\hspace{4cm}\includegraphics[height=3cm]{../../images/img13/mlops6.png}
\end{minipage}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize

\textbf{MLOps perspective}

\begin{itemize}
  \item Behavior emerges from \rtext{data and training}
  \item Models evolve through \rtext{retraining}
  \item Performance can change \rtext{without code changes}
\end{itemize}

\vspace{2mm}
\textbf{Operational impact}

\begin{itemize}
  \item Data becomes a \rtext{first-class artifact}
  \item Validation must be \rtext{continuous}
  \item \y{Rollback applies to \rtext{models}}, not just code
\end{itemize}

\end{column}

\end{columns}

\vspace{2mm}
\footnotesize
\rtext{\bf MLOps extends DevOps — it does not replace it.}

\end{frame}
%!TEX root = lec13.tex
% ================================================================================
% Lecture 13 — Slide 05
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{The Classical MLOps Cycle}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize

\textbf{From experiment to operation}

\begin{itemize}
  \item \y{Data ingestion} and preprocessing
  \item \y{Model training} and validation
  \item \y{Deployment} into an operational environment
\end{itemize}

\vspace{2mm}
This cycle extends the classical DevOps loop by explicitly
including \y{data and models}.

\vspace{6mm}
\color{darkgreen}\textbf{
Modern MLOps has many elements of typical \g{NWP development
cycles}. NWP also integrates data, e.g.\ orography, canopy layers,
and real data through observations.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize

\textbf{Operational feedback loop}

\begin{itemize}
  \item \y{Monitoring} of system and model performance
  \item Detection of \rtext{drift and degradation}
  \item Triggering \y{retraining or rollback}
\end{itemize}

\vspace{2mm}
\textbf{Key property}

\begin{itemize}
  \item The cycle is \rtext{continuous}, not linear
  \item Operations actively influence development
\end{itemize}

\end{column}

\end{columns}

\vspace{2mm}
\footnotesize
\hfill{\bf MLOps is a closed loop, not a one-time deployment.}

\end{frame}
%!TEX root = lec13.tex
% ================================================================================
% Lecture 13 — Slide 06
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{How Automation Is Achieved in MLOps}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize

\textbf{Automation principles}

\begin{itemize}
  \item Each step is \y{explicitly defined} and scripted
  \item Execution is \y{trigger-based}, not manual
  \item Results are \y{logged and versioned} automatically
\end{itemize}

\vspace{2mm}
Automation replaces informal procedures by
\rtext{repeatable execution rules}.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize

\vspace{-5mm}
\textbf{Technical mechanisms}

\begin{itemize}
  \item \y{CI/CD pipelines} trigger builds and checks
  \item \y{Version control} tracks code, configs, and metadata
  \item \y{Registries} store models and runtime artifacts
  \item \y{Containers} freeze execution environments
\end{itemize}

\vspace{2mm}
\textbf{Key effect}

\begin{itemize}
  \item Humans decide \y{what should happen}
  \item Systems enforce \rtext{how it happens}
\end{itemize}

\end{column}

\end{columns}

\vspace{2mm}
\footnotesize
\rtext{\bf Automation makes MLOps scalable, auditable, and safe.}

\end{frame}
%!TEX root = lec13.tex
% ================================================================================
% Lecture 13 — Slide 07
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{CI and CD in MLOps}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.60\textwidth}
\footnotesize

\vspace{-3mm}
\textbf{Continuous Integration (CI)}

\vspace{1mm}
\texttt{CI = Every change is automatically built, checked, and validated}

\begin{itemize}
  \item Triggered by \y{commits} to code or configuration
  \item Executes \y{tests, linters, and consistency checks}
  \item Detects problems \rtext{early and reproducibly}
\end{itemize}

\vspace{3mm}

\textbf{Continuous Delivery / Deployment (CD)}

\vspace{1mm}
\texttt{CD = Validated artifacts are automatically prepared for operation}

\begin{itemize}
  \item Packages \y{software, models, and environments}
  \item Produces \y{versioned, deployable artifacts}
  \item Enables \y{controlled rollout or rollback}
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.38\textwidth}
\footnotesize

\textbf{CI/CD in MLOps}

\begin{itemize}
  \item CI validates \y{logic and structure}
  \item CD delivers \y{operational artifacts}
\end{itemize}

\vspace{2mm}

\textbf{Important distinction}

\begin{itemize}
  \item CI/CD \rtext{does not decide} when models are used
  \item Operations retain \y{execution control}
\end{itemize}

\vspace{2mm}

\rtext{\bf Automation without loss of control.}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec13.tex
% ================================================================================
% Lecture 13 — Slide 08
% ================================================================================
\begin{frame}[t]

\mytitle{MLOps as a Role-Based Pipeline}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\vspace{-2mm}
It is a \y{\rtext{\bf sequence of responsibilities}} that together form a
\y{complete lifecycle}:

\begin{itemize}
  \item data preparation and feature design
  \item model development and validation
  \item packaging and deployment
  \item monitoring, feedback and retraining
\end{itemize}

\vspace{2mm}
Each of these steps:
\begin{itemize}
  \item requires \y{different skills},
  \item has \y{different risks},
  \item and implies \y{different ownership}.
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-10mm}
\footnotesize
A useful way to understand MLOps is therefore as a
\y{role game}, where different actors take responsibility for
different parts of the pipeline.


\vspace{2mm}
\includegraphics[width=0.9\textwidth]{../../images/img13/mlops_roles.png}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec13.tex
% ================================================================================
% Lecture 13 — Slide 09
% ================================================================================
\begin{frame}[t]

\mytitle{Who Defines What “Good” Means?}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.55\textwidth}
\footnotesize

In MLOps, \y{quality is not a technical concept}.

\vspace{2mm}
It is defined by:
\begin{itemize}
  \item physical constraints,
  \item domain knowledge,
  \item operational requirements,
  \item user expectations.
\end{itemize}

\vspace{2mm}
These aspects cannot be learned from data alone.

\vspace{2mm}
\textbf{Therefore:}

\begin{itemize}
  \item \y{Domain experts define what “good” means},
  \item ML systems optimize \emph{towards} this definition,
  \item Operations validate it against reality.
\end{itemize}


\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.41\textwidth}

\vspace{2mm}
{\color{darkgreen}
\textbf{\textit{Without a domain expertise, metrics are meaningless.}}
}

\vspace{6mm}
\footnotesize
\textbf{Domain Expert}

\begin{itemize}
  \item \y{Defines quality and success criteria}
  \item Specifies relevant metrics and constraints
  \item Interprets model behaviour in context
  \item \rtext{Does not implement models or pipelines}
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec13.tex
% ================================================================================
% Lecture 13 — Slide 10
% ================================================================================
\begin{frame}[t]

\mytitle{Roles in the MLOps Pipeline}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize
\textbf{Data Scientist}

\begin{itemize}
  \item \y{Develops models to optimize domain criteria}
  \item Explores data and hypotheses
  \item Translates questions into ML problems
  \item \rtext{Does not decide operational relevance}
\end{itemize}

\vspace{2mm}
\textbf{ML Engineer}

\begin{itemize}
  \item \y{Turns models into software artifacts}
  \item Builds training and inference pipelines
  \item \y{Ensures reproducibility and versioning}
  \item Bridges research and operations
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-4mm}
\footnotesize
\textbf{DevOps / Platform Engineer}

\begin{itemize}
  \item \y{Provides CI/CD and build infrastructure}
  \item Manages containers and registries
  \item Ensures security and scalability
  \item \rtext{\bf Does not tune models}
\end{itemize}

\vspace{2mm}
\textbf{Domain Expert / Operations / Users}

\begin{itemize}
  \item \y{Run models in production}
  \item Monitor behaviour and failures
  \item Validate outputs against reality
  \item \rtext{Do not modify code or models}
\end{itemize}

\end{column}

\end{columns}

\vspace{5mm}
\footnotesize
\color{darkgreen}
\centering
\textit{\bf Roles should be clear, people may be the same.}

\end{frame}
%!TEX root = lec13.tex
% ================================================================================
% Lecture 13 — Slide 11
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Starting Point: A Baseline ML Application}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\vspace{-2mm}
We start with a \y{minimal working ML example}.

\vspace{2mm}
The goal at this stage is simple:
\begin{itemize}
  \item load a pretrained model,
  \item apply it to input data,
  \item inspect the output.
\end{itemize}

\vspace{2mm}
This corresponds to running the notebook:
\begin{itemize}
  \item \texttt{00\_face-detection-onnx.py}
\end{itemize}

\vspace{2mm}
At this point:
\begin{itemize}
  \item the method works,
  \item results can be inspected visually.
\end{itemize}

\vspace{2mm}
\rtext{Nothing here is operational yet.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}

\vspace{-4mm}
\includegraphics[width=\textwidth]{../../images/img13/i01.png}

\vspace{1mm}
\footnotesize
The notebook instantiates a \y{pretrained} \y{face-detection model}
and applies it directly to an input image.

\vspace{0mm}
\color{darkgreen}
\tiny
\begin{lstlisting}
def mark_faces(image_filename):
    """Mark all faces recognized in the image"""
    image = PIL.Image.open(image_filename)

    faces = detect_faces(image)

    render_data = detections_to_render_data(
        faces, bounds_color=Colors.GREEN, line_width=3 )
    render_to_image(render_data, image)
    display(image)
\end{lstlisting}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec13.tex
% ================================================================================
% Lecture 13 — Slide 12
% ================================================================================
\begin{frame}[t]

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\centering
\vspace{-3mm}
\includegraphics[width=0.9\textwidth]{../../images/img13/Apollo_11_Crew.jpg}

\vspace{2mm}
\footnotesize
\textbf{Input image}

\vspace{2mm}
Raw input data, loaded via \texttt{PIL}.
No preprocessing, no metadata,
no assumptions beyond file availability.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\centering
\vspace{-3mm}
\includegraphics[width=0.9\textwidth]{../../images/img13/Apollo_11_Crew_out.jpg}

\vspace{2mm}
\footnotesize
\textbf{Model output}

\vspace{2mm}
Bounding boxes produced by a
\y{pretrained face-detection model}
and rendered directly onto the image.

\end{column}

\end{columns}

\vspace{2mm}
\footnotesize
\rtext{This is pure inference: load → detect → render.}

\end{frame}
%!TEX root = lec13.tex
% ================================================================================
% Lecture 13 — Slide 13
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Docker: Installation and Input Files}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize

{\sl If you have \rtext{admin rights} on your computer, installation
of docker is easy. }
\begin{lstlisting}
brew install --cask docker
\end{lstlisting}

\vspace{3mm}
\textbf{Step 1: Install Docker}

\begin{itemize}
  \item Install \y{Docker Desktop} (Mac)
  \item Start Docker service
  \item Verify installation:
\end{itemize}

\begin{codeonly}{Check Docker}
docker --version
docker run hello-world
\end{codeonly}

\vspace{2mm}
If this works, Docker is \y{ready to use}.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize

\vspace{-4mm}
\textbf{Step 2: Python code to run in Docker}

\vspace{2mm}
\begin{codeonly}{02\_code\_to\_execute\_in\_docker.py}
from pathlib import Path

print("Hello from Docker")

out = Path("docker_output.txt")
out.write_text("Generated inside Docker\n")

print("Wrote:", out)
\end{codeonly}

\vspace{1mm}
This is \y{ordinary Python}.  
\rtext{No Docker logic} inside the code.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec13.tex
% ================================================================================
% Lecture 13 — Slide 14
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Dockerfile, Image Build, and Execution}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize

\textbf{Step 3: Define the container}

{\tiny
\begin{lstlisting}
FROM python:3.11-slim
WORKDIR /app
COPY 02_code_to_execute_in_docker.py /app/
CMD ["python", "02_code_to_execute_in_docker.py"]
\end{lstlisting}
}

\vspace{1mm}
\footnotesize
Docker \y{freezes the runtime environment}:
\begin{itemize}
  \item operating system (Debian slim)
  \item Python version (\texttt{3.11.x})
  \item system libraries and \texttt{pip}
\end{itemize}

\vspace{1mm}
\rtext{\bf A Docker image already acts as a virtual environment.}

No \texttt{venv} activation is required;  
packages installed in the image are isolated by default.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\vspace{-7mm}
\textbf{Step 4: Build and run}

\begin{codeonly}{Build image}
docker build -t \
  python-hello-docker \
  -f 02_dockerfile.txt .
\end{codeonly}

\vspace{6mm}
\begin{codeonly}{Run container}
docker run --rm \
  -v "$(pwd):/app" \
  python-hello-docker
\end{codeonly}

\vspace{1mm}
\y{Volume mount} exposes results.  
\rtext{Without \texttt{-v}, files disappear.}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec13.tex
% ================================================================================
% Lecture 13 — Slide 15
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Building Docker Containers on GitHub}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\textbf{General principle}

\begin{itemize}
  \item Docker containers do \y{not need} to be built locally
  \item GitHub provides \y{CI runners} with Docker installed
  \item A container can be built \y{directly on the platform}
\end{itemize}

\vspace{2mm}
\textbf{What is required}

\begin{itemize}
  \item Source code
  \item A \y{Dockerfile}
  \item A CI workflow definition
\end{itemize}

\vspace{2mm}
\footnotesize
\rtext{\bf CI builds containers as first-class artifacts.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize

\vspace{-6mm}
\rtext{\bf The build is moved from the laptop to the platform.}

\vspace{2mm}
\textbf{Concrete example (this lecture)}

\begin{itemize}
  \item Python script generates a plot
  \item Dockerfile defines the runtime
  \item GitHub Actions builds the image
  \item Image is pushed to a \y{container registry}
\end{itemize}

\vspace{0mm}
\textbf{Result}

\begin{itemize}
  \item Reproducible container image
  \item Independent of local setup
  \item Ready for download and execution
\end{itemize}

\vspace{2mm}
\y{Code lives in Git.}\\
\y{Images live in the registry.}

\end{column}

\end{columns}


\end{frame}
%!TEX root = lec13.tex
% ================================================================================
% Lecture 13 — Slide 16
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Downloading and Running a Container Image}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\footnotesize

\vspace{-2mm}
\textbf{Pulling a container image}

\begin{itemize}
  \item Images are downloaded via \y{Docker CLI}
  \item Private images require \y{authentication}
  \item Access is granted via \y{registry tokens}
\end{itemize}

\vspace{2mm}
\begin{codeonly}{Download image}
docker pull ghcr.io/eumetnet-e-ai/docker-plot-03:latest
\end{codeonly}

\vspace{0mm}
\textbf{Important distinction}

\begin{itemize}
  \item Git access $\neq$ registry access
  \item Separate permissions for code and containers
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize

\vspace{-2mm}
\textbf{Running the container}

\hspace{-1cm}
\begin{minipage}{6cm}
\tiny
\begin{lstlisting}
docker run --rm \
  -v "$(pwd)/03_docker_plot:/app" \
  ghcr.io/eumetnet-e-ai/docker-plot-03:latest
\end{lstlisting}
\end{minipage}

\vspace{2mm}
\textbf{Why the volume mount matters}

\begin{itemize}
  \item Container files are \rtext{ephemeral}
  \item \y{Volume mounts expose results}
  \item Without \texttt{-v}, outputs disappear
\end{itemize}

\vspace{2mm}
\rtext{\bf Execution is decoupled from development.}

\end{column}

\end{columns}

\vspace{2mm}
\footnotesize
\y{Build once, run anywhere — with controlled environments.}

\end{frame}
%!TEX root = lec13.tex
% ================================================================================
% Lecture 13 — Slide 17
% ================================================================================
\begin{frame}[t]

\mytitle{Docker Containers Built on GitHub}

\vspace{-2mm}
\begin{center}
  \includegraphics[width=0.90\textwidth]{../../images/img13/github_docker_container.png}
\end{center}

\vspace{-2mm}
\footnotesize
\centering
\y{Source code in Git} $\rightarrow$
\y{CI build on GitHub} $\rightarrow$
\y{Container registry} $\rightarrow$
\y{Pull and run anywhere}

\end{frame}
%!TEX root = lec13.tex
% ================================================================================
% Lecture 13 — Slide 18
% ================================================================================
\begin{frame}[t]

\mytitle{GitHub Container Registry (ghcr.io)}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\footnotesize

\textbf{What is \texttt{ghcr.io}?}

\begin{itemize}
  \item GitHub’s \y{container registry service}
  \item Stores Docker / OCI container images
  \item Integrated with \y{GitHub repositories and CI}
\end{itemize}

\vspace{2mm}
\textbf{How it works}

\begin{itemize}
  \item CI builds an image from a Dockerfile
  \item Image is \y{pushed to ghcr.io}
  \item Image is identified by \y{name, tag, and SHA}
\end{itemize}

\vspace{2mm}
\rtext{\bf Containers are artifacts, not source code.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize

\vspace{-6mm}
\textbf{Access and usage}

\begin{itemize}
  \item Images are \y{pulled via Docker or Apptainer}
  \item Private images require \y{authentication}
  \item Access control is \rtext{separate from Git}
\end{itemize}

\vspace{2mm}
\textbf{Browser access}

\begin{itemize}
  \item Containers \y{can be inspected in the browser}
  \item Tags, SHAs, and metadata are visible
  \item \rtext{No direct download button}
\end{itemize}

\vspace{2mm}
\y{Click to inspect. Pull to execute.}

\end{column}

\end{columns}

\vspace{2mm}
\footnotesize
\centering
\rtext{\bf ghcr.io stores images; runtimes execute them.}

\end{frame}
%!TEX root = lec13.tex
% ================================================================================
% Lecture 13 — Slide 19
% ================================================================================
\begin{frame}[t]

\mytitle{Apptainer on HPC: Build vs Run}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\footnotesize

\textbf{What happens when pulling Docker images}

\begin{itemize}
  \item Apptainer converts Docker images into \y{local containers}
  \item This involves \y{SquashFS compression}
  \item Compression is \rtext{memory- and thread-intensive}
\end{itemize}

\vspace{2mm}
\textbf{Typical failure on login nodes}

\begin{itemize}
  \item Limited memory and process counts
  \item SquashFS build cannot create threads
\end{itemize}

\vspace{2mm}
{\footnotesize
\texttt{Out of memory (frag\_thrd)}\\
\texttt{Failed to create thread}
}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize

\textbf{Important distinction}

\begin{itemize}
  \item \y{Running} containers is lightweight
  \item \rtext{Building} containers is a compute task
\end{itemize}

\vspace{2mm}
\textbf{HPC policy (typical)}

\begin{itemize}
  \item Login nodes: editing, submitting jobs
  \item Compute nodes: builds, compression, heavy work
\end{itemize}

\vspace{2mm}
\rtext{\bf Apptainer pull = build step, not runtime.}

\end{column}

\end{columns}

\vspace{2mm}
\footnotesize
\centering
\y{Disk quota is irrelevant — memory and threads decide.}

\end{frame}
%!TEX root = lec13.tex
% ================================================================================
% Lecture 13 — Slide 20
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Correct Apptainer Workflow on HPC}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize

\textbf{Recommended solution}

\begin{itemize}
  \item Run container pulls as \y{batch jobs}
  \item Request sufficient \y{memory}
  \item Avoid compressed SIF builds on login nodes
\end{itemize}

\vspace{2mm}
\textbf{Use sandbox format}

\begin{itemize}
  \item Uncompressed directory container
  \item Much lower memory pressure
  \item Fully usable with Apptainer
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize

\vspace{-12mm}
\begin{codeonly}{Batch job (concept)}
#PBS -q gp_norm_all
#PBS -l memsz_job=128gb
#PBS -l cpunum_job=2

apptainer build --sandbox \
  my-container \
  docker://ghcr.io/ORG/IMAGE:TAG
\end{codeonly}

\vspace{2mm}
\textbf{Running the container}

\begin{itemize}
  \item No root privileges
  \item Current directory mounted by default
  \item Same performance as SIF
\end{itemize}

\vspace{2mm}
\rtext{\bf HPC rule: build elsewhere, run everywhere.}

\end{column}

\end{columns}

\vspace{2mm}
\footnotesize
\centering
\y{For production: build SIFs in CI, not on the cluster.}

\end{frame}
%!TEX root = lec13.tex
% ================================================================================
% Lecture 13 — Slide 21
% ================================================================================
\begin{frame}[t]

\mytitle{Building Apptainer Containers on GitHub}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\footnotesize

\textbf{Motivation}

\begin{itemize}
  \item HPC systems often \rtext{cannot build containers locally}
  \item Docker images must be converted to \y{Apptainer (SIF)}
  \item Conversion is \rtext{memory-intensive}
\end{itemize}

\vspace{2mm}
\textbf{Key idea}

\begin{itemize}
  \item Move the \y{build step off the HPC}
  \item Use \y{GitHub Actions} as build infrastructure
  \item Produce ready-to-run \y{SIF artifacts}
\end{itemize}

\vspace{2mm}
\rtext{\bf CI builds containers, HPC only runs them.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize

\vspace{-4mm}
\textbf{What GitHub provides}

\begin{itemize}
  \item Linux build nodes with Docker
  \item Sufficient memory for SquashFS
  \item Integrated access to \y{ghcr.io}
\end{itemize}

\vspace{2mm}
\textbf{Required inputs}

\begin{itemize}
  \item Docker image in a registry
  \item Apptainer installed in CI
  \item Authentication token (\texttt{read:packages})
\end{itemize}

\vspace{2mm}
\y{Result:} A portable \rtext{single-file container}.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec13.tex
% ================================================================================
% Lecture 13 — Slide 22
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{CI Workflow: Docker Image to Apptainer SIF}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\textbf{Automated workflow}

\begin{itemize}
  \item Triggered after successful Docker build
  \item Runs on GitHub Linux runner
  \item Converts image to \y{SIF format}
\end{itemize}

\vspace{2mm}
\textbf{Main steps within the Github environment}

\begin{enumerate}
  \item Install Apptainer
  \item Authenticate to \texttt{ghcr.io}
  \item Pull Docker image
  \item Convert to \y{SIF}
  \item Upload as artifact
\end{enumerate}

\vspace{2mm}
\rtext{\bf This is CI/CD for runtime environments.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.53\textwidth}
\footnotesize

\vspace{-3mm}
\begin{codeonly}{Core CI command on GitHub}
apptainer pull \
  docker-plot-03.sif \
  docker://ghcr.io/ORG/IMAGE:TAG
\end{codeonly}

\vspace{2mm}
\textbf{Distribution}

\begin{itemize}
  \item SIF stored as CI artifact
  \item Downloadable via browser
  \item Transfer to HPC via \texttt{scp}
\end{itemize}

\vspace{0mm}
\textbf{On the cluster}

\begin{itemize}
  \item \y{No build step}
  \item No Docker required
  \item Immediate execution
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec13.tex
% ================================================================================
% Lecture 13 — Slide 23
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Triggering the SIF Build via GitHub Actions, YAML}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize

\textbf{What this workflow does}

\begin{itemize}
  \item Listens for a \y{successful Docker build}
  \item Runs \y{only if the image exists}
  \item Converts Docker $\rightarrow$ Apptainer
\end{itemize}

\vspace{0mm}
\textbf{Why this design}

\begin{itemize}
  \item Avoids duplicate builds
  \item Enforces a clean dependency chain
  \item CI controls the runtime environment
\end{itemize}

\vspace{0mm}
\rtext{\bf Docker build is a prerequisite.}

\vspace{2mm}
This makes the SIF build:
\begin{itemize}
  \item deterministic, reproducible
  \item traceable to a commit
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize

\vspace{-4mm}
\begin{minipage}{7cm}
\tiny
\begin{lstlisting}
name: Export Apptainer SIF (Example 03)
on:
  workflow_run:
    workflows: ["Build and publish Docker image (03 plot)"]
    types: [completed]
jobs:
  build-sif:
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: read
    steps:
      - name: Install Apptainer
        run: |
          sudo apt-get update
          sudo apt-get install -y \
\end{lstlisting}
\end{minipage}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec13.tex
% ================================================================================
% Lecture 13 — Slide 24
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Running the Apptainer Container on the HPC}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\textbf{On the HPC system}

\begin{itemize}
  \item No Docker available
  \item Apptainer pre-installed
  \item No build permissions required
\end{itemize}

\vspace{2mm}
\textbf{Run the container}

\begin{codeonly}{HPC execution}
apptainer exec \
docker-plot-03.sif python \
-B 03_plot_curve.py
\end{codeonly}

\vspace{2mm}

\vspace{2mm}
\rtext{\bf Same container, different system.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}


\textbf{What happens}

\footnotesize
\begin{itemize}
  \item Python code runs inside container
  \item Output file written to working directory
  \item No external dependencies needed
\end{itemize}

\vspace{-2mm}
\includegraphics[width=0.95\textwidth]{../../images/img13/03_plot_curve.png}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec13.tex
% ================================================================================
% Lecture 13 — Slide 25
% ================================================================================
\begin{frame}[t]

\mytitle{From Docker Image to Apptainer SIF on GitHub}

\vspace{2mm}
\centering
\includegraphics[width=0.92\textwidth]{../../images/img13/github_docker_container_sif.png}

\end{frame}
%!TEX root = lec13.tex
% ================================================================================
% Lecture 13 — Slide 27
% ================================================================================
\begin{frame}[t]

\mytitle{Why Containers are Essential in ML Frameworks}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\textbf{The core problem in ML}

\begin{itemize}
  \item ML code depends on:
  \begin{itemize}
    \item specific library versions
    \item CUDA / CPU features
    \item system-level dependencies
  \end{itemize}
  \item These dependencies \rtext{change over time}
  \item Results become hard to reproduce
\end{itemize}

\vspace{2mm}
\rtext{\bf ML models are not standalone artifacts.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\textbf{What containers provide}

\begin{itemize}
  \item Encapsulation of:
  \begin{itemize}
    \item code
    \item libraries
    \item runtime environment
  \end{itemize}
  \item Identical execution on:
  \begin{itemize}
    \item laptops
    \item CI systems
    \item HPC clusters
  \end{itemize}
\end{itemize}

\vspace{2mm}
\y{\bf Containers turn models into executable artifacts.}

\end{column}

\end{columns}

\vspace{2mm}
\centering
\footnotesize
Reproducibility, portability, and controlled execution are \rtext{non-negotiable} in ML.

\end{frame}
% ================================================================================
% E-AI Tutorial Slides
% Filename: lec13.tex
%
% Roland Potthast 2025/2026
% Licence: CC-BY4.0
% ================================================================================
\documentclass[aspectratio=169]{beamer}

% --- Load lecture macros --------------------------------------------------------
\input{../lec_macros.tex}
\newcommand{\LectureNumber}{Lecture 13}

% --- Document -------------------------------------------------------------------
\begin{document}

\setagendaboxforlecture{13}

\input{../lec_agenda.tex}
\input{lec13_01.tex}
\input{lec13_02.tex}
\input{lec13_03.tex}
\input{lec13_04.tex}
\input{lec13_05.tex}
\input{lec13_06.tex}
\input{lec13_07.tex}
\input{lec13_08.tex}
\input{lec13_09.tex}
\input{lec13_10.tex}
\input{lec13_11.tex}
\input{lec13_12.tex}
\input{lec13_13.tex}
\input{lec13_14.tex}
\input{lec13_15.tex}
\input{lec13_16.tex}
\input{lec13_17.tex}
\input{lec13_18.tex}
\input{lec13_19.tex}
\input{lec13_20.tex}
\input{lec13_21.tex}
\input{lec13_22.tex}
\input{lec13_23.tex}
\input{lec13_24.tex}
\input{lec13_25.tex}
\input{lec13_26.tex}

% --- End Document ---------------------------------------------------------------
\end{document}
%!TEX root = lec14.tex
% ================================================================================
% Lecture 14 — Slide 01
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Why CI/CD Is Not Optional for AI/ML}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize

\textbf{What continuously changes in AI/ML}

\begin{itemize}
  \item Model parameters through retraining
  \item Training and validation data
  \item Feature engineering and preprocessing
  \item Hyperparameters and runtime configuration
\end{itemize}

\vspace{2mm}
As a consequence:
\begin{itemize}
  \item System behavior is \rtext{not fixed}
  \item Outputs depend on \y{code, data, and environment}
  \item Small changes can have \rtext{large effects}
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}
\footnotesize

\textbf{Why manual workflows break down}

\begin{itemize}
  \item Experiments cannot be reproduced reliably
  \item Results depend on undocumented environments or training data
  \item Errors surface \rtext{late or not at all}
  \item Deployment decisions become guesswork
\end{itemize}

\vspace{2mm}
Without automation:
\begin{itemize}
  \item Models cannot be trusted operationally
  \item Debugging becomes \rtext{forensic work}
\end{itemize}

\end{column}

\end{columns}

\vspace{2mm}
\footnotesize
\rtext{\bf CI/CD is the mechanism that makes AI/ML systems controllable and trustworthy.}

\end{frame}
%!TEX root = lec14.tex
% ================================================================================
% Lecture 14 — Slide 02
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{AI/ML Is Not Special — But Updating Becomes Complex}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize

\textbf{From a software engineering perspective}

\begin{itemize}
  \item AI/ML systems are still \y{software systems}
  \item They use standard languages, libraries and toolchains
  \item The same DevOps principles apply
\end{itemize}

\vspace{2mm}
There is \rtext{no special engineering magic} in AI/ML:
\begin{itemize}
  \item version control
  \item testing
  \item packaging
  \item deployment
\end{itemize}

\vspace{2mm}
\footnotesize
\rtext{\bf CI/CD is needed to manage updates, not to handle “AI magic”.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}
\footnotesize

\color{darkgreen}
\textbf{Where the real complexity comes from}

\begin{itemize}
  \item \color{darkgreen}
	Frequent retraining with \y{new data}
  \item Multiple preprocessing and feature pipelines
  \item Changing \y{model architectures}
  \item Different \y{loss functions} and objectives
  \item Many runtime and training configurations
\end{itemize}

\vspace{2mm}
As a result:
\begin{itemize}
  \item Updates are \rtext{continuous}
  \item Reproducibility becomes \rtext{non-trivial}
  \item Manual tracking no longer works
\end{itemize}

\end{column}

\end{columns}


\end{frame}
%!TEX root = lec14.tex
% ================================================================================
% Lecture 14 — Slide 03
% ================================================================================
\begin{frame}[t]

\vspace{-2mm}
\begin{center}
  \includegraphics[width=0.95\textwidth]{../../images/img14/full_story_data_to_deployment.png}
\end{center}

\end{frame}
%!TEX root = lec14.tex
% ================================================================================
% Lecture 14 — Slide 04
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Starting Locally: A Concrete Git Hook Example}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize

{\bf Black} is an \y{automatic code formatter} for Python.

{\sl 
It rewrites Python source code into a single, consistent style, without asking questions.
}

\vspace{2mm}
\textbf{Minimal pre-commit hook}

\begin{codeonly}{.git/hooks/pre-commit}
#!/bin/sh
pytest || exit 1
black .
\end{codeonly}

\vspace{1mm}
This hook is executed automatically when running:
\begin{itemize}
  \item \texttt{git commit}
\end{itemize}

If tests fail, the commit is \rtext{blocked}.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}
\footnotesize

\textbf{What this enforces locally}

\begin{itemize}
  \item Code must be \y{syntactically correct}
  \item Tests must \y{pass}
  \item Code formatting is \y{consistent}
\end{itemize}

\vspace{2mm}
Key properties:
\begin{itemize}
  \item Runs \rtext{before} code leaves the laptop
  \item No CI server involved
  \item Immediate feedback to the developer
\end{itemize}

\end{column}

\end{columns}

\vspace{2mm}
\footnotesize
\rtext{\bf Git hooks enforce local discipline — not global policy.}

\end{frame}
%!TEX root = lec14.tex
% ================================================================================
% Lecture 14 — Slide 05
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{When Are Git Hooks Executed?}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize

\textbf{Git commands trigger hooks}

Git automatically executes hooks at
\y{well-defined points} in its workflow.

\vspace{2mm}
Common examples:
\begin{itemize}
  \item \texttt{pre-commit} — before a commit is created
  \item \texttt{commit-msg} — to validate commit messages
  \item \texttt{pre-push} — before pushing to a remote
\end{itemize}

\vspace{2mm}
Hooks run \rtext{before} Git completes the command.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}
\footnotesize

\textbf{Effect on the workflow}

\begin{itemize}
  \item Hook succeeds $\rightarrow$ Git continues
  \item Hook fails $\rightarrow$ Git aborts the command
\end{itemize}

\vspace{2mm}
This means:
\begin{itemize}
  \item Invalid code never enters the repository
  \item Errors are caught \y{immediately}
  \item No manual checks are required
\end{itemize}

\vspace{2mm}
Hooks are \rtext{deterministic}:
same input $\rightarrow$ same outcome.

\end{column}

\end{columns}

\vspace{2mm}
\footnotesize
\rtext{\bf Hooks turn Git commands into enforced quality gates.}

\end{frame}
%!TEX root = lec14.tex
% ================================================================================
% Lecture 14 — Slide 06
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{A Git Hook in Action: What Actually Happens}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\vspace{-2mm}
\textbf{Before committing}

\begin{itemize}
  \item Python test file is \rtext{poorly formatted}
  \item Code is syntactically valid
  \item Tests pass when run manually
\end{itemize}

\vspace{0mm}
After running \texttt{black}:
\begin{itemize}
  \item Formatting is rewritten automatically
  \item No code logic is changed
\end{itemize}

\textbf{During \texttt{git commit}}

\begin{itemize}
  \item \texttt{pytest} is executed automatically
  \item \texttt{black} is executed automatically
  \item Both run via the \y{pre-commit hook}
\end{itemize}

\vspace{0mm}
\footnotesize
\rtext{\bf The hook turns a manual checklist into an automatic guarantee.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.42\textwidth}
\footnotesize


\vspace{-3mm}
{\bf Outcome:}
\begin{itemize}
  \item Tests pass
  \item Formatting is consistent
  \item Commit is \y{accepted}
\end{itemize}

\hspace{-3mm}\color{black}\rule{0.5pt}{4cm}

\vspace{-4.3cm}
\begin{minipage}{7cm}
\tiny\color{red}
\begin{lstlisting}
def add( a ,b ):
  return a+b
def test_answer( ):
  print("Testing add(1, 3) == 4")
  assert add(1,3)==4
\end{lstlisting}

\vspace{-2mm}
\color{darkgreen}
\begin{lstlisting}
def add(a, b):
    return a + b
def test_answer():
    print("Testing add(1, 3) == 4")
    assert add(1, 3) == 4
\end{lstlisting}
\end{minipage}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec14.tex
% ================================================================================
% Lecture 14 — Slide 07
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Strengths and Limits of Git Hooks}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\footnotesize

\textbf{Strengths}

\begin{itemize}
  \item \y{Extremely fast feedback}. Helps you!!
  \item No external infrastructure required
  \item Works offline
  \item Integrated directly into Git commands
\end{itemize}

\vspace{2mm}
Git hooks are ideal for:
\begin{itemize}
  \item formatting checks
  \item unit tests
  \item catching trivial mistakes early
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize

\textbf{Limitations}

\begin{itemize}
  \item Run only on the developer machine
  \item Not enforced across a team
  \item Can be bypassed or disabled
  \item No neutral execution environment
\end{itemize}

\vspace{2mm}
As a consequence:
\begin{itemize}
  \item Hooks improve discipline
  \item But they do \rtext{not guarantee quality}
\end{itemize}

\end{column}

\end{columns}

\vspace{4mm}
\footnotesize
\rtext{\bf Git hooks accelerate development — CI platforms enforce standards.}

\end{frame}
%!TEX root = lec14.tex
% ================================================================================
% Lecture 14 — Slide 08
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Formatting vs Behavior: Two Different Checks}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\footnotesize

\vspace{-2mm}
\textbf{Code formatting (Black)}

\begin{itemize}
  \item Enforces a consistent style
  \item Removes whitespace and layout differences
  \item Does \rtext{not} change program logic
\end{itemize}

\vspace{2mm}
Example:
\begin{codeonly}{black reformats code}
def add( a ,b ):
  return a+b
\end{codeonly}

becomes:
\begin{codeonly}{}
def add(a, b):
    return a + b
\end{codeonly}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize

\textbf{Behavior testing (pytest)}

\begin{itemize}
  \item Checks whether code does the \y{right thing}
  \item Executes functions and validates results
  \item Fails if behavior changes unexpectedly
\end{itemize}

\vspace{2mm}
Formatting makes code readable.  
Testing makes code \rtext{\bf correct}.

\end{column}

\end{columns}

\vspace{2mm}
\footnotesize
\rtext{\bf Style and correctness are independent concerns.}

\end{frame}
%!TEX root = lec14.tex
% ================================================================================
% Lecture 14 — Slide 09
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Code and Test: Defining and Enforcing Behavior}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\textbf{Formatted Code}

\begin{codeonly}{test\_example.py}
def add(a, b):
    return a + b
\end{codeonly}

\vspace{2mm}
This code:
\begin{itemize}
  \item is syntactically correct
  \item is well formatted
  \item may still be \rtext{logically wrong}
\end{itemize}

\vspace{2mm}
Formatting alone cannot guarantee correctness.

\vspace{2mm}
\footnotesize
\y{\rtext{\bf Correct behavior is defined by function tests,}}
\y{\rtext{\bf not by appearance.}}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\textbf{Test that enforces behavior}

\begin{codeonly}{test\_example.py}
def test_add():
    assert add(2, 3) == 5
\end{codeonly}

\vspace{0mm}
This test:
\begin{itemize}
  \item executes the function
  \item checks the expected result
  \item fails automatically if behavior changes
\end{itemize}

\vspace{0mm}
The test can run:
\begin{itemize}
  \item locally
  \item in Git hooks
  \item in CI pipelines
\end{itemize}

\end{column}

\end{columns}


\end{frame}
%!TEX root = lec14.tex
% ================================================================================
% Lecture 14 — Slide 10
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{CI/CD Tools: \y{Local Discipline and Correctness}}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\vspace{-2mm}
\textbf{Version control}

\begin{itemize}
  \item \textbf{Git} \\
  {\tiny Tracks changes to source code and configuration files, enabling
  branching, merging, and full reconstruction of development history.}
  
  \item \textbf{GitHub / GitLab} \\
  {\tiny Hosting platforms for Git repositories, providing collaboration,
  access control, and CI integration.}
\end{itemize}

\vspace{0mm}
\textbf{Local enforcement}

\begin{itemize}
  \item \textbf{Git hooks} \\
  {\tiny Local scripts executed automatically on Git events
  (e.g.\ \texttt{pre-commit}) to enforce rules before code is committed.}

  \item \textbf{pre-commit framework} \\
  {\tiny Version-controlled hook manager that ensures identical checks across
  developers and CI environments.}
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\textbf{Code quality and correctness}

\begin{itemize}
  \item \textbf{Black} \\
  {\tiny Automatic Python formatter that enforces a single,
  deterministic code style without configuration decisions.}

  \item \textbf{pytest} \\
  {\tiny Python testing framework that executes test functions and
  fails automatically when expected behavior is violated.}
\end{itemize}

\vspace{0mm}
These tools:
\begin{itemize}
  \item run fast
  \item provide immediate feedback
  \item prevent trivial errors from propagating
\end{itemize}

\vspace{2mm}
\footnotesize
\rtext{\bf Local discipline reduces error rates before CI even starts.}

\end{column}

\end{columns}



\end{frame}
%!TEX root = lec14.tex
% ================================================================================
% Lecture 14 — Slide 11
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{CI/CD Tools: Automation and Execution}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\y{\textbf{CI orchestration}}

\begin{itemize}
  \item \textbf{GitHub Actions} \\
  {\tiny Event-driven CI system integrated into GitHub, executing workflows
  defined in YAML on managed runners.}

  \item \textbf{GitLab CI} \\
  {\tiny Pipeline-based CI system configured via \texttt{.gitlab-ci.yml},
  supporting self-hosted and specialized runners (e.g.\ HPC, GPU).}

  \item \textbf{Jenkins} \\
  {\tiny Standalone automation server using scripted pipelines,
  common in legacy and enterprise environments.}
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\y{\textbf{Execution environments}}

\begin{itemize}
  \item \textbf{Python virtual environments} \\
  {\tiny Isolate Python dependencies to ensure reproducible runtime behavior.}

  \item \textbf{Containers (Docker, Apptainer)} \\
  {\tiny Package applications and dependencies into portable,
  reproducible execution units across systems.}
\end{itemize}

\vspace{2mm}
\y{\textbf{Artifacts}}

\begin{itemize}
  \item \textbf{CI artifacts and registries} \\
  {\tiny Store outputs such as logs, test reports, trained models,
  and container images produced during pipelines.}
\end{itemize}

\end{column}

\end{columns}

\vspace{4mm}
\centering
\footnotesize
\rtext{\bf CI platforms enforce rules; environments make them reproducible.}

\end{frame}
%!TEX root = lec14.tex
% ================================================================================
% Lecture 14 — Slide 12
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Why Data Formats Matter in AI/ML}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\footnotesize

\textbf{Characteristics of training data}

\begin{itemize}
  \item Very large (GB–TB scale)
  \item Multi-dimensional (time, space, channels)
  \item Often produced continuously
\end{itemize}

\vspace{2mm}
In contrast to classical workflows:
\begin{itemize}
  \item Data rarely fits into memory
  \item Full sequential reads are uncommon
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize

\textbf{Typical ML access patterns}

\begin{itemize}
  \item Repeated sampling of small subsets
  \item Random or structured access
  \item Parallel reading by many workers
\end{itemize}

\vspace{2mm}
As a result, the \y{data format} directly affects:
\begin{itemize}
  \item I/O performance
  \item Scalability of training
  \item Feasibility of distributed ML
\end{itemize}

\end{column}

\end{columns}

\vspace{2mm}
\footnotesize
\rtext{\bf Data formats are part of the ML infrastructure, not just storage.}

\end{frame}
%!TEX root = lec14.tex
% ================================================================================
% Lecture 14 — Slide 13
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Zarr: Why It Is Attractive for AI/ML}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\footnotesize

\textbf{Design principles}

\begin{itemize}
  \item Chunked, array-based storage
  \item Designed for cloud and HPC
  \item Partial reads without full downloads
\end{itemize}

\vspace{2mm}
\textbf{Performance features}

\begin{itemize}
  \item Parallel reads of independent chunks
  \item Flexible chunk layout
  \item Compression per chunk
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize

\textbf{Why this helps ML training}

\begin{itemize}
  \item Efficient random sampling
  \item Scales to distributed workers
  \item Reduces I/O bottlenecks
\end{itemize}

\vspace{2mm}
\textbf{Typical use cases}

\begin{itemize}
  \item Images and video
  \item Satellite and geospatial data
  \item Scientific simulation output
\end{itemize}

\end{column}

\end{columns}

\vspace{2mm}
\footnotesize
\rtext{\bf Zarr optimizes data access patterns — not the ML logic itself.}

\end{frame}
%!TEX root = lec14.tex
% ================================================================================
% Lecture 14 — Slide 14
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Zarr: Limitations and When to Use Alternatives}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\footnotesize

\textbf{Limitations}

\begin{itemize}
  \item Limited native integration with ML frameworks
  \item Metadata overhead for many small arrays
  \item Not well suited for tabular data
  \item Care needed for concurrent writes
\end{itemize}

\vspace{2mm}
Zarr adds complexity that is not always justified.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize

\textbf{When to choose alternatives}

\begin{itemize}
  \item Tabular ML data: \y{Parquet}, Arrow
  \item TensorFlow pipelines: \y{TFRecord}
  \item PyTorch streaming: \y{WebDataset}
  \item Small datasets: NetCDF, HDF5, NPY
\end{itemize}

\vspace{2mm}
\textbf{Guiding principle}

\begin{itemize}
  \item Choose formats based on data structure
  \item Optimize for access pattern, not fashion
\end{itemize}

\end{column}

\end{columns}

\vspace{2mm}
\footnotesize
\rtext{\bf Zarr is powerful when the problem matches the format.}

\end{frame}
%!TEX root = lec14.tex
% ================================================================================
% Lecture 14 — Slide 15
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Demo Forecast Dataset (Europe, 5 variables)}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.58\textwidth}
\footnotesize
\vspace{-3mm}

\textbf{Dataset design}

\vspace{0mm}
We generate a small \y{synthetic forecast archive} over Europe:
\begin{itemize}
  \item grid: \texttt{lat} $\times$ \texttt{lon} (regular lat/lon)
  \item time axis: \texttt{valid\_time} for lead times (e.g.\ 0--120h)
  \item variables:
  \begin{itemize}
    \item \texttt{t2m} (2m temperature)
    \item \texttt{u10}, \texttt{v10} (10m wind)
    \item \texttt{mslp} (mean sea-level pressure)
    \item \texttt{tp} (precipitation)
  \end{itemize}
\end{itemize}

\vspace{0mm}
We mimic the \y{access patterns} of real NWP:
\begin{itemize}
  \item map snapshot for one lead time
  \item town / station time series extraction
  \item local patches for ML training
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.38\textwidth}
\footnotesize
\vspace{-8mm}

\textbf{Notebook outputs}

\vspace{1mm}
\begin{itemize}
  \item Zarr store:
  \\
  \texttt{data/demo\_eu\_forecast.zarr}
  \item first plots: Europe maps
  \item metadata: coordinates + attrs
\end{itemize}

\vspace{2mm}
\textbf{Next}
\begin{itemize}
  \item generate fields with moving patterns
  \item write to Zarr with chunking
\end{itemize}

\vspace{-2mm}
\includegraphics[width=5cm]{../../images/img14/zarr_ex_field_000.png}

\vspace{-3mm}
Lead Time: 0h

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec14.tex
% ================================================================================
% Lecture 14 — Slide 16
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Synthetic Forecast Generation (moving patterns)}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.58\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{Idea}

\vspace{0mm}
We generate physically plausible \y{spatio-temporal structure}:
\begin{itemize}
  \item coherent ``weather patterns'' move eastward with time
  \item correlated variables:
  \begin{itemize}
    \item pressure wave $\rightarrow$ wind via spatial gradients
    \item temperature advected + noise
    \item precipitation linked to fronts (thresholded patterns)
  \end{itemize}
\end{itemize}

\vspace{-1mm}
\begin{minipage}{6cm}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
# grid (Europe)
lon2d, lat2d = np.meshgrid(lon, lat)
# moving phase (eastward shift with lead time)
phase = kx * lon2d + ky * lat2d - omega * lead_hours[t]

# temperature: advected pattern
t2m[t] = 10.0 + 6.0*np.cos(phase + 0.7) + 0.8*rng.normal(size=lon2d.shape)
\end{lstlisting}
\end{minipage}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.38\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{Result}

\vspace{1mm}
Fields are realistic enough to demonstrate:
\begin{itemize}
  \item map snapshots
  \item point extraction
  \item patch-based ML sampling
\end{itemize}

\vspace{2mm}
\textbf{Example snapshot}

\vspace{1mm}
\includegraphics[width=5cm]{../../images/img14/zarr_ex_field_120.png}
Lead Time: 120h
\end{column}

\end{columns}

\end{frame}
%!TEX root = lec14.tex
% ================================================================================
% Lecture 14 — Slide 17
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Writing the Zarr Archive (chunking for point extraction)}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}

\footnotesize
\vspace{-1mm}
\textbf{Zarr write: key decisions}

\vspace{0mm}
We write the dataset as a \y{chunked archive}:
\begin{itemize}
  \item \textbf{time chunk = 1:} fast town time series extraction
  \item \textbf{lat/lon chunks = 60:} moderate patch size for ML sampling
\end{itemize}

\textbf{Chunk layout}

\vspace{1mm}
\begin{itemize}
  \item chunks stored as independent files
  \item town extraction reads \y{few chunks only}
  \item patches match ML mini-batches
\end{itemize}

\vspace{2mm}
We generate chunks that contain exactly \y{one lead time}
and a \y{60$\times$60} spatial patch.


\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\footnotesize
\vspace{-1mm}
Example: \\
\texttt{(valid\_time, lat, lon) = (1,60,60)}

\begin{minipage}{7cm}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
# ------------------------------------------------------------
# Zarr write
# ------------------------------------------------------------
OUTDIR = "data"
os.makedirs(OUTDIR, exist_ok=True)

ZARR_PATH = os.path.join(OUTDIR, "demo_eu_forecast.zarr")

# best practice: chunk so point extraction is fast
# - valid_time chunk = 1 (fast timeseries reading)
# - lat/lon chunks ~ moderate
chunked = ds.chunk({"valid_time": 1, "lat": 60, "lon": 60})

# overwrite if exists
if os.path.exists(ZARR_PATH):
    import shutil
    shutil.rmtree(ZARR_PATH)

chunked.to_zarr(ZARR_PATH, mode="w", consolidated=True)
print("Wrote:", ZARR_PATH)
\end{lstlisting}
\end{minipage}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec14.tex
% ================================================================================
% Lecture 14 — Slide 18
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Open Zarr Archive and Inspect Dataset}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}

\footnotesize
\vspace{-1mm}
\textbf{Open archive}

\vspace{0mm}
We open the Zarr store as an \texttt{xarray.Dataset}:
\begin{itemize}
  \item lazy loading via \texttt{dask.array}
  \item chunk layout is preserved:
  \\
  \texttt{(valid\_time, lat, lon) = (1,60,60)}
\end{itemize}

\vspace{2mm}
\textbf{Dataset structure}

\vspace{0mm}
\begin{itemize}
  \item dimensions: \texttt{valid\_time=41}, \texttt{lat=121}, \texttt{lon=181}
  \item variables: \texttt{t2m, u10, v10, mslp, tp}
  \item coordinate: \texttt{lead\_time} as timedelta
\end{itemize}

\vspace{2mm}
\textbf{Key observation}

\vspace{0mm}
Even though the archive is chunked, xarray provides a
\y{single logical dataset} interface.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\footnotesize
\vspace{-1mm}
Example:

\begin{minipage}{7cm}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
ZARR_PATH = "data/demo_eu_forecast.zarr"
ds = xr.open_zarr(ZARR_PATH, consolidated=True)
ds
\end{lstlisting}
\end{minipage}

\vspace{1mm}
\includegraphics[width=5.6cm]{../../images/img14/zarr_ds_summary.png}

\vspace{-2mm}
\scriptsize
Dataset preview: dimensions, coords, variables, and Dask chunks.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec14.tex
% ================================================================================
% Lecture 14 — Slide 19
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Town Forecast Extraction (nearest grid point)}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\footnotesize
\vspace{-1mm}
\textbf{Offline town database}

\vspace{0mm}
We use a small built-in town table:
\begin{itemize}
  \item no internet required
  \item town $\rightarrow$ \texttt{(lat,lon)}
\end{itemize}

\vspace{1mm}
\textbf{Point extraction}

\vspace{0mm}
From the full dataset we extract a \y{single point forecast}:
\begin{itemize}
  \item use nearest neighbor selection:
  \\
  \texttt{ds.sel(..., method="nearest")}
  \item result: dataset with only dimension \texttt{valid\_time}
\end{itemize}

\vspace{2mm}
\textbf{Output}

\vspace{0mm}
A compact dataset with time series for:
\texttt{t2m, u10, v10, mslp, tp}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\footnotesize
\vspace{-1mm}
Example:

\vspace{0mm}
\begin{minipage}{7cm}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
TOWNS = {
 "Berlin": (52.5200, 13.4050), ... }

pt = ds.sel(lat=lat0, lon=lon0, method="nearest")
\end{lstlisting}
\end{minipage}

\vspace{-1mm}
\includegraphics[width=5.6cm]{../../images/img14/zarr_pt_summary.png}

\vspace{2mm}
\scriptsize
Point forecast: only dimension \texttt{valid\_time} remains.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec14.tex
% ================================================================================
% Lecture 14 — Slide 20
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Town Forecast Dynamics (build time series table)}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.54\textwidth}

\footnotesize
\vspace{-1mm}
\textbf{Prepare time series data}

\vspace{0mm}
We convert the extracted point dataset into a clean table:
\begin{itemize}
  \item convert times to \texttt{datetime}
  \item convert lead time to hours
  \item compute derived variables (e.g.\ wind speed)
\end{itemize}

\vspace{-2mm}
\begin{minipage}{7.2cm}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
# ------------------------------------------------------------
# Create a clean timeseries table
# ------------------------------------------------------------
lead_h = (pt["lead_time"].values / np.timedelta64(1, "h")).astype(int)

df = pd.DataFrame({
    "valid_time": pd.to_datetime(pt["valid_time"].values),
    "lead_h": lead_h,
    "t2m_C": pt["t2m"].values,
    "wind_ms": np.sqrt(pt["u10"].values**2 + pt["v10"].values**2),
    "mslp_hPa": pt["mslp"].values,
    "tp_mm": pt["tp"].values,
})
\end{lstlisting}
\end{minipage}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}

\footnotesize
\vspace{-1mm}

\includegraphics[width=6.2cm]{../../images/img14/zarr_t2m_dynamics.png}

\vspace{2mm}
\includegraphics[width=6.2cm]{../../images/img14/zarr_wind_dynamics.png}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec14.tex
% ================================================================================
% Lecture 14 — Slide 21
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Local Map Plot (OSM basemap + 100 km temperature overlay)}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}

\footnotesize
\vspace{-2mm}
Visualize a local patch around the town:
\begin{itemize}
  \item \y{\rtext{\bf OpenStreetMap (OSM)}} background tiles
  \item overlay \texttt{t2m} for one lead time
  \item show only a 100 km box for clarity and speed
\end{itemize}

\vspace{1mm}
\textbf{Key steps}

\vspace{0mm}
\begin{itemize}
  \item select lead time index (e.g.\ 24h)
  \item slice \texttt{t2m} in a local lon/lat window
  \item reproject to WebMercator (EPSG:3857)
\end{itemize}

\vspace{-2mm}
\begin{minipage}{7.2cm}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
t2m_local = ds["t2m"].isel(valid_time=i).sel(
    lat=slice(latc-dlat, latc+dlat),
    lon=slice(lonc-dlon, lonc+dlon)
)

# plot on OSM background (contextily)
ctx.add_basemap(ax, source=ctx.providers.OpenStreetMap.Mapnik, zoom=10)
\end{lstlisting}
\end{minipage}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}

\footnotesize
\vspace{-3mm}

\includegraphics[width=6cm]{../../images/img14/zarr_map_Berlin_crop.png}

\vspace{2mm}
\scriptsize
\raggedleft
Example: Berlin, t2m at lead 24h \\
(local 100 km window).

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec14.tex
% ================================================================================
% Lecture 14 — Slide 22
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Training a CNN: field(t) -> field(t+1)}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}

\footnotesize
\vspace{-1mm}
\textbf{Learning task}

\vspace{0mm}
We train a CNN to predict next-step temperature:
\begin{itemize}
  \item input at time \texttt{t}: \texttt{t2m, u10, v10, mslp}
  \item target: \texttt{t2m(t+1)}
\end{itemize}

\vspace{1mm}
\textbf{Patch training}

\vspace{0mm}
Instead of full fields, we train on random patches:
\begin{itemize}
  \item sample \texttt{64x64} patches from random positions
  \item efficient mini-batches on laptop/GPU
  \item same idea as Zarr chunks: local spatial tiles
\end{itemize}

\vspace{1mm}
\textbf{Normalization}

\vspace{0mm}
Channel-wise mean/std over time and space:
\begin{itemize}
  \item stabilize training
  \item same scaling for training and evaluation
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\footnotesize
\vspace{-1mm}
Example:

\vspace{0mm}
\begin{minipage}{7cm}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
# inputs and target in RAM
t2m  = ds["t2m"].astype("float32").values
u10  = ds["u10"].astype("float32").values
v10  = ds["v10"].astype("float32").values
mslp = ds["mslp"].astype("float32").values

# normalization
Xin = np.stack([t2m, u10, v10, mslp], axis=1)
X_mean = Xin.mean(axis=(0,2,3), keepdims=True)
X_std  = Xin.std(axis=(0,2,3), keepdims=True) + 1e-6

y_mean = t2m.mean()
y_std  = t2m.std() + 1e-6
\end{lstlisting}
\end{minipage}

\vspace{1mm}
\begin{minipage}{7cm}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
# patch sampler: X(t) -> y(t+1)
Xt, yt = sample_patch_batch(batch_size=8, patch=64)

# small CNN: 4ch -> 1ch
model = SmallCNN(in_ch=4, out_ch=1, hidden=32)
loss_fn = nn.MSELoss()
opt = optim.Adam(model.parameters(), lr=2e-3)
\end{lstlisting}
\end{minipage}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec14.tex
% ================================================================================
% Lecture 14 — Slide 23
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Training Loop and Outcome (loss curve)}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}

\footnotesize
\vspace{-1mm}
\textbf{Training loop}

\vspace{0mm}
We train on randomly sampled spatial patches:
\begin{itemize}
  \item each step draws a new batch: location + time
  \item objective: MSE between predicted and true \texttt{t2m(t+1)}
  \item optimizer: Adam
\end{itemize}

\vspace{1mm}
\textbf{Expected behavior}

\vspace{0mm}
\begin{itemize}
  \item loss decreases quickly in the first iterations
  \item later it stabilizes (noise floor of the synthetic data)
  \item model learns local transport and correlations
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\footnotesize
\vspace{-8mm}
Example:

\vspace{0mm}
\begin{minipage}{7cm}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
rng = np.random.default_rng(123)
n_steps = 800
batch_size = 8

loss_hist = []

model.train()
for step in range(1, n_steps + 1):
    Xt, yt = sample_patch_batch(batch_size=batch_size, rng=rng)
    pred = model(Xt)
    loss = loss_fn(pred, yt)

    opt.zero_grad()
    loss.backward()
    opt.step()

    loss_hist.append(float(loss.item()))
\end{lstlisting}
\end{minipage}

\vspace{-2mm}
\includegraphics[width=6.2cm]{../../images/img14/zarr_training_loss.png}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec14.tex
% ================================================================================
% Lecture 14 — Slide 24
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Evaluation: rollout forecast from initial time}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}

\footnotesize
\vspace{-1mm}
\textbf{One-step skill}

\vspace{0mm}
We test the CNN on random samples:
\begin{itemize}
  \item predict \texttt{t2m(t+1)} from \texttt{X(t)}
  \item compare to truth with RMSE
  \item compare to persistence baseline
\end{itemize}

\vspace{1mm}
\textbf{Rollout forecast}

\vspace{0mm}
Starting from the initial forecast field:
\begin{itemize}
  \item use CNN repeatedly: $\hat{x}_{t+1} = f_\theta(\hat{x}_t)$
  \item build a full forecast trajectory
  \item then extract town series for comparison
\end{itemize}

\vspace{1mm}
This gives a realistic "mini NWP" demonstration:
\y{Zarr archive -> ML training -> forecast rollout}.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\footnotesize
\vspace{-1mm}
Example (rollout):

\vspace{0mm}
\begin{minipage}{7cm}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
# rollout: start from true initial field at t0
t2m_hat = t2m[0].copy()

pred_series = [t2m_hat]
for k in range(0, nt-1):
    Xk = build_features(t2m_hat, u10[k], v10[k], mslp[k])
    t2m_hat = predict_next_field(model, Xk)
    pred_series.append(t2m_hat)

pred_series = np.stack(pred_series, axis=0)  # (time, lat, lon)
\end{lstlisting}
\end{minipage}

\vspace{1mm}
\includegraphics[width=6.2cm]{../../images/img14/town_forecasts/fc_Berlin.png}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec14.tex
% ================================================================================
% Lecture 14 — Slide 25
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Outcome: Town Forecasts from ML Rollout}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}

\footnotesize
\vspace{-1mm}
\textbf{Town-level evaluation}

\vspace{0mm}
After rollout, we extract time series at town locations:
\begin{itemize}
  \item nearest neighbor on the lat/lon grid
  \item compare truth vs ML forecast
  \item generate one plot per town
\end{itemize}

\vspace{1mm}
\textbf{Saved outputs}

\vspace{0mm}
\begin{itemize}
  \item figures: \texttt{fc\_<town>.png}
  \item fast way to compare skill across cities
\end{itemize}

\vspace{-2mm}
\begin{minipage}{7.2cm}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
for town, (lat0, lon0) in TOWNS.items():
    # nearest grid point
    pt_true = ds.sel(lat=lat0, lon=lon0, method="nearest")

    # predicted series at same grid point
    y_true = pt_true["t2m"].values[:n_forecast+1]
    y_pred = pred_series[:, iy, ix]   # from rollout
\end{lstlisting}
\end{minipage}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\footnotesize
\vspace{-1mm}

\includegraphics[width=7cm]{../../images/img14/town_forecasts/fc_hamburg_crop.png}

\vspace{1mm}
\includegraphics[width=7cm]{../../images/img14/town_forecasts/fc_vienna_crop.png}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec14.tex
% ================================================================================
% Lecture 14 — Slide 26
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Zarr Chunk Decomposition (patch-only visualization)}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.40\textwidth}

\footnotesize
\vspace{-1mm}
\textbf{Goal}

\vspace{0mm}
\y{Visualize the Zarr chunk structure}:
\begin{itemize}
  \item each chunk corresponds to a spatial patch (60x60)
  \item plot patch values only (no full-field replot)
  \item use one global color scale (vmin/vmax of full field)
\end{itemize}

\vspace{1mm}
\textbf{Procedure}

\vspace{0mm}
\begin{itemize}
  \item load full field once (for vmin/vmax)
  \item loop over patch indices (py,px)
  \item save one image per patch
\end{itemize}


\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.58\textwidth}

\footnotesize
\vspace{-1mm}

\includegraphics[width=\textwidth]{../../images/img14/zarr_patches_grid.png}

\vspace{1mm}
\scriptsize
Patch-only plots: py=0..2, px=0..3 (Europe extent, global color scale).

\end{column}

\end{columns}

\end{frame}
% ================================================================================
% E-AI Tutorial Slides
% Filename: lec14.tex
%
% Roland Potthast 2025/2026
% Licence: CC-BY4.0
% ================================================================================
\documentclass[aspectratio=169]{beamer}

% --- Load lecture macros --------------------------------------------------------
\input{../lec_macros.tex}
\newcommand{\LectureNumber}{Lecture 14}

% --- Document -------------------------------------------------------------------
\begin{document}

\setagendaboxforlecture{14}

\input{../lec_agenda.tex}
\input{lec14_01.tex}
\input{lec14_02.tex}
\input{lec14_03.tex}
\input{lec14_04.tex}
\input{lec14_05.tex}
\input{lec14_06.tex}
\input{lec14_07.tex}
\input{lec14_08.tex}
\input{lec14_09.tex}
\input{lec14_10.tex}
\input{lec14_11.tex}
\input{lec14_12.tex}
\input{lec14_13.tex}
\input{lec14_14.tex}
\input{lec14_15.tex}
\input{lec14_16.tex}
\input{lec14_17.tex}
\input{lec14_18.tex}
\input{lec14_19.tex}
\input{lec14_20.tex}
\input{lec14_21.tex}
\input{lec14_22.tex}
\input{lec14_23.tex}
\input{lec14_24.tex}
\input{lec14_25.tex}
\input{lec14_26.tex}

% --- End Document ---------------------------------------------------------------
\end{document}
%!TEX root = lec15.tex
% ================================================================================
% Lecture 15 — Slide 01
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Why Anemoi?}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.55\textwidth}
\footnotesize

\textbf{Weather forecasting is a large-scale problem}

\begin{itemize}
  \item modern forecasts rely on \y{very large state vectors}
  \item global and regional fields with millions of grid points
  \item high temporal resolution and long time series
\end{itemize}

\vspace{2mm}
\textbf{Training data is massive}

\begin{itemize}
  \item global reanalyses such as \y{ERA5}, \y{ICON-DREAM}
  \item convection-permitting simulations (e.g.\ Arome, ICON-Force)
  \item multi-variable, multi-level, multi-year datasets
\end{itemize}

\vspace{2mm}
These datasets quickly reach \rtext{terabyte scale}.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.43\textwidth}
\footnotesize

\vspace{-8mm}
\textbf{What this implies for ML}

\begin{itemize}
  \item training must be \y{parallel and distributed}
  \item data access must be chunked and efficient
  \item geometry and grid structure must be respected
\end{itemize}

\vspace{2mm}
\textbf{Role of Anemoi}

\begin{itemize}
  \item parallelizes \y{fields and samples}
  \item integrates data, graphs, models, and training
  \item supports the \y{full ML lifecycle} for weather models
\end{itemize}

\vspace{2mm}
\rtext{\bf Anemoi is not a model — it is a framework.}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec15.tex
% ================================================================================
% Lecture 15 — Slide 02
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Design Philosophy of Anemoi}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize

\textbf{Core principles}

\begin{itemize}
  \item \y{configuration over hard-coded logic}
  \item clear separation of responsibilities
  \item scalable by construction
\end{itemize}

\vspace{2mm}
Anemoi is designed such that:
\begin{itemize}
  \item data handling,
  \item graph construction,
  \item model definition,
  \item training orchestration
\end{itemize}
are \rtext{independent but composable} components.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize

\vspace{-6mm}
\textbf{Declarative workflows}

\begin{itemize}
  \item experiments are defined in \y{YAML}
  \item components are selected, not programmed
  \item changes are traceable and reproducible
\end{itemize}

\vspace{2mm}
\textbf{Operational mindset}

\begin{itemize}
  \item same setup works on laptop, HPC, and cloud
  \item parallelism is explicit, not accidental
  \item full provenance of data and models
\end{itemize}

\vspace{2mm}
\rtext{\bf Anemoi treats ML experiments as engineering systems.}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec15.tex
% ================================================================================
% Lecture 15 — Slide 03
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{YAML: The Configuration Backbone}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize

\textbf{Why configuration matters at scale}

\begin{itemize}
  \item experiments involve many interacting components
  \item parameters change more often than code
  \item reproducibility depends on \y{explicit configuration}
\end{itemize}

\vspace{2mm}
In Anemoi, \y{YAML files define}:
\begin{itemize}
  \item datasets and preprocessing
  \item model architectures and hyperparameters
  \item training strategies and resources
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize

\textbf{Why YAML?}

\begin{itemize}
  \item human-readable and versionable
  \item hierarchical and structured
  \item easy to override and compose
\end{itemize}

\vspace{2mm}
\textbf{Design choice}

\begin{itemize}
  \item no Python code for experiment logic
  \item no hidden defaults in scripts
  \item configuration becomes a \rtext{first-class artifact}
\end{itemize}

\vspace{2mm}
\rtext{\bf In Anemoi, changing the experiment means changing YAML.}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec15.tex
% ================================================================================
% Lecture 15 — Slide 04
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{YAML in Practice: Declaring an Experiment}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\textbf{A single YAML file describes an experiment}

\begin{itemize}
  \item what data is used
  \item which model is trained
  \item how training is executed
\end{itemize}

\vspace{2mm}
No experiment logic is hidden in Python code.
The configuration is the experiment.


\vspace{5mm}
\footnotesize
\rtext{\bf This YAML file fully specifies one training run.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\footnotesize

\vspace{-5mm}
\begin{codeonly}{Example: training configuration (simplified)}
dataset:
  name: era5
  variables: [t2m, u10, v10]
  resolution: 0.25

model:
  name: graph_transformer
  hidden_dim: 256
  num_layers: 6

training:
  batch_size: 4
  max_epochs: 50
  accelerator: gpu
\end{codeonly}

\end{column}

\end{columns}


\end{frame}
%!TEX root = lec15.tex
% ================================================================================
% Lecture 15 — Slide 05
% ================================================================================
\begin{frame}[t]

\mytitle{OmegaConf: From YAML to Runtime Objects}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize

\textbf{The problem}

\begin{itemize}
  \item YAML files are static text
  \item training code needs structured objects
  \item configuration must be inspectable at runtime
\end{itemize}

\vspace{2mm}
\textbf{OmegaConf solves this}

\begin{itemize}
  \item represents configuration as Python objects
  \item preserves hierarchy and structure
  \item supports interpolation and defaults
\end{itemize}

\vspace{2mm}
The result is a \y{\texttt{DictConfig}} object.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}
\footnotesize

\textbf{Properties of \texttt{DictConfig}}

\begin{itemize}
  \item hierarchical (mirrors YAML structure)
  \item accessed via attributes or keys
  \item supports type checking
\end{itemize}

\vspace{2mm}
\textbf{Why this matters}

\begin{itemize}
  \item training code stays generic
  \item behaviour is fully configuration-driven
  \item experiments become reproducible by construction
\end{itemize}

\vspace{2mm}
\rtext{\bf Configuration becomes part of the program state.}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec15.tex
% ================================================================================
% Lecture 15 — Slide 06
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{OmegaConf in Practice and in Anemoi}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\footnotesize

\textbf{Using OmegaConf in Python}

\begin{itemize}
  \item configuration is passed into the training code
  \item parameters are accessed programmatically
  \item no hard-coded values are needed
\end{itemize}

\vspace{2mm}
\begin{codeonly}{Accessing the configuration}
# cfg provided by Hydra
print(cfg.model.layer_sizes)
print(cfg.training.max_epochs)
\end{codeonly}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\vspace{-5mm}
\begin{codeonly}{Resolving and converting}
from omegaconf import OmegaConf

OmegaConf.resolve(cfg)
cfg_dict = OmegaConf.to_object(cfg)
\end{codeonly}

\vspace{2mm}
\textbf{Role in Anemoi}

\begin{itemize}
  \item schemas validate configs before training
  \item resolved configs are logged with results
  \item the full configuration defines the experiment
\end{itemize}

\vspace{2mm}
\rtext{\bf OmegaConf links configuration and execution.}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec15.tex
% ================================================================================
% Lecture 15 — Slide 05
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Hydra: Managing Variants of the Same Experiment}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\footnotesize

\textbf{Motivation}

\begin{itemize}
  \item same training code
  \item same task (e.g.\ learning $\sin(x)$)
  \item different model architectures
\end{itemize}

\vspace{0mm}
Hydra allows:
\begin{itemize}
  \item selecting model variants via YAML
  \item switching architectures without code changes
  \item keeping experiments comparable
\end{itemize}

\vspace{0mm}
\textbf{Base configuration}

\begin{itemize}
  \item defines which components are active
  \item serves as the experiment entry point
\end{itemize}

\vspace{2mm}
\footnotesize
\rtext{\bf The experiment is composed, not rewritten.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\footnotesize

\vspace{-4mm}
\begin{codeonly}{config.yaml}
defaults:
  - model: mlp
  - training: simple
  - _self_
\end{codeonly}

\vspace{0mm}
\begin{codeonly}{model/mlp.yaml}
layer_sizes: [1, 64, 1]
activation: relu
\end{codeonly}

\vspace{0mm}
\begin{codeonly}{model/deep.yaml}
layer_sizes: [1, 128, 64, 32, 1]
activation: tanh
\end{codeonly}

\end{column}

\end{columns}


\end{frame}



%!TEX root = lec15.tex
% ================================================================================
% Lecture 15 — Slide 06
% ================================================================================
\begin{frame}[t]

\mytitle{Hydra in Practice: Same Code, Different Outcomes}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize

\textbf{What changes between these runs}

\begin{itemize}
  \item only the \y{Hydra configuration}
  \item different model definitions (\texttt{mlp} vs \texttt{deep})
  \item same training loop, same data
\end{itemize}

\vspace{2mm}
Hydra controls:
\begin{itemize}
  \item which YAML files are composed
  \item which model architecture is instantiated
  \item which hyperparameters are active
\end{itemize}

\vspace{0mm}
\textbf{Key observation}

\begin{itemize}
  \item shallow model converges smoothly
  \item deeper model shows slower, less stable training
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.54\textwidth}
\centering

\vspace{-2mm}
\includegraphics[width=0.48\textwidth]{../../images/img15/hydra1_mlp.png}
\includegraphics[width=0.48\textwidth]{../../images/img15/hydra2_mlp.png}

\vspace{2mm}

\includegraphics[width=0.48\textwidth]{../../images/img15/hydra1_deep.png}
\includegraphics[width=0.48\textwidth]{../../images/img15/hydra2_deep.png}

\vspace{2mm}
\footnotesize
\rtext{\bf Hydra makes architectural choices explicit, comparable, and reproducible.}

\end{column}

\end{columns}



\end{frame}
%!TEX root = lec15.tex
% ================================================================================
% Lecture 15 — Slide 09
% ================================================================================
\begin{frame}[t]

\mytitle{Why Graphs in Weather Machine Learning?}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize

\textbf{Weather data is not Cartesian}

\begin{itemize}
  \item global models use spherical geometry
  \item grids are often \y{non-uniform and unstructured}
  \item classical CNN assumptions break down
\end{itemize}

\vspace{2mm}
Examples:
\begin{itemize}
  \item ICON triangular grid
  \item reduced Gaussian grids
  \item observation networks
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}
\footnotesize

\textbf{Why graphs are a natural abstraction}

\begin{itemize}
  \item nodes represent spatial locations
  \item edges represent physical neighbourhoods
  \item locality is explicit, not implicit
\end{itemize}

\vspace{2mm}
\textbf{Key idea}

\begin{itemize}
  \item move from \y{array indices} to \y{connectivity}
  \item geometry becomes part of the model
\end{itemize}

\vspace{2mm}
\rtext{\bf Graphs decouple geometry from resolution.}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec15.tex
% ================================================================================
% Lecture 15 — Slide 10
% ================================================================================
\begin{frame}[t]

\mytitle{Icosahedral and Geodesic Graphs}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize

\textbf{ICON as a guiding principle}

\begin{itemize}
  \item refined icosahedral grids
  \item nearly uniform cell areas
  \item no singularities at the poles
\end{itemize}

\vspace{2mm}
Anemoi adopts the same idea:
\begin{itemize}
  \item nodes placed on a refined icosahedron
  \item spherical geometry is explicit
  \item resolution controlled by refinement level
\end{itemize}

\vspace{2mm}
\textbf{Key trade-off}

\begin{itemize}
  \item higher resolution $\Rightarrow$ more nodes
  \item increased cost, but better spatial fidelity
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}

\centering
\vspace{-10mm}

\includegraphics[width=0.95\textwidth]{../../images/img15/anemoi_graph_2.png}

\vspace{-1mm}
\footnotesize
Icosahedral graph on the sphere (orthographic projection).
Edges follow great-circle distances.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec15.tex
% ================================================================================
% Lecture 15 — Slide 11
% ================================================================================
\begin{frame}[t]

\mytitle{Edges, Neighbours, and Graph Topology}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize

\vspace{-2mm}
\textbf{Defining neighbourhoods}

\begin{itemize}
  \item edges encode spatial interaction
  \item most common choice: \y{k-nearest neighbours (kNN)}
  \item distance measured on the sphere
\end{itemize}

\vspace{0mm}
Each node exchanges information only with its neighbours:
\begin{itemize}
  \item local interactions
  \item scalable message passing
\end{itemize}

\textbf{Edge index representation}

\begin{itemize}
  \item graph stored as \texttt{edge\_index}
  \item integer pairs $(i,j)$ define connections
  \item independent of data values
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}
\footnotesize

\vspace{-8mm}
\textbf{Reuse across experiments}

\begin{itemize}
  \item graph built once
  \item reused for training, validation, inference
  \item ensures geometric consistency
\end{itemize}

\vspace{0mm}
\rtext{\bf Topology is fixed; data changes.}

\includegraphics[width=0.95\textwidth]{../../images/img15/Graph_connectivity.png}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec15.tex
% ================================================================================
% Lecture 15 — Slide 12
% ================================================================================
\begin{frame}[t]

\mytitle{Anemoi: A Modular ML Framework for Weather}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize

\textbf{Design philosophy}

\begin{itemize}
  \item separate concerns cleanly
  \item make each component replaceable
  \item scale from experiments to operations
\end{itemize}

\vspace{2mm}
Anemoi is not a single package, but a \y{coordinated ecosystem}.

\vspace{2mm}
Each package addresses one layer:
\begin{itemize}
  \item data handling
  \item graph construction
  \item model definition
  \item training orchestration
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}
\footnotesize

\textbf{Core Anemoi packages}

\begin{itemize}
  \item \texttt{anemoi-datasets}
  \item \texttt{anemoi-graphs} {\color{blue}in anemoi-core repo}
  \item \texttt{anemoi-models} {\color{blue}in anemoi-core repo}
  \item \texttt{anemoi-training} {\color{blue}in anemoi-core repo}
\end{itemize}

\vspace{2mm}
All packages:
\begin{itemize}
  \item use YAML + Hydra + OmegaConf
  \item integrate via clearly defined interfaces
  \item are developed in a shared monorepo
\end{itemize}

\vspace{2mm}
\rtext{\bf Graphs connect geometry; packages connect workflows.}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec15.tex
% ================================================================================
% Lecture 15 — Slide 13
% ================================================================================
\begin{frame}[t]

\mytitle{anemoi-datasets: Data and Metadata}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.55\textwidth}
\footnotesize

\textbf{Purpose}

\begin{itemize}
  \item prepare large meteorological datasets for ML
  \item unify metadata, statistics, and structure
  \item decouple raw data formats from training
\end{itemize}

\vspace{2mm}
\textbf{Key features}

\begin{itemize}
  \item \y{ingestion} from GRIB / NetCDF
  \item conversion to \y{Zarr}
  \item automatic statistics (mean, std, min, max)
  \item validation and consistency checks
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.41\textwidth}
\footnotesize

\vspace{-5mm}
\textbf{Why this matters}

\begin{itemize}
  \item scalable I/O for HPC and cloud
  \item reproducible data pipelines
  \item identical datasets across experiments
\end{itemize}

\vspace{2mm}
\rtext{\bf Data becomes a first-class, validated object.}

\vspace{2mm}
\includegraphics[width=6cm]{../../images/img15/anemoi_datasets.png}

\end{column}

\end{columns}

\vspace{5mm}
\footnotesize
\href{https://anemoi.readthedocs.io/projects/datasets/en/latest/}
{\texttt https://anemoi.readthedocs.io/projects/datasets/en/latest/}

\end{frame}
%!TEX root = lec15.tex
% ================================================================================
% Lecture 15 — Slide 14
% ================================================================================
\begin{frame}[t]

\mytitle{anemoi-graphs: Geometry and Connectivity}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\footnotesize

\textbf{Purpose}

\begin{itemize}
  \item represent \y{spatial geometry} explicitly
  \item construct reusable graph topologies
  \item support \y{non-Cartesian grids}
\end{itemize}

\vspace{2mm}
\textbf{Key components}

\begin{itemize}
  \item \texttt{TriNodes} from refined icosahedra
  \item neighbour definitions via kNN
  \item edge construction on the sphere
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\textbf{Design principle}

\begin{itemize}
  \item graph built once
  \item reused for training and inference
  \item geometry independent of data values
\end{itemize}

\vspace{2mm}
\rtext{\bf Topology is fixed; learning happens on it.}


\vspace{2mm}
\hspace*{-1cm}
\includegraphics[width=7cm]{../../images/img15/aicon_graphs.png}

\end{column}

\end{columns}

\vspace{5mm}
\footnotesize
\href{https://anemoi.readthedocs.io/projects/graphs/en/latest/}
\texttt{Docs: https://anemoi.readthedocs.io/projects/graphs/en/latest/}

\end{frame}
%!TEX root = lec15.tex
% ================================================================================
% Lecture 15 — Slide 15
% ================================================================================
\begin{frame}[t]

\mytitle{anemoi-models: Neural Architectures}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.55\textwidth}
\footnotesize

\textbf{Purpose}

\begin{itemize}
  \item define \y{ML models} for weather prediction
  \item separate architecture from training logic
  \item support graph-based learning
\end{itemize}

\vspace{2mm}
\textbf{Model families}

\begin{itemize}
  \item \y{graph} neural networks
  \item \y{transformer-based} architectures
  \item hybrid models for spatio-temporal data
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.41\textwidth}
\footnotesize

\vspace{-8mm}
\textbf{Interfaces}

\begin{itemize}
  \item standardized input/output conventions
  \item integration with PyTorch Lightning
  \item instantiated via Hydra configs
\end{itemize}

\vspace{2mm}
\rtext{\bf Models are components, not scripts.}

\vspace{0mm}
\hspace*{-1cm}
\includegraphics[width=6cm]{../../images/img15/anemoi_graph_3.png}

\end{column}

\end{columns}

\vspace{5mm}
\footnotesize
\href{https://anemoi.readthedocs.io/projects/models/en/latest/}
\texttt{Docs: https://anemoi.readthedocs.io/projects/models/en/latest/}

\end{frame}
%!TEX root = lec15.tex
% ================================================================================
% Lecture 15 — Slide 16
% ================================================================================
\begin{frame}[t]

\mytitle{anemoi-training: Orchestrating Experiments}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.55\textwidth}
\footnotesize

\textbf{Purpose}

\begin{itemize}
  \item orchestrate the full training lifecycle
  \item integrate data, graphs, and models
  \item scale to HPC environments
\end{itemize}

\vspace{2mm}
\textbf{Key elements}

\begin{itemize}
  \item \texttt{AnemoiTrainer} as central controller
  \item PyTorch Lightning backend
  \item distributed and multi-node training
\end{itemize}


\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.41\textwidth}
\footnotesize

\vspace{-8mm}
\textbf{Experiment control}

\begin{itemize}
  \item driven entirely by configuration
  \item automatic logging and checkpointing
  \item reproducible, restartable runs
\end{itemize}

\vspace{2mm}
\rtext{\bf Training becomes declarative and scalable.}

\vspace{0mm}
\hspace*{-1cm}
\includegraphics[width=6cm]{../../images/img15/aicon_training.png}

\end{column}

\end{columns}

\vspace{0mm}
\footnotesize
\href{https://anemoi.readthedocs.io/projects/training/en/latest/}
\texttt{Docs: https://anemoi.readthedocs.io/projects/training/en/latest/}

\end{frame}
%!TEX root = lec15.tex
% ================================================================================
% Lecture 15 — Slide 17
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Creating Zarr Datasets with anemoi-datasets}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.53\textwidth}
\footnotesize

\vspace{-3mm}
\begin{itemize}
  \item convert raw meteorological data into ML-ready format
  \item standardize structure, metadata, and statistics
  \item enable scalable training and validation
\end{itemize}

\vspace{0mm}
\textbf{Key idea}

\begin{itemize}
  \item dataset creation is fully \y{configuration-driven}
  \item no preprocessing logic is hard-coded
  \item every dataset is reproducible
\end{itemize}

\vspace{0mm}
Typical processing steps:
\begin{itemize}
  \item read GRIB or NetCDF input
  \item reshape and flatten grids if required
  \item compute global statistics
  \item write chunked Zarr archive
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.45\textwidth}
\footnotesize

\vspace{-3mm}
\begin{codeonly}{Command-line workflow}
anemoi-datasets create \
  dataset.yaml \
  era5.zarr
\end{codeonly}

\vspace{2mm}
\textbf{Result}

\begin{itemize}
  \item validated Zarr dataset
  \item embedded metadata and statistics
  \item directly usable by Anemoi training
\end{itemize}

\vspace{2mm}
\rtext{\bf Data preparation becomes a reproducible pipeline.}

\vspace{5mm}
\footnotesize
\hspace*{-2.5cm}\href{https://anemoi.readthedocs.io/projects/datasets/en/latest/}
     {\texttt{https://anemoi.readthedocs.io/projects/datasets/en/latest/}}

\end{column}

\end{columns}



\end{frame}
%!TEX root = lec15.tex
% ================================================================================
% Lecture 15 — Slide 18
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Validating and Inspecting Zarr Datasets}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.56\textwidth}
\footnotesize

\textbf{Why validation matters}

\begin{itemize}
  \item training assumes consistent metadata
  \item missing values or shapes cause silent errors
  \item errors should be caught \y{before} training
\end{itemize}

\vspace{2mm}
Anemoi provides built-in tools to:
\begin{itemize}
  \item verify temporal coverage
  \item check spatial resolution and shapes
  \item ensure statistics are present
\end{itemize}

\vspace{2mm}
Validation is part of the dataset lifecycle,
not an afterthought.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.40\textwidth}
\footnotesize

\begin{codeonly}{Inspecting a dataset}
anemoi-datasets inspect era5.zarr
\end{codeonly}

\vspace{2mm}
Typical output includes:
\begin{itemize}
  \item time range and frequency
  \item variables and dimensions
  \item min / max / mean / std
  \item total size and chunking
\end{itemize}

\vspace{2mm}
\rtext{\bf Only validated datasets enter training.}

\end{column}

\end{columns}

\vspace{2mm}
\footnotesize
\href{https://anemoi.readthedocs.io/projects/datasets/en/latest/}
     {\texttt{Docs: anemoi-datasets}}

\end{frame}
%!TEX root = lec15.tex
% ================================================================================
% Lecture 15 — Slide 19
% ================================================================================
\begin{frame}[t]

\mytitle{ERA Data Stored in Zarr}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize

\textbf{What these images show}

\begin{itemize}
  \item ERA reanalysis data after Zarr conversion
  \item accessed chunk-wise, not as monolithic files
  \item identical physical content, different storage logic
\end{itemize}

\vspace{2mm}
Zarr enables:
\begin{itemize}
  \item parallel access to spatial subdomains
  \item efficient mini-batching for ML
  \item scalable training on HPC systems
\end{itemize}

\vspace{2mm}
\rtext{\bf Zarr is an ML-optimized view \\
of reanalysis data.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\centering

\vspace{-10mm}
\includegraphics[width=0.95\textwidth]{../../images/img15/era_t2m_2025_01_01_00_crop.png}

\vspace{-2mm}

\includegraphics[
  width=0.8\textwidth,
  trim=0 6cm 0 0,
  clip
]{../../images/img15/era_zarr_1_0_crop.png}


\vspace{1mm}
\footnotesize
Top: Global ERA5 2\,m temperature field.\\
Bottom: Spatial chunk extracted from Zarr archive.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec15.tex
% ================================================================================
% Lecture 15 — Slide 20
% ================================================================================
\begin{frame}[t]
\mytitle{Application Example: Learning CBCF Warning Polygons from Forecast Fields}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize
\vspace{-2mm}

Learn an AI model that predicts \y{operational warning regions}
(CBCF polygons) from model forecast fields.

\vspace{0mm}
\textbf{Training data}

\begin{itemize}
  \item multi-year archive of forecast fields (e.g.\ wind/gust)
  \item forecaster-issued \y{warning polygons} 
\end{itemize}

\vspace{0mm}
\textbf{Core idea}

\begin{itemize}
  \item polygons are a \y{human product representation}
  \item neural nets learn on \y{grids / tensors}
  \item therefore we convert polygons $\rightarrow$ \y{mask labels}
\end{itemize}

\vspace{2mm}
\rtext{\bf We train on masks --- and recover polygons afterwards.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\vspace{-4mm}
\centering
\includegraphics[width=\textwidth]{../../images/img15/cbcf_d0_20240501_12utc.png}

\vspace{1mm}
\scriptsize Example CBCF polygons (likelihood categories).
\end{column}

\end{columns}
\end{frame}
%!TEX root = lec15.tex
% ================================================================================
% Lecture 15 — Slide 21
% ================================================================================
\begin{frame}[t]
\mytitle{From Polygons to Masks: Training Labels on the Model Grid}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{Why convert polygons to masks?}

\vspace{0mm}
\begin{itemize}
  \item operational warnings are defined as \y{polygons}
  \item neural nets require \y{grid-aligned targets}
  \item rasterization yields a binary/soft \y{mask} $m(x)\in[0,1]$
\end{itemize}

\vspace{1mm}
\textbf{Two-way conversion}

\vspace{0mm}
\begin{itemize}
  \item \textbf{Polygon $\rightarrow$ mask:} rasterize onto model grid
  \item \textbf{Mask $\rightarrow$ polygon:} contour / region extraction
\end{itemize}

\vspace{1mm}
\textbf{Quality control}

\vspace{0mm}
\begin{itemize}
  \item check \y{mask(polygons)} against reference labels
  \item difference highlights discretization artefacts
\end{itemize}


\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\vspace{-2mm}
\begin{itemize}
  \item predictors: \y{wind} + \y{gust} fields
  \item target: warning mask derived from polygons
\end{itemize}


\centering
\includegraphics[width=\textwidth]{../../images/img15/polygon_to_mask.png}

\vspace{1mm}
\scriptsize Polygon-to-mask conversion and consistency check.
\end{column}

\end{columns}
\end{frame}
%!TEX root = lec15.tex
% ================================================================================
% Lecture 15 — Slide 22
% ================================================================================
\begin{frame}[t]
\mytitle{Learning Demo: Inputs (Wind/Gust) $\rightarrow$ True vs Predicted Mask \& Polygons}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{This figure shows one training/evaluation example}

\vspace{0mm}
\begin{itemize}
  \item predictors are \y{gridded forecast fields}
  \item target is a \y{warning mask} derived from forecaster polygons
  \item predicted mask is transformed back into \y{polygons}
\end{itemize}

\vspace{2mm}
\textbf{Layout (4 columns)}

\vspace{0mm}
\begin{enumerate}
  \item \textbf{Input 1:} wind field
  \item \textbf{Input 2:} gust field
  \item \textbf{Target:} true mask + true polygons
  \item \textbf{Prediction:} predicted mask + recovered polygons
\end{enumerate}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\vspace{-4mm}
\centering
\includegraphics[width=\textwidth]{../../images/img15/polygon_prediction_test2.png}

\vspace{1mm}
\scriptsize 4-column result: inputs, target, prediction.
\end{column}

\end{columns}
\end{frame}
%!TEX root = lec15.tex
% ================================================================================
% Lecture 15 — Slide 23
% ================================================================================
\begin{frame}[t,fragile]
\mytitle{Real Demo: CBCF Training with Anemoi (Repository Setup)}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.58\textwidth}
\footnotesize
\vspace{-2mm}

We ran the CBCF demo using an \y{Anemoi-based training stack}.

\vspace{1mm}
\textbf{Local repo structure}

\vspace{0mm}
\begin{itemize}
  \item \texttt{anemoi-datasets}  (data handling, zarr)
  \item \texttt{anemoi-transform} (preprocessing)
  \item \texttt{anemoi-core} (graphs, models, training)
  \item \texttt{training\_config/} (yaml configs)
  \item \texttt{batch\_train.sh} (run script)
\end{itemize}

\vspace{2mm}
\textbf{Key point}

\vspace{0mm}
\begin{itemize}
  \item this is not a standalone notebook hack
  \item it is a \y{reproducible training workflow} (configs + checkpoints)
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.42\textwidth}
\vspace{-2mm}
\footnotesize
\textbf{Dependencies (uv workspace)}

\vspace{-1mm}
\begin{itemize}
  \item \texttt{anemoi-training, anemoi-models, anemoi-graphs, ...}
  \item \texttt{aicon-catalog[create]}
\end{itemize}

\textbf{Commands (as executed)}
\begin{lstlisting}[basicstyle=\ttfamily\scriptsize]
cd cbcf
git pull
ls training_config
# run: batch_train.sh
\end{lstlisting}

\vspace{2mm}
\textbf{Outcome}
\begin{itemize}
  \item trained checkpoints
  \item inference + plots
\end{itemize}

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec15.tex
% ================================================================================
% Lecture 15 — Slide 24
% ================================================================================
\begin{frame}[t,fragile]
\mytitle{Configuration-Driven Workflow: Training \& Diagnosis YAML}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.58\textwidth}

\footnotesize
\vspace{-4mm}
\begin{itemize}
  \item training is \y{fully reproducible} and versionable
  \item separation of concerns:
  \begin{itemize}
    \item dataset / resolution (R3B5, R3B8, ...)
    \item variables (inputs/targets)
    \item model architecture choice
    \item training schedule / precision / hardware
  \end{itemize}
\end{itemize}

\vspace{2mm}
\textbf{Example config files}

\vspace{0mm}
\begin{itemize}
  \item \texttt{training\_config/cbcf\_graph\_R3B5.yaml}
  \item \texttt{training\_config/cbcf\_diagnose\_R3B5.yaml}
\end{itemize}

\vspace{2mm}
\textbf{Demo message}

\vspace{0mm}
We can train CBCF models for \y{different ICON grids and resolutions}
without changing code --- only by switching configs.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.42\textwidth}
\vspace{-2mm}
\footnotesize

\textbf{Conceptual config blocks}
\begin{lstlisting}[basicstyle=\ttfamily\scriptsize]
dataset:
  resolution: R03B05
model:
  type: graph/diagnoser
training:
  precision: 16-mixed
outputs:
  checkpoint: inference-last.ckpt
\end{lstlisting}

\vspace{1mm}
\scriptsize
(Shown here only conceptually --- actual files live in
\texttt{training\_config/} and include many more details.)

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec15.tex
% ================================================================================
% Lecture 15 — Slide 25
% ================================================================================
\begin{frame}[t,fragile]
\mytitle{Inference Pipeline: Load Checkpoint $\rightarrow$ Predict $\rightarrow$ Plot}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.58\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{What happens after training?}

\vspace{0mm}
\begin{itemize}
  \item load \y{checkpoint} (\texttt{inference-last.ckpt})
  \item load forecast data from \y{zarr archive}
  \item build input tensor (multi-step input supported)
  \item run \texttt{model.predict\_step(...)}
\end{itemize}

\vspace{0mm}
\textbf{Outputs}

\vspace{0mm}
\begin{itemize}
  \item predicted CBCF fields / masks
  \item comparison against targets
  \item saved plots per date + variable
\end{itemize}

\vspace{0mm}
\textbf{Take-away}

\vspace{0mm}
\begin{itemize}
  \item same pipeline works for long archives
  \item basis for \y{operational verification and monitoring}
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.42\textwidth}
\vspace{-2mm}
\footnotesize

\textbf{Code sketch (from \texttt{main.py})}
\begin{lstlisting}[basicstyle=\ttfamily\scriptsize]
model = torch.load(ckpt)
model.eval()

ds = zarr.open("...CBCF.zarr")

input = build_tensor(...)
y_pred = model.predict_step(input)

plot(y_pred); plot(target)
\end{lstlisting}

\vspace{1mm}
\scriptsize
The demo uses multi-step inputs and produces predicted/target plots.

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec15.tex
% ================================================================================
% Lecture 15 — Slide 26
% ================================================================================
\begin{frame}[t]
\mytitle{CBCF Results: Anemoi Training Demo (Examples)}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{What we show}

\vspace{0mm}
\begin{itemize}
  \item results from the Anemoi-based training workflow
  \item prediction of CBCF target fields / masks from forecast inputs
  \item comparison against the corresponding targets
\end{itemize}

\vspace{2mm}
\textbf{Interpretation}


\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\vspace{-4mm}
\centering

\includegraphics[width=\textwidth]{../../images/img15/cbcf_results_2.png}

\end{column}

\end{columns}

\vspace{0mm}
\begin{itemize}
  \item spatial patterns are learned coherently
  \item overall structure matches operational products
  \item remaining differences motivate the next steps:
  \begin{itemize}
    \item improved architectures
    \item longer training / larger datasets
    \item calibration and polygon-space verification
  \end{itemize}
\end{itemize}

\end{frame}
%!TEX root = lec15.tex
% ================================================================================
% Lecture 15 — Slide 27
% ================================================================================
\begin{frame}[t]
\mytitle{CBCF Results: Predicted vs Target Fields (Selected Outputs)}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
% Left column: cbcf_results_4.png
% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\vspace{0mm}
\centering

\includegraphics[
  width=\textwidth,
  keepaspectratio
]{../../images/img15/cbcf_results_4.png}

\vspace{2mm}
\scriptsize
\textbf{Fields shown (left = prediction, right = target):}
\begin{itemize}
  \item \texttt{CBCF}: main warning mask/product
  \item \texttt{CBCF\_likeliness}: continuous likelihood / confidence field
\end{itemize}

\end{column}

% ------------------------------------------------------------
% Right column: cbcf_results_5.png
% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\vspace{0mm}
\centering

\includegraphics[
  width=\textwidth,
  keepaspectratio
]{../../images/img15/cbcf_results_5.png}

\vspace{2mm}
\scriptsize
\textbf{Fields shown (left = prediction, right = target):}
\begin{itemize}
  \item \texttt{CBCF\_top}: top-level / dominant CBCF intensity field
  \item \texttt{CLST}: additional label channel (sparser warning type)
\end{itemize}

\end{column}

\end{columns}
\end{frame}
% ================================================================================
% E-AI Tutorial Slides
% Filename: lec15.tex
%
% Roland Potthast 2025/2026
% Licence: CC-BY4.0
% ================================================================================
\documentclass[aspectratio=169]{beamer}

% --- Load lecture macros --------------------------------------------------------
\input{../lec_macros.tex}
\newcommand{\LectureNumber}{Lecture 15}

% --- Document -------------------------------------------------------------------
\begin{document}

\setagendaboxforlecture{15}

\input{../lec_agenda.tex}
\input{lec15_01.tex}
\input{lec15_02.tex}
\input{lec15_03.tex}
\input{lec15_04.tex}
\input{lec15_05.tex}
\input{lec15_06.tex}
\input{lec15_07.tex}
\input{lec15_08.tex}
\input{lec15_09.tex}
\input{lec15_10.tex}
\input{lec15_11.tex}
\input{lec15_12.tex}
\input{lec15_13.tex}
\input{lec15_14.tex}
\input{lec15_15.tex}
\input{lec15_16.tex}
\input{lec15_17.tex}
\input{lec15_18.tex}
\input{lec15_19.tex}
\input{lec15_20.tex}
\input{lec15_21.tex}
\input{lec15_22.tex}
\input{lec15_23.tex}
\input{lec15_24.tex}
\input{lec15_25.tex}
\input{lec15_26.tex}
\input{lec15_27.tex}

% --- End Document ---------------------------------------------------------------
\end{document}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16, Slide 01
% ================================================================================
\begin{frame}[t]
  \mytitle{The AI Transformation: Communication History in 8 Steps}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize
\vspace{4mm}

\textbf{\textcolor{blue}{From printed knowledge to mass media}}

\vspace{2mm}
\begin{itemize}
  \item \textbf{Book printing} \hfill \textcolor{gray}{\textbf{1450}}
    {\tiny \newline \textcolor{gray}{(Gutenberg press, scalable knowledge)}}
  \item \textbf{Electricity / telegraph} \hfill \textcolor{gray}{\textbf{1837}}
    {\tiny \newline \textcolor{gray}{(Morse telegraph, instant signals)}}
  \item \textbf{Radio} \hfill \textcolor{gray}{\textbf{1895}}
    {\tiny \newline \textcolor{gray}{(wireless transmission, mass broadcasting)}}
  \item \textbf{Television} \hfill \textcolor{gray}{\textbf{1927}}
    {\tiny \newline \textcolor{gray}{(moving images, global events)}}
\end{itemize}

\vspace{2mm}
\footnotesize
\textbf{\textcolor{red}{Transformation:}}
\quad \y{Communication turns into interaction.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize
\vspace{4mm}

\textbf{\textcolor{violet}{From computation to language interfaces}}

\vspace{2mm}
\begin{itemize}
  \item \textbf{Computers} \hfill \textcolor{gray}{\textbf{1941}}
    {\tiny \newline \textcolor{gray}{(Konrad Zuse Z3, programmable digital computer)}}
  \item \textbf{Internet} \hfill \textcolor{gray}{\textbf{1983}}
    {\tiny \newline \textcolor{gray}{(TCP/IP, global connectivity)}}
  \item \textbf{WWW} \hfill \textcolor{gray}{\textbf{1993}}
    {\tiny \newline \textcolor{gray}{(Internet for all!)}}
  \item \textbf{Social media} \hfill \textcolor{gray}{\textbf{2004}}
    {\tiny \newline \textcolor{gray}{(Facebook era, interactive networks)}}
  \item \textbf{\textcolor{violet}{LLMs \& AI systems}} \hfill \textcolor{gray}{\textbf{2022}}
    {\tiny \newline \textcolor{gray}{(\y{language becomes an interface}, interaction at scale)}}
\end{itemize}

\end{column}

\end{columns}


\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16, Slide 02
% ================================================================================
\begin{frame}[t]
  \mytitle{Why Now? The Next Step Has Arrived}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}
\footnotesize
\vspace{5mm}

\textbf{\textcolor{blue}{A new communication revolution}}

\vspace{2mm}
\begin{itemize}
  \item Book printing scaled \textbf{knowledge}
  \item Internet scaled \textbf{connectivity}
  \item \textbf{LLMs scale interaction:}
    \y{language becomes an interface}
\end{itemize}

\vspace{4mm}
\textbf{\textcolor{red}{What changes:}}

\vspace{1mm}
\begin{itemize}
  \item from \textbf{information access}
  \item to \textbf{interactive assistance}
\end{itemize}

\vspace{3mm}
{\tiny
This affects communication, documentation, coding, workflows
\textemdash{} across the entire organisation.
}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.56\textwidth}
\centering
\vspace{0mm}

\includegraphics[width=\linewidth]{../../images/img16/comm_history_crop2.png}

\vspace{5mm}
{ \textcolor{gray}{
\begin{minipage}{0.92\linewidth}
\centering
\emph{
Progress in Communication. \\
What does it mean? \\
Where are we as humans?
}
\end{minipage}
}}


\end{column}

\end{columns}

\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16, Slide 03
% ================================================================================
\begin{frame}[t]
  \mytitle{Why Now? Language Becomes an Interface}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.56\textwidth}
\footnotesize
\vspace{2mm}

\textbf{\textcolor{blue}{What changed in 2022?}}

\vspace{2mm}
\begin{itemize}
  \item For the first time, computers can handle \y{natural language 
  \rtext{appropriately}}
  \item This enables \textbf{interaction} instead of programming
  \item Not only answers --- but \textbf{actions}:
    {\tiny \newline (writing, summarizing, translating, coding, planning)}
\end{itemize}

\vspace{3mm}
\textbf{\textcolor{blue}{New capability: conversational work}}

\vspace{1mm}
{
\begin{itemize}
  \item Ask $\rightarrow$ draft $\rightarrow$ revise $\rightarrow$ finalize
  \item Explain $\rightarrow$ implement $\rightarrow$ test $\rightarrow$ debug
\end{itemize}
}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}
\footnotesize
\vspace{2mm}

\textbf{\textcolor{violet}{Examples in daily work}}

\vspace{2mm}
\begin{itemize}
  \item Draft emails, minutes, reports
  \item Summarize long documents
  \item Create slides from bullet points
  \item Helpdesk: FAQ, ticket triage
  \item Code assistance: refactor + docs
\end{itemize}

\vspace{3mm}
\textbf{\textcolor{red}{Key message:}}

\vspace{1mm}
\y{AI affects everyone} \textemdash{}
not only scientists or IT staff.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16, Slide 04
% ================================================================================
\begin{frame}[t]
  \mytitle{\rtext{Slow Down:} 1993: The Internet Becomes Public}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize
\vspace{4mm}

\textbf{\textcolor{blue}{1993: a global information layer}}

\vspace{2mm}
\begin{itemize}
  \item Web browsers make the Internet usable for everyone
  \item Information access becomes \textbf{self-service}
  \item Knowledge shifts from \textbf{local} to \textbf{global}
\end{itemize}

\vspace{4mm}
\textbf{\textcolor{red}{Key change:}}
\quad \y{Search and access replace distribution.}

\vspace{3mm}
{\footnotesize
Many workflows become web-based:
documentation, support, collaboration, publishing.
}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\centering
\vspace{-4mm}

\includegraphics[width=\linewidth]{../../images/img16/1993_computer_and_web_crop.png}

\vspace{2mm}
{\tiny \textcolor{gray}{Internet era: global connectivity and instant access}}
\end{column}

\end{columns}

\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16, Slide 05
% ================================================================================
\begin{frame}[t]
  \mytitle{2004 / 2008: Social Media + Smartphones}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize
\vspace{4mm}

\textbf{\textcolor{blue}{From websites to interactive networks}}

\vspace{2mm}
\begin{itemize}
  \item 2004: social networks go mainstream
  \item 2007/2008: smartphones put the Internet in every pocket
  \item Everyone becomes: \textbf{consumer + producer + distributor}
\end{itemize}

\vspace{4mm}
\textbf{\textcolor{red}{Key change:}}
\quad \y{Communication becomes continuous and interactive.}

\vspace{3mm}
{\tiny
Attention becomes a resource; content flows in real time.
}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\centering
\vspace{-4mm}

\includegraphics[width=\linewidth]{../../images/img16/smartphone_crop.jpeg}

\vspace{2mm}
{\footnotesize \textcolor{gray}{The always-on era: interaction at global scale}}
\end{column}

\end{columns}

\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16, Slide 06
% ================================================================================
\begin{frame}[t]
  \mytitle{2012--2019: The ML Revolution in Vision and Translation}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\footnotesize
\vspace{4mm}

\textbf{\textcolor{blue}{Deep learning becomes practical}}

\vspace{2mm}
\begin{itemize}
  \item \rtext{\bf Image recognition} jumps to new accuracy levels
  \item \rtext{\bf Machine translation} improves dramatically
  \item Pattern learning outperforms hand-crafted rules
\end{itemize}

\vspace{4mm}
\textbf{\textcolor{red}{Key change:}}
\quad \y{Perception tasks become learnable at scale.}

\vspace{3mm}
{\tiny
This is the foundation for today’s multi-modal AI
(text, images, audio).
}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\centering
\vspace{2mm}

\includegraphics[width=\linewidth]{../../images/img16/images_and_translation_crop.jpeg}

\vspace{2mm}
{\footnotesize \textcolor{gray}{Modern deep learning architectures enable scaling}}
\end{column}

\end{columns}

\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16, Slide 07
% ================================================================================
\begin{frame}[t]
  \mytitle{2022: The Chatbot Threshold}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\footnotesize
\vspace{4mm}

\textbf{\textcolor{blue}{The breakthrough: language interaction}}

\vspace{2mm}
\begin{itemize}
  \item Chatbots become useful for real work
  \item People can \textbf{ask, refine, and iterate} in dialogue
  \item The interface is now \y{natural language}
\end{itemize}

\vspace{4mm}
\textbf{\textcolor{red}{Key change:}}
\quad \y{From communication to interaction.}

\vspace{3mm}
{\tiny
LLMs + tools + knowledge access $\Rightarrow$ AI assistants and agents.
}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\centering
\vspace{-8mm}

\includegraphics[width=\linewidth]{../../images/img16/chatbot2022_crop.jpeg}

\vspace{2mm}
{\tiny \textcolor{gray}{Chatbots evolve into systems: retrieval + tools + guardrails}}
\end{column}

\end{columns}

\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16, Slide 08
% ================================================================================
\begin{frame}[t,fragile]
  \mytitle{LLMs in One Sentence}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize
\vspace{4mm}

\textbf{\textcolor{blue}{A large language model is a prediction machine}}

\vspace{2mm}
\begin{itemize}
  \item It reads text and predicts \textbf{the next token}
  \item It repeats this step many times to produce an answer
  \item Training: learn statistical structure from huge corpora
\end{itemize}

\vspace{4mm}
\textbf{\textcolor{red}{Key point:}}
\quad It does not store facts like an encyclopedia.  
It learns \y{patterns of language and reasoning}.
\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.54\textwidth}
\centering
\vspace{2mm}

\includegraphics[width=\linewidth]{../../images/img16/transformer_all.jpeg}

\vspace{-4mm}
{\tiny \textcolor{gray}{Transformer models: sequence in $\rightarrow$ sequence out}}
\end{column}

\end{columns}

\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16, Slide 09
% ================================================================================
\begin{frame}[t]
  \mytitle{Step 1: From Text to Tokens}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}
\footnotesize
\vspace{4mm}

\textbf{\textcolor{blue}{Computers do not read words}}

\vspace{2mm}
\begin{itemize}
  \item Text is split into \textbf{tokens}
  \item Tokens are pieces of words, punctuation, spaces
  \item Example:
\end{itemize}

\vspace{2mm}
{\footnotesize
\texttt{``forecasting is hard''}\\
$\Rightarrow$ \texttt{[``fore'', ``casting'', `` is'', `` hard'']}\\
\vspace{1mm}
$\Rightarrow$ \texttt{[1523,\;9182,\;318,\;6732]} \quad {\tiny \textcolor{gray}{(token IDs)}}
}

\vspace{4mm}
\textbf{\textcolor{red}{Why tokens matter:}}
\quad they define what the model can represent efficiently.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize
\vspace{-11mm}
\includegraphics[width=0.8\linewidth]{../../images/img16/transformer_embedding.jpeg}

\vspace{-2mm}
\textbf{\textcolor{violet}{Tokens $\rightarrow$ vectors}}

\vspace{0mm}
\begin{itemize}
  \item each token becomes a vector (\textbf{embedding})
  \item vectors capture similarity:
  {\tiny \newline (``rain'' closer to ``cloud'' than to ``banana'')}
  \item position is added:
  {\tiny \newline (word order matters)}
\end{itemize}

\vspace{0mm}
{\tiny \textcolor{gray}{
This is how text enters a neural network:
as numbers in a high-dimensional space.
}}
\end{column}

\end{columns}

\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16, Slide 10
% ================================================================================
\begin{frame}[t]
  \mytitle{Step 2: Attention --- How the Model Understands Context}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\footnotesize
\vspace{3mm}

\textbf{\textcolor{blue}{Attention is selective reading}}

\vspace{2mm}
\begin{itemize}
  \item for each word, the model decides:
  \textbf{what earlier words matter}
  \item it forms weighted links between tokens
  \item repeated many times in layers
\end{itemize}

\vspace{4mm}
\textbf{\textcolor{red}{Key point:}}
\quad Attention allows \y{long-range dependencies}
and structured reasoning.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize
\vspace{3mm}

\textbf{\textcolor{violet}{A simple intuition}}

\vspace{2mm}
\begin{itemize}
  \item Like humans:
  \textbf{scan} + \textbf{focus} + \textbf{connect}
  \item Not one focus, but many:
  {\tiny \newline (\textbf{multi-head attention})}
\end{itemize}

\vspace{3mm}
{\tiny \textcolor{gray}{
Transformer = many attention layers + feed-forward layers.
}}
\end{column}

\end{columns}

% ------------------------------------------------------------
% Attention diagram (TikZ)
% ------------------------------------------------------------
\vspace{2mm}

\vspace{-1.5cm}
\hspace*{5cm}\scalebox{0.85}{
\begin{tikzpicture}[>=latex, x=1cm, y=1cm]

\tikzstyle{tok}=[draw, rounded corners, minimum width=1.75cm, minimum height=0.55cm, align=center]
\tikzstyle{qtok}=[draw, rounded corners, minimum width=2.1cm, minimum height=0.60cm, align=center, very thick]

% --- top: current token (query) ---
\node[qtok] (q) at (0,1.8) {\textbf{token $i$}\\{\scriptsize ``rain''}};

% --- bottom: context tokens (keys/values) ---
\node[tok] (t1) at (-4.0,0) {\scriptsize The};
\node[tok] (t2) at (-2.0,0) {\scriptsize forecast};
\node[tok] (t3) at ( 0.0,0) {\scriptsize predicts};
\node[tok] (t4) at ( 2.0,0) {\scriptsize heavy};
\node[tok] (t5) at ( 4.0,0) {\scriptsize rain};

% --- arrows = attention weights ---
\draw[->, line width=0.4pt, opacity=0.35] (q.south) to[out=250,in=90] (t1.north);
\draw[->, line width=0.7pt, opacity=0.45] (q.south) to[out=255,in=90] (t2.north);
\draw[->, line width=0.9pt, opacity=0.55] (q.south) to[out=260,in=90] (t3.north);
\draw[->, line width=2.0pt, opacity=0.85] (q.south) to[out=270,in=90] (t4.north);
\draw[->, line width=2.4pt, opacity=0.90] (q.south) to[out=290,in=90] (t5.north);

% --- labels ---
\node[align=center] at (0,1.15) {\scriptsize \textcolor{gray}{attention weights}};
\node[align=center] at (0,-0.65) {\scriptsize \textcolor{gray}{earlier tokens = context memory}};

\end{tikzpicture}
}

\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16, Slide 11
% ================================================================================
\begin{frame}[t]
  \mytitle{Step 3: Training --- Next Token Prediction}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\footnotesize
\vspace{4mm}

\textbf{\textcolor{blue}{Training objective}}

\vspace{2mm}
\begin{itemize}
  \item show text to the model
  \item hide the next token
  \item train it to predict the hidden token
\end{itemize}

\vspace{3mm}
\textbf{\textcolor{red}{Result:}}
\quad the model learns grammar, style, facts, and reasoning patterns
\y{as an emergent capability}.

\vspace{3mm}
{\tiny
Important: training is expensive \\
(compute + data).  \\
Using a model is cheap (inference).
}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize
\vspace{4mm}

\textbf{\textcolor{violet}{Why it can fail}}

\vspace{2mm}
\begin{itemize}
  \item it predicts \textbf{plausible text}
  \item not guaranteed truth
  \item can \textbf{hallucinate} details
\end{itemize}

\vspace{3mm}
{\tiny \textcolor{gray}{
Therefore: verification + grounding are crucial in professional use.
}}
\end{column}

\end{columns}

% ------------------------------------------------------------
% Next token prediction visualization (TikZ)
% ------------------------------------------------------------
\vspace{-11mm}
\hspace*{4cm}
\scalebox{0.70}{
\begin{tikzpicture}[>=latex, x=1cm, y=1cm]

\tikzstyle{tok}=[draw, rounded corners, minimum width=1.9cm, minimum height=0.55cm, align=center]
\tikzstyle{tokfaint}=[draw, rounded corners, minimum width=1.9cm, minimum height=0.55cm, align=center, opacity=0.55]
\tikzstyle{tokspecial}=[draw, rounded corners, minimum width=2.2cm, minimum height=0.62cm, align=center, very thick]
\tikzstyle{arrow}=[->, thick]

% --- input tokens ---
\node[tok] (t1) at (-5.7,0) {\scriptsize tomorrow};
\node[tok] (t2) at (-3.8,0) {\scriptsize it will};
\node[tok] (t3) at (-1.9,0) {\scriptsize rain};
\node[tok] (t4) at ( 0.0,0) {\scriptsize over};
\node[tok] (t5) at ( 1.9,0) {\scriptsize Berlin};

% --- hidden next token ---
\node[tokspecial] (q) at (4.3,0) {\scriptsize next token\\\textbf{?}};

% --- model prediction ---
\node[tok] (pred) at (4.3,-1.35) {\scriptsize \textbf{``again''}};
\draw[arrow] (q.south) -- (pred.north);

% --- loss / training signal ---
\node[tokfaint] (true) at (6.7,-1.35) {\scriptsize true token\\\textbf{``again''}};
\draw[arrow, opacity=0.55] (pred.east) -- (true.west);

% --- captions ---
\node[align=center] at (-2.7,0.85) {\scriptsize \textcolor{gray}{context tokens (input)}};
\node[align=center] at (4.3,0.85) {\scriptsize \textcolor{gray}{hide next token}};
\node[align=center] at (5.5,-2.05) {\scriptsize \textcolor{gray}{training: compare prediction with truth}};

\end{tikzpicture}
}

\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16, Slide 12
% ================================================================================
\begin{frame}[t]
  \mytitle{Inference: Prompting Is Steering}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\footnotesize
\vspace{0mm}

\textbf{\textcolor{blue}{A prompt creates the context}}

\vspace{0mm}
\begin{itemize}
  \item system message: role + rules
  \item user message: task + data
  \item the model continues from there
\end{itemize}

\vspace{4mm}
\textbf{\textcolor{red}{Key point:}}
\quad The model is \y{not stable by itself}.  
It is shaped by the context we provide.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize
\vspace{0mm}

\textbf{\textcolor{violet}{What improves results}}

\vspace{2mm}
\begin{itemize}
  \item clear goal + constraints
  \item examples of desired style
  \item provide trusted information
  \item ask for uncertainties / checks
\end{itemize}

\vspace{3mm}
{\tiny \textcolor{gray}{
Good prompting is a communication skill:
precise intent, good context, clear quality criteria.
}}
\end{column}

\end{columns}

% ------------------------------------------------------------
% Visualization: prompting = steering (TikZ)
% ------------------------------------------------------------
\vspace{0mm}
\begin{center}
\scalebox{0.85}{
\begin{tikzpicture}[>=latex, x=1cm, y=1cm]

\tikzstyle{box}=[draw, rounded corners, minimum width=3.2cm, minimum height=0.8cm, align=center]
\tikzstyle{smallbox}=[draw, rounded corners, minimum width=3.2cm, minimum height=0.62cm, align=center]
\tikzstyle{arrow}=[->, thick]

% Left: system+user messages
\node[smallbox] (sys) at (-5.0,0.9) {\scriptsize \textbf{system message}\\{\tiny role + rules}};
\node[smallbox] (usr) at (-5.0,-0.1) {\scriptsize \textbf{user message}\\{\tiny task + data}};

% Middle: context / steering
\node[box] (ctx) at (-1.0,0.4) {\scriptsize \textbf{context}\\{\tiny steering signal}};

\draw[arrow] (sys.east) -- (ctx.west);
\draw[arrow] (usr.east) -- (ctx.west);

% Engine: model
\node[box] (llm) at (2.6,0.4) {\scriptsize \textbf{LLM}\\{\tiny generates next tokens}};

\draw[arrow] (ctx.east) -- (llm.west);

% Output
\node[smallbox] (out1) at (6.2,1.05) {\scriptsize \textbf{output text}\\{\tiny answer / plan}};
\node[smallbox] (out2) at (6.2,-0.25) {\scriptsize \textbf{output action}\\{\tiny tool call / code}};

\draw[arrow] (llm.east) -- (out1.west);
\draw[arrow] (llm.east) -- (out2.west);

% Small caption
\node[align=center] at (0.6,-1.05) {\scriptsize \textcolor{gray}{Prompting = setting context that steers the model's behavior and output.}};

\end{tikzpicture}
}
\end{center}

\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16, Slide 13
% ================================================================================
\begin{frame}[t]
  \mytitle{From Language to Interaction: LLMs + Tools}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.54\textwidth}
\footnotesize
\vspace{-1mm}

\textbf{\textcolor{blue}{LLMs become useful at work when connected}}

\vspace{-1mm}
\begin{itemize}\setlength{\itemsep}{1mm}

  \item \textbf{retrieval (RAG):} trusted documents
  {\tiny
  \begin{itemize}\setlength{\itemsep}{0mm}\setlength{\topsep}{0mm}\setlength{\parskip}{0mm}
    \item policies, manuals, guidance, internal knowledge bases
    \item reduces hallucinations by grounding on sources
  \end{itemize}
  }

  \item \textbf{tools:} APIs, code execution, search
  {\tiny
  \begin{itemize}\setlength{\itemsep}{0mm}\setlength{\topsep}{0mm}\setlength{\parskip}{0mm}
    \item from ``talking'' to \y{doing} (compute, query, automate)
    \item reproducible outputs: scripts, plots, tables
  \end{itemize}
  }

\end{itemize}

\vspace{-1mm}
\textbf{\textcolor{red}{Key message:}}
\quad Real systems are \y{LLM-based assistants}, not just chat.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\centering
\vspace{-2mm}

\begin{itemize}
  \item \color{red}\textbf{memory:} project and user context
  {\tiny
  \begin{itemize}\setlength{\itemsep}{0mm}\setlength{\topsep}{0mm}\setlength{\parskip}{0mm}
    \item remembers assumptions, preferences, ongoing tasks
    \item avoids repeating the same onboarding every time
  \end{itemize}
  }
\end{itemize}

\includegraphics[width=\linewidth]{../../images/img16/rag.png}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16 — Slide 14
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{From Chat to Action: Why Function Calling Matters}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\vspace{6mm}
\textbf{Chat is not the goal.}

\vspace{2mm}
\rtext{\bf LLMs become truly useful when they can trigger \y{real actions}:}

\vspace{1mm}
\begin{itemize}
  \item download and inspect forecast data
  \item compute diagnostics and key numbers
  \item generate plots and reports
  \item call services (archives, NWP, HPC tools)
\end{itemize}

\vspace{2mm}
\textbf{Function calling} turns language into \y{structured decisions} ---
executed by a controlled backend (not by the LLM).

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}
\vspace{-2mm}

% --- tool call snippet ----------------------------------------------------------
{\scriptsize\textbf{Example: tool call proposed by the LLM}}
\vspace{1mm}

\tiny
\begin{lstlisting}
{
  "tool_name": "get_weather_forecast",
  "arguments": {
    "model": "ICON-EU",
    "variable": "t2m",
    "location": "Berlin",
    "lead_time_h": 24
  }
}
\end{lstlisting}

\vspace{-8mm}
% --- dawid icon-eu image --------------------------------------------------------
\begin{center}
\includegraphics[height=2cm]{../../images/img16/weather_reading_crop.png}

\vspace{2mm}
{\scriptsize \textit{DAWID executes the tool call and returns the result.}}
\end{center}

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16 — Slide 15
% ================================================================================
\begin{frame}[t,fragile]
\mytitle{Tool Awareness: How the Model Knows What It Can Do}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize
\vspace{2mm}

\textbf{The key idea}

\vspace{2mm}
The LLM cannot ``invent'' actions.
It can only call tools that we \rtext{explicitly provide}.

\vspace{2mm}
\textbf{Why this matters}
\begin{itemize}
  \item clear capabilities: \y{what is possible}
  \item safety boundary: \y{what is not allowed}
  \item reproducible results: same tool $\Rightarrow$ same behavior
\end{itemize}

\vspace{2mm}
\rtext{\textbf{Think of it as a menu:}
the model chooses an item, the system cooks it.}

\vspace{0mm}
\begin{center}
{\scriptsize \textit{The tool list becomes the model’s action space.}}
\end{center}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\vspace{-2mm}

{\scriptsize\textbf{\y{Tool registry} (provided to the model)}}

\vspace{-3mm}
\tiny
\begin{lstlisting}
TOOLS = [
  {
    "name": "get_weather_forecast",
    "description": "Retrieve ICON-EU forecast values.",
    "inputs": {
      "location": "string",
      "variable": "t2m|wind|precip",
      "lead_time_h": "integer"
    }
  },
  {
    "name": "google_search",
    "description": "Search the web for up-to-date information and sources.",
    "inputs": { "query": "string" }
  }
]
\end{lstlisting}


\end{column}

\end{columns}
\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16 — Slide 16
% ================================================================================
\begin{frame}[t]

\vspace{-3mm}
\begin{center}
\includegraphics[width=0.76\linewidth]{../../images/img16/function_or_agent_crop.png}
\end{center}


\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16 — Slide 17
% ================================================================================
\begin{frame}[t,fragile]
\mytitle{Tools can be Functions \emph{or} Agents}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{Next step beyond tool calling}

\vspace{0mm}
With function calling, a ``tool'' does not need to be a single function.
It can also be an \y{agent} --- a specialist that performs multi-step actions.

\vspace{0mm}
\textbf{Example specialist agents}
\begin{itemize}
  \item \textbf{Search agent:} finds reliable sources
  \item \textbf{Data agent:} downloads + preprocesses datasets
  \item \textbf{Code agent:} runs scripts and produces figures
  \item \textbf{Report agent:} writes a structured summary
\end{itemize}

\vspace{0mm}
\textbf{Key idea:}
the LLM becomes a \y{coordinator} that delegates tasks
and combines results into one coherent answer.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}

\vspace{-7mm}
{\scriptsize\textbf{Example: delegate to a specialist agent}}
\vspace{1mm}

\begin{lstlisting}
{
  "tool_name": "search_agent",
  "arguments": {
    "task": "Find the latest DWD warnings for Berlin",
    "sources": "official",
    "return_format": "short_summary + links"
  }
}
\end{lstlisting}

\vspace{1mm}
Delivers as return:

\begin{lstlisting}
{
  "agent_result": {
    "summary": "...",
    "sources": ["...","..."]
  }
}
\end{lstlisting}

\vspace{-1mm}
\begin{center}
{\scriptsize \textit{A tool call can trigger a workflow --- not just one function.}}
\end{center}

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16 — Slide 18
% ================================================================================
\begin{frame}[t]
\mytitle{LLM Orchestration: Decisions \& Guardrails}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize
\vspace{2mm}

\textbf{LLM = Decision Engine}

\vspace{2mm}
For each user request, the model decides \y{what happens next}:

\vspace{1mm}
\begin{itemize}
  \item answer directly (when trivial)
  \item call a function tool (fast action)
  \item delegate to an agent (multi-step work)
  \item ask a clarifying question (missing info)
\end{itemize}

\vspace{2mm}
\textbf{Key idea:}
The model routes the task to the best capability.

\vspace{1mm}
{\scriptsize \textit{(Like a dispatcher: choose the right action at the right time.)}}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize
\vspace{2mm}

\textbf{Guardrails = System Control}

\vspace{2mm}
The system stays in charge of \y{execution}:

\vspace{1mm}
\begin{itemize}
  \item only approved tools exist (tool registry)
  \item arguments are validated (schemas)
  \item execution runs outside the LLM
  \item logging \& reproducibility by design
\end{itemize}

\vspace{2mm}
\textbf{Result:}
Reliable actions, not hallucinated actions.

\vspace{1mm}
{\scriptsize \textit{The LLM proposes --- the backend disposes.}}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16 — Slide 19
% ================================================================================
\begin{frame}[t]
\mytitle{The Race for Function \& Agent Standards}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.56\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{OpenAI — Tool Calling + JSON Schema}
\begin{itemize}
  \item tools defined via \y{JSON Schema}
  \item \y{Structured Outputs / strict schema} for reliable calls
\end{itemize}

\vspace{2mm}
\textbf{Anthropic — MCP (Model Context Protocol)}
\begin{itemize}
  \item open connector: \y{model $\leftrightarrow$ MCP server $\leftrightarrow$ tools/data}
  \item goal: universal plug-in interface for enterprise tools
\end{itemize}

\vspace{2mm}
\includegraphics[width=0.45\linewidth]{../../images/img16/race01.png}
\includegraphics[width=0.45\linewidth]{../../images/img16/race02.png}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{Google — Gemini Function Calling}
\begin{itemize}
  \item built-in function calling in the Gemini API ecosystem
  \item tight integration with the Google stack
\end{itemize}

\vspace{2mm}
\textbf{Linux Foundation / AAIF — Interoperability}
\begin{itemize}
  \item push for neutral/open \y{agent tool interfaces}
  \item avoid vendor lock-in and ``tool Babel''
\end{itemize}

\vspace{2mm}
\includegraphics[width=0.45\linewidth]{../../images/img16/race03.png}
\includegraphics[width=0.45\linewidth]{../../images/img16/race04.png}

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16 — Slide 20
% ================================================================================
\begin{frame}[t]
\mytitle{Our Opportunity: DAWID Puts Trusted Functions at Our Fingertips}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{What we can do immediately}

\vspace{2mm}
DAWID gives us a practical advantage:
we can expose \y{our own operational capabilities} as tools.

\vspace{2mm}
\begin{itemize}
  \item tools = \y{trusted} ECMWF / DWD / NHMS \y{functions} (not generic chat)
  \item each tool encodes a workflow step we already know
  \item the LLM becomes the \y{orchestrator} and UI
\end{itemize}

\vspace{0mm}
\textbf{Result:}
\begin{itemize}
  \item faster exploration and analysis
  \item reproducible results (same tools, same outputs)
  \item knowledge transfer: tools carry expertise
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.45\textwidth}

\vspace{-2mm}
\raggedleft
\includegraphics[width=5cm]{../../images/img16/fraim01}

\includegraphics[width=5.1cm]{../../images/img16/fraim02}

\vspace{1mm}
\centering
{\scriptsize \textit{DAWID: User Interface}}

\vspace{2mm}
\raggedleft
\rtext{\bf --- OUR functions!!}

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16, Slide 14
% ================================================================================
\begin{frame}[t]
  \mytitle{AI Forecasting: Learning to Predict the Next Weather State}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}
\footnotesize
\vspace{2mm}

\textbf{\textcolor{blue}{Key idea}}

\vspace{2mm}
\begin{itemize}
  \item The atmosphere has a \textbf{state} (a snapshot)
  \item \y{Forecasting means predicting a \textbf{future state}}
  \item A neural network learns a mapping:
\end{itemize}

\vspace{2mm}
\[
x(t) \;\;\Rightarrow\;\; x(t+48h)
\]

\vspace{1mm}
{\tiny
where $x$ contains fields like temperature, wind, pressure, humidity.
}

\vspace{3mm}
\textbf{\textcolor{red}{Training:}}
\quad learn from millions of examples
(reanalysis + observations).

\vspace{2mm}
{\tiny
After training, the model can produce forecasts extremely fast.
}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\centering
\vspace{1mm}
\includegraphics[width=0.7\linewidth]{../../images/img16/weather_t1_t48_rain_gsp_1honly_europe_crop.png}

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16, Slide 15
% ================================================================================
\begin{frame}[t]
  \mytitle{Neural Network Forecasting: One Step $\rightarrow$ Many Steps}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize
\vspace{1mm}

\textbf{\textcolor{blue}{How an AI forecast is produced}}

\vspace{2mm}
\begin{itemize}
  \item The model learns: \y{state now} $\rightarrow$ \y{state later}
  \item Longer lead times come from \textbf{repeating the prediction step}
\end{itemize}

\vspace{-2mm}
\[
x(t) \rightarrow x(t+\Delta t) \rightarrow x(t+2\Delta t) \rightarrow \dots
\]

\vspace{3mm}
\textbf{\textcolor{red}{Physics detail: accumulated variables}}

\vspace{1mm}
\begin{itemize}
  \item precipitation is often stored as an \textbf{accumulated sum}
  \item to get \textbf{1-hour rain} at lead $L$:
\end{itemize}

\vspace{-3mm}
\[
RAIN(L) - RAIN(L-1)
\]

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\centering
\vspace{1mm}

\includegraphics[width=\linewidth]{../../images/img16/rain_gsp_1h_2x4_panels_crop.png}

\vspace{1mm}
\textcolor{gray}{
Example: ICON-EU 1-hour precipitation for multiple lead times.
}

\vspace{3mm}
\rtext{\bf Here: Nowcasting or NWP - depending on input, time scales and variables!}
\end{column}

\end{columns}

\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16, Slide 16
% ================================================================================
\begin{frame}[t]
  \mytitle{Nowcasting and NWP: One Continuum (Observations $\rightarrow$ DA $\rightarrow$ Forecast)}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize
\vspace{2mm}

\textbf{\textcolor{blue}{NWP with Data Assimilation (DA) is the full framework}}

\vspace{0mm}
\begin{itemize}
  \item \textbf{observations} enter continuously:
    {\tiny \newline radar, satellite, aircraft, surface stations, etc.}
  \item \textbf{DA} combines obs + model:
    {\tiny \newline best estimate of the 3D atmosphere at ``now''}
  \item then \textbf{forecast propagation} produces future weather
\end{itemize}

\vspace{0mm}
\textbf{\textcolor{violet}{Nowcasting is the short-range regime}}

\vspace{1mm}
\begin{itemize}
  \item lead times: \textbf{minutes to a few hours}
  \item very high weight of recent observations
  \item focus on rapidly evolving phenomena:
    {\tiny \newline convective storms, precipitation cells}
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\centering
\vspace{2mm}

\includegraphics[width=\textwidth]{../../images/img16/nwc-to-fcst_crop.png}

\vspace{3mm}
{\tiny \textcolor{gray}{
AI can support different parts: observations, DA, model emulation, and products.
}}

\hspace*{-8mm}\y{There is no strict boundary: it is one continuum.}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16, Slide 17
% ================================================================================
\begin{frame}[t]
  \mytitle{Forecasting in One Sentence}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}
\footnotesize
\vspace{3mm}

\textbf{\textcolor{blue}{Weather forecasting = state estimation + prediction}}

\vspace{2mm}
\begin{itemize}
  \item We estimate the \textbf{current atmospheric state}
  \item Then we predict how it changes in time
\end{itemize}

\vspace{-2mm}
\[
\underbrace{x(t_0)}_{\text{best estimate now}}
\quad \rightarrow \quad
\underbrace{x(t_0+\Delta t)}_{\text{future state}}
\]

\vspace{3mm}
\textbf{\textcolor{red}{Why it is hard}}

\vspace{1mm}
\begin{itemize}
  \item the atmosphere is \textbf{chaotic}
  \item small errors grow with time
  \item observations are incomplete and noisy
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}

\vspace{-5mm}
\textbf{\textcolor{violet}{So we quantify uncertainty}}
\begin{itemize}
  \item ensembles: many forecasts instead of one
\end{itemize}

\centering
\vspace{2mm}

% image placeholder (you can replace)
\includegraphics[width=\linewidth]{../../images/img16/nwp_continuum_crop.png}

\vspace{1mm}
{\tiny \textcolor{gray}{Forecasting: observation $\rightarrow$ analysis $\rightarrow$ prediction}}
\end{column}

\end{columns}

\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16, Slide 18
% ================================================================================
\begin{frame}[t]
\centering
\vspace{-2mm}

\includegraphics[width=0.8\linewidth]{../../images/img16/nwp_neural.png}

\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16, Slide 19
% ================================================================================
\begin{frame}[t]
  \mytitle{How a Neural Network Learns Forecasting: Front Template + Motion}

\centering
\vspace{-2mm}

\includegraphics[width=0.6\linewidth]{../../images/img16/nn_front_visual_argument_4panel.png}

\vspace{1mm}
{\footnotesize \textcolor{gray}{
Visual argument: the NN learns \textbf{templates} (front patterns) and how they
\textbf{move / evolve} over time.
}}

\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16, Slide 20
% ================================================================================
\begin{frame}[t]
  \mytitle{One Step, Many Steps: Templates + Transport + Accumulations}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize
\vspace{0mm}

\textbf{\textcolor{blue}{Neural forecasting learns reusable building blocks}}

\vspace{1mm}
\begin{itemize}
  \item learn \textbf{templates} for structures:
    {\tiny \newline fronts, rain bands, vortices, jets}
  \item learn \textbf{how they move and change} from context
    {\tiny \newline (e.g. wind, humidity, stability)}
\end{itemize}

\vspace{0mm}
\textbf{\textcolor{blue}{Then: one step $\rightarrow$ many steps}}

\vspace{-2mm}
\[
x(t) \rightarrow x(t+\Delta t) \rightarrow x(t+2\Delta t) \rightarrow \dots
\]

\vspace{0mm}
\textbf{\textcolor{red}{Important for users: accumulated products}}

\vspace{1mm}
\begin{itemize}
  \item many outputs are stored as \textbf{accumulations}
  \item 1-hour precipitation at lead $L$ is:
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{1mm}
\[
RAIN(L) - RAIN(L-1)
\]

\vspace{0mm}
\textbf{\textcolor{violet}{Take-away:}}
\quad \y{Forecasting = detect patterns +} \\
\hfill \y{transport them forward in time.}


\centering
\vspace{4mm}

\includegraphics[width=\linewidth]{../../images/img16/nn_front_template_motion.png}

\vspace{1mm}
{\tiny \textcolor{gray}{
Templates $\rightarrow$ heatmaps $\rightarrow$ shifted patterns $\rightarrow$ next map
(repeated for longer lead times).
}}
\end{column}

\end{columns}

\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16 — Slide 28
% ================================================================================
\begin{frame}[t]
\mytitle{A Minimal Forecasting World: A Blob Moving on a Circle}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize

\vspace{4mm}
We create a simple 1D world on $[0,10]$:

\vspace{1mm}
\begin{itemize}
  \item a \y{function} $f(t,x)$ (a ``blob'')
  \item periodic domain: $x=0$ connects to $x=10$
  \item dynamics: \y{pure translation}
  \[
  f(t+\Delta,x) = f(t,x-\delta)
  \]
\end{itemize}

\vspace{2mm}
\textbf{Forecasting task:}
given $f(t,\cdot)$, predict $f(t+\Delta,\cdot)$.

\vspace{2mm}
This captures the essence of advection:
\y{structures move}.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-6mm}
\begin{center}
\includegraphics[width=\linewidth]{../../images/img16/cnn_translation_input_output.png}

\vspace{1mm}
{\scriptsize \textit{Input $f(t)$ and target/forecast $f(t+\Delta)$.}}

\vspace{-8mm}
\includegraphics[width=5cm]{../../images/img16/signal_on_circle_3d_crop.png}

\end{center}
\end{column}

\end{columns}
\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16 — Slide 29
% ================================================================================
\begin{frame}[t]
\mytitle{What the Neural Network Sees}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{Important: the input is the \y{full signal}, not single points.}

\vspace{1mm}
The network gets all grid values of $f(t,x)$ at once:
\[
f(t,\cdot)\in\mathbb{R}^{N}\qquad (N=256)
\]

\vspace{2mm}
\textbf{But the computation is local:}
each output point is computed from a \y{neighborhood}.

\vspace{6mm}
\textbf{Kernel size $k$ = width of the filter}

\vspace{1mm}
With $k=7$, the network looks at:
\[
[x_{i-3},\dots,x_i,\dots,x_{i+3}]
\]

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}

\vspace{-6mm}
\textbf{Stacking layers increases context}

\vspace{1mm}
After 3 conv layers (all $k=7$), each output point depends on roughly:
\[
1 + 3\cdot(k-1) = 19\ \text{grid points}
\]

\hspace*{-1cm}\includegraphics[height=4cm]{../../images/img16/cnn_layers_influence.png}

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16 — Slide 30
% ================================================================================
\begin{frame}[t]
\mytitle{Inside the CNN: Many Feature Variables}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}
\footnotesize
\vspace{-2mm}

The CNN transforms the input into many internal variables:

\vspace{2mm}
\begin{center}
{\Large $1 \rightarrow 32 \rightarrow 32 \rightarrow 32 \rightarrow 1$}
\end{center}

\vspace{2mm}
\begin{itemize}
  \item input: one function $f(t,x)$
  \item hidden layers: 32 feature channels each
  \item output: predicted function $\hat f(t+\Delta,x)$
\end{itemize}

\vspace{2mm}
\textbf{Interpretation:}
each channel is a learned detector for local shapes
(edges, slopes, curvature, \dots).

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\vspace{-8mm}
\begin{center}
\includegraphics[width=\linewidth]{../../images/img16/cnn_translation_features_h1.png}

\vspace{1mm}
{\scriptsize \textit{Example: 6 of 32 feature channels in layer $h1$.}}
\end{center}

\hspace{-12mm}
\begin{minipage}{7.5cm}
\footnotesize
The variables $h_1,h_2,h_3$ are \y{hidden feature maps} inside the CNN.
They form a \y{latent feature space}: not observed, not physical, but learned.
Each layer contains many channels (e.g.\ 32), extracting different local aspects of the signal.
The forecast emerges by transforming $f(t,\cdot)\rightarrow h_1\rightarrow h_2\rightarrow h_3\rightarrow \hat f(t+\Delta,\cdot)$.
\end{minipage}

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16 — Slide 31
% ================================================================================
\begin{frame}[t]
\mytitle{Why This Is \emph{Not} Explicit Pattern Matching}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.56\textwidth}
\footnotesize
\vspace{-2mm}

A common misconception is:
\begin{center}
\textit{``The network finds the blob pattern and just copies it forward.''}
\end{center}

\vspace{2mm}
\textbf{What actually happens:}
\begin{itemize}
  \item the CNN computes many internal feature variables (32 channels)
  \item each channel responds to \y{different local aspects}
  \item the forecast is produced by recombining these features
\end{itemize}

\vspace{2mm}
\rtext{\textbf{Key point:}
the NN does not store templates --- it learns a \y{continuous mapping}
from input to forecast.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}

\vspace{-8mm}
\begin{center}
\includegraphics[width=\linewidth]{../../images/img16/cnn_translation_features_h2.png}
\includegraphics[width=\linewidth]{../../images/img16/cnn_translation_features_h3.png}

\vspace{1mm}
{\scriptsize \textit{Example: 6 of 32 feature channels in layer $h3$.}}
\end{center}
\end{column}

\end{columns}
\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16 — Slide XX
% ================================================================================
\begin{frame}[t]
\mytitle{What We Can Do Already}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\vspace{-2mm}

\begin{center}
\includegraphics[width=\linewidth]{../../images/img16/earth_forecast2.png}
\end{center}

\textbf{We already have strong building blocks in place:}

\vspace{2mm}
\begin{itemize}
  \item We have created a \y{framework} \y{for AI-based} \y{weather forecasting}
  with \rtext{Anemoi}
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.56\textwidth}
\footnotesize
\vspace{-10mm}

\begin{itemize}
  \item We have developed libraries (\rtext{mfai, FRAIM}) for:
  \begin{itemize}
    \item \y{downscaling} and high-resolution products 
    \item \y{road weather} services
    \item high-impact weather \y{feature extraction}
    \item weather \y{interpretation} and \y{explainability}
    \item \y{nowcasting} of observation fields (radiation, precipitation, \dots)
  \end{itemize}
  
  \vspace{3mm}\color{darkgreen}
  \item We have gained expertise across the full \y{AI/ML value chain}
        in weather services and international organizations.
  \item \color{red} We have created \y{networking and structures} for joint development
        and sustainable research --- connected to leading global AI/ML developments.
\end{itemize}

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16 — Slide XX
% ================================================================================
\begin{frame}[t]
\mytitle{What We Can Do Already (Operational AI Forecasting)}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.58\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{AI forecasting is already operational.}

\vspace{0mm}
In Europe, several AI-based forecasting systems are now in \y{production use} 
(e.g. AIFS, AICON, BRIS).
They complement classical NWP by providing:
\begin{itemize}
  \item fast state-to-state forecasts (minutes instead of hours)
  \item competitive large-scale skill for key variables
  \item robust baselines and rapid experimentation
\end{itemize}

\vspace{0mm}
\textbf{Key message:}
AI is no longer ``research only'' --- it is \y{part of the operational toolbox}.

\vspace{2mm}
This opens a clear opportunity:
\begin{itemize}
  \item combine NWP + AI hybrids
  \item integrate new observation-driven products 
  \item accelerate development cycles via ML pipelines
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.42\textwidth}
\vspace{-3mm}

\begin{center}
\includegraphics[width=0.7\linewidth]{../../images/img16/already1.png}

\vspace{2mm}
\includegraphics[width=0.5\linewidth]{../../images/img16/already2.png}

\vspace{2mm}
\includegraphics[width=0.7\linewidth]{../../images/img16/already3.png}
\end{center}

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16 — Slide XX
% ================================================================================
\begin{frame}[t]
\mytitle{Library Ecosystem: Complementary Capabilities}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{We are building a strong ecosystem of AI libraries}

\vspace{0mm}
Different libraries contribute complementary capabilities:
\begin{itemize}
  \item \textbf{Anemoi:} end-to-end AI weather models 
  \item \textbf{mfai:} vision transformers and many applications
  \item \textbf{MLCast:} nowcasting library, observation based
  \item \textbf{FRAIM:} products and services, full value chain
\end{itemize}

\vspace{0mm}
\textbf{Positive outlook}
\begin{itemize}
  \item no single library needs to do everything
  \item modular building blocks enable rapid innovation
  \item shared standards $\Rightarrow$ interoperability and reuse
\end{itemize}

\vspace{0mm}
\rtext{\textbf{Key message:}
Together, these components form a \y{platform for scalable AI in weather services}.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\vspace{-2mm}
\begin{center}
\includegraphics[width=\linewidth]{../../images/img16/library_ecosystem2.png}

\vspace{1mm}
{\scriptsize \textit{Ecosystem view: different strengths, one common mission.}}
\end{center}
\end{column}

\end{columns}
\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16 — Slide 35
% ================================================================================
\begin{frame}[t]
\mytitle{Why Physics Matters: Future AI Forecast Systems Will Be \rtext{Physics + AI}}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{Weather is not just a pattern problem}

\vspace{0mm}
Forecasting is about \y{consistent evolution} of a \y{physical state}:
\begin{itemize}
  \item conservation laws (mass, energy, water)
  \item balances and constraints (geostrophy, stability)
  \item multiscale interactions (local storms $\leftrightarrow$ global flow)
\end{itemize}

\vspace{0mm}
\textbf{Why ``pure AI'' can fail}
\begin{itemize}
  \item excellent short-term skill can still drift long-term
  \item small violations accumulate (mass / moisture / energy)
  \item rare extremes need physics consistency, not just averages
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\vspace{-4mm}
\begin{center}
\includegraphics[width=\linewidth]{../../images/img16/earth_forecast2.png}

\vspace{0mm}
{\scriptsize \rtext{\textbf{AI gives speed and learning. \\
Physics gives truth and trust.}}}
\end{center}

\vspace{-2mm}\color{darkgreen}
\begin{itemize}
  \item AI learns \y{corrections / closures}
  \item constraints and invariants built \y{into the model}
  \item physics-based evaluation \& reliability
\end{itemize}

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16 — Slide 36
% ================================================================================
\begin{frame}[t]
\mytitle{What You Can Do (A): Use LLMs as a Tool --- You Stay the Master}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.56\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{Use AI for: understanding, exploring, developing}

\vspace{1mm}
Think of LLMs as a \y{power tool} for knowledge work:
\begin{itemize}
  \item explain unfamiliar concepts in your context
  \item explore alternatives and trade-offs quickly
  \item generate drafts, code sketches, slide structure
  \item summarize documents, meetings, research threads
\end{itemize}

\vspace{2mm}
\textbf{The right mindset}
\begin{itemize}
  \item \y{you are the pilot}, the AI is the assistant
  \item ask for options, then decide yourself
  \item validate important facts (sources, experiments)
\end{itemize}

\vspace{2mm}
\rtext{\textbf{Key message:}}
AI needs guidance --- quality comes from \y{your questions and your checks}.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}

\vspace{-6mm}
\begin{center}
\includegraphics[width=\linewidth]{../../images/img16/ai_books.png}

\vspace{-3mm}
{\scriptsize \rtext{\textbf{Human judgment stays in control.}}}
\end{center}
\end{column}

\end{columns}
\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16 — Slide 37
% ================================================================================
\begin{frame}[t]
\mytitle{What LLMs Do Today --- and What ``World Models'' Add Next}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.54\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{LLMs today (what they actually do)}
\begin{itemize}
  \item generate text/code by \y{next-token prediction}
  \item strong at language tasks: explain, summarize, draft, transform
  \item can \y{appear} to reason, but truth not guaranteed
  \item without grounding: can be \rtext{confidently wrong}
\end{itemize}

\vspace{2mm}
\tiny
\textbf{World-model approaches (the next step)}
\begin{itemize}
  \item learn explicit \y{state} representations of a system (world state)
  \item learn \y{dynamics}: state$(t)$ + action $\rightarrow$ state$(t{+}1)$
  \item enable planning, long-horizon consistency, and controllable actions
  \item usually needs \y{grounding} (data, sensors, simulators, tools)
\end{itemize}

\vspace{0mm}
\footnotesize
\rtext{\textbf{Message:}}
LLMs are powerful interfaces --- world models aim at \y{reliable dynamics}.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{LLMs for knowledge work}

\tiny
\vspace{0mm}\color{red}
\textbf{Be careful:}
\begin{itemize}\color{darkgreen}
  \item verify facts, numbers, and operational details
  \item demand sources or reproduce with scripts
  \item watch for missing assumptions and edge cases
\end{itemize}

\footnotesize
\vspace{0mm}
\textbf{Take full advantage:}
\begin{itemize}
  \item accelerate understanding and documentation
  \item structure tasks into steps, checklists, and options
  \item generate first drafts and improve clarity
  \item connect to tools/agents for \y{grounded actions}
\end{itemize}

\vspace{-1mm}
\rtext{\textbf{Fast thinking + human validation \\
= real productivity.}}

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16 — Slide 38
% ================================================================================
\begin{frame}[t]
\mytitle{What You Can Do (B): Rebuild Services with Tools, Agents, and Clear APIs}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.58\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{Use the AI revolution to modernize services}

\vspace{0mm}
LLMs work best when they can call \y{clear interfaces}.
This is an opportunity to rebuild our services in a clean way:

\vspace{0mm}
\begin{itemize}
  \item define small, robust \y{functions} (tools)
  \item combine them into \y{agent workflows}
  \item expose everything as \y{API-based services}
\end{itemize}

\vspace{0mm}
\textbf{Why this is powerful}
\begin{itemize}
  \item clarity: inputs/outputs become explicit
  \item reuse: one tool serves many applications
  \item automation: agents connect tools: end-to-end
  \item acceleration: faster prototyping and delivery
\end{itemize}

\vspace{0mm}
\rtext{\textbf{Key message:}}
LLMs need good tool definitions --- \y{we can use this to create better services for ourselves.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.42\textwidth}
\vspace{-2mm}
\begin{center}
\includegraphics[width=\linewidth]{../../images/img16/function_or_agent_crop.png}

\vspace{1mm}
{\scriptsize \textit{Tool calling turns services into reusable building blocks.}}
\end{center}
\end{column}

\end{columns}
\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16 — Slide 39
% ================================================================================
\begin{frame}[t]
\mytitle{Slide 39: Rebuild Services --- Analyze Work, Find Waste, Build Tools}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{Step 1: Look at our daily workflow}
\begin{itemize}
  \item Where do we \rtext{repeat} the same steps?
  \item Where do we \rtext{copy/paste} between systems?
  \item Where do we \rtext{wait} for data, plots, approvals?
  \item Where do we \rtext{lose context} (emails, chats, files)?
\end{itemize}

\vspace{2mm}
\textbf{Step 2: Turn waste into tools}
\begin{itemize}
  \item define a clear \y{input/output interface}
  \item make it callable (API / function / agent tool)
  \item reuse it everywhere: DAWID, scripts, services, pipelines
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\vspace{-2mm}

\begin{center}
\scalebox{0.6}{
\begin{tikzpicture}[x=1cm,y=1cm,>=latex]

\tikzstyle{box}=[draw,rounded corners,align=center,minimum width=3.7cm,minimum height=0.85cm]
\tikzstyle{waste}=[draw,rounded corners,align=center,minimum width=3.7cm,minimum height=0.75cm]
\tikzstyle{tool}=[draw,rounded corners,align=center,minimum width=3.7cm,minimum height=0.75cm]
\tikzstyle{arrow}=[->,thick]

% ------------------------------------------------------------
% main chain (more vertical spacing)
% ------------------------------------------------------------
\node[box] (q) at (0,4.2) {\textbf{Question / Task}\\{\scriptsize ``What is happening?''}};
\node[box] (d) at (0,2.8) {\textbf{Data + Context}\\{\scriptsize model + obs + metadata}};
\node[box] (a) at (0,1.4) {\textbf{Analysis}\\{\scriptsize plots, stats, checks}};
\node[box] (p) at (0,0.0) {\textbf{Product / Decision}\\{\scriptsize briefing, warning, API}};

\draw[arrow] (q) -- (d);
\draw[arrow] (d) -- (a);
\draw[arrow] (a) -- (p);

% ------------------------------------------------------------
% waste tags on the right (aligned to chain)
% ------------------------------------------------------------
\node[waste] (w1) at (4.3,3.05) {\rtext{\textbf{Waste}}\\{\scriptsize manual steps}};
\node[waste] (w2) at (4.3,1.65) {\rtext{\textbf{Waste}}\\{\scriptsize re-creating plots}};
\node[waste] (w3) at (4.3,0.25) {\rtext{\textbf{Waste}}\\{\scriptsize format conversions}};

\draw[arrow] (w1.west) -- (d.east);
\draw[arrow] (w2.west) -- (a.east);
\draw[arrow] (w3.west) -- (p.east);

% ------------------------------------------------------------
% tools on the left (aligned to chain)
% ------------------------------------------------------------
\node[tool] (t1) at (-4.3,3.05) {\y{\textbf{Tool}}\\{\scriptsize get\_forecast(...)}};
\node[tool] (t2) at (-4.3,1.65) {\y{\textbf{Tool}}\\{\scriptsize impact\_summary(...)}};
\node[tool] (t3) at (-4.3,0.25) {\y{\textbf{Tool}}\\{\scriptsize standard\_plots(...)}};

\draw[arrow] (t1.east) -- (d.west);
\draw[arrow] (t2.east) -- (a.west);
\draw[arrow] (t3.east) -- (p.west);

% ------------------------------------------------------------
% small caption
% ------------------------------------------------------------
\node[align=center] at (0,-0.9) {\footnotesize \textit{Replace repeated manual work by reusable tools with clear interfaces.}};

\end{tikzpicture}
}
\end{center}

\end{column}

\end{columns}

\vspace{2mm}
\rtext{\textbf{Key message:}}
If a task repeats, it should become a \y{tool}.

\end{frame}
%!TEX root = lec16.tex
% ================================================================================
% Lecture 16 — Slide XX
% ================================================================================
\begin{frame}[t]
\mytitle{What You Can Do (C): Bring Your Domain Expertise --- Make AI Your Own}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.54\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{AI becomes powerful when it is grounded in meteorology}

\vspace{0mm}
LLMs and neural networks do not automatically understand:
\begin{itemize}
  \item processes, states, and transitions
  \item limits and plausibility
  \item physical constraints and balances
  \item weather regimes and rare extremes
\end{itemize}

\vspace{2mm}\color{blue}
\textbf{Your expertise is the missing ingredient}
\begin{itemize}\color{blue}
  \item define what matters: variables, events, diagnostics
  \item define what is allowed: limits, physics, consistency
  \item define what is useful: products, warnings, explanations
\end{itemize}


\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.42\textwidth}

\vspace{0mm}
\rtext{\textbf{Key message:}}
Do not outsource AI --- \y{embed your knowledge} 
into tools, workflows, and constraints.

\vspace{2mm}
\begin{center}
\includegraphics[width=\linewidth]{../../images/img16/physics_and_ai.png}

\vspace{-1mm}
{\scriptsize \rtext{\textbf{Domain expertise turns AI into trust.}}}
\end{center}
\end{column}

\end{columns}
\end{frame}
% ================================================================================
% E-AI Tutorial Slides
% Filename: lec16.tex
%
% Roland Potthast 2025/2026
% Licence: CC-BY4.0
% ================================================================================
\documentclass[aspectratio=169]{beamer}

% --- Load lecture macros --------------------------------------------------------
\input{../lec_macros.tex}
\newcommand{\LectureNumber}{Lecture 16}

% --- Document -------------------------------------------------------------------
\begin{document}

\setagendaboxforlecture{16}

\input{../lec_agenda.tex}
\input{lec16_01.tex}
\input{lec16_02.tex}
\input{lec16_03.tex}
\input{lec16_04.tex}
\input{lec16_05.tex}
\input{lec16_06.tex}
\input{lec16_07.tex}
\input{lec16_08.tex}
\input{lec16_09.tex}
\input{lec16_10.tex}
\input{lec16_11.tex}
\input{lec16_12.tex}
\input{lec16_13.tex}
\input{lec16_14.tex}
\input{lec16_15.tex}
\input{lec16_16.tex}
\input{lec16_17.tex}
\input{lec16_18.tex}
\input{lec16_19.tex}
\input{lec16_20.tex}
\input{lec16_21.tex}
\input{lec16_22.tex}
\input{lec16_23.tex}
\input{lec16_24.tex}
\input{lec16_25.tex}
\input{lec16_26.tex}
\input{lec16_27.tex}
\input{lec16_28.tex}
\input{lec16_29.tex}
\input{lec16_30.tex}
\input{lec16_31.tex}
\input{lec16_32.tex}
\input{lec16_33.tex}
\input{lec16_34.tex}
\input{lec16_35.tex}
\input{lec16_36.tex}
\input{lec16_37.tex}
\input{lec16_38.tex}
\input{lec16_39.tex}
\input{lec16_40.tex}


% --- End Document ---------------------------------------------------------------
\end{document}
%!TEX root = lec17.tex
% ================================================================================
% Lecture 17 — Slide 01
% ================================================================================
\begin{frame}[t]

\mytitle{Why Emulators in Numerical Weather Prediction?}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}

\vspace{-2mm}
\includegraphics[width=6cm]{../../images/img17/nwp.png}

\footnotesize
\begin{itemize}
  \item High-resolution NWP is \\ \y{computationally expensive}
  \item Many applications do not require \\ full physical fidelity
  \item Fast forecasts enable \y{new applications} \\ and scale
\end{itemize}
\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\vspace{-2mm}
\textbf{Emulator concept}

\begin{itemize}
  \item Learns the forecast step: state $\rightarrow$ state
  \item Operates within an existing NWP ecosystem
  \item Preserves grids, variables, and semantics
\end{itemize}

\vspace{2mm}
\textbf{Goal of this lecture}

\begin{itemize}
  \item Understand emulator-based AI systems
  \item Compare AIFS and AICON
  \item Walk through AICON step by step
\end{itemize}

\vspace{2mm}
\footnotesize
\rtext{\bf Emulators complement numerical models — they do not replace physical understanding.}

\end{column}

\end{columns}



\end{frame}
%!TEX root = lec17.tex
% ================================================================================
% Lecture 17 — Slide 02
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Big-Tech AI Weather Models: Architectural Landscape}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\textbf{GraphCast (Google DeepMind)}

\begin{itemize}
  \item \y{Graph Neural Network (GNN)}
  \item Icosahedral grid, $\sim$0.25$^\circ$
  \item Multi-mesh message passing
  \item Deterministic medium-range forecasts
\end{itemize}

\vspace{4mm}
\textbf{GenCast (Google DeepMind)}

\begin{itemize}
  \item \y{Diffusion model on graphs}
  \item Icosahedral grid, $\sim$1$^\circ$–0.25$^\circ$
  \item Probabilistic forecasting
  \item Explicit uncertainty representation
\end{itemize}



\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\textbf{Pangu-Weather (Huawei)}

\begin{itemize}
  \item \y{3D Transformer architecture}
  \item Regular lat--lon grid, $\sim$0.25$^\circ$
  \item Attention over space and vertical levels
  \item Image-like representation of atmosphere
\end{itemize}

\vspace{4mm}
\textbf{FourCastNet (NVIDIA)}

\begin{itemize}
  \item \y{Fourier Neural Operator (FNO)}
  \item Regular lat--lon grid, $\sim$0.25$^\circ$
  \item Spectral convolution in Fourier space
  \item Extremely fast inference
\end{itemize}

\end{column}

\end{columns}

\vspace{2mm}
\footnotesize
\rtext{\bf All models replace the forecast step — none are embedded in classical NWP systems.}

\end{frame}
%!TEX root = lec17.tex
% ================================================================================
% Lecture 17 — Slide 03
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Research and Operational AI Weather Systems}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\textbf{Aurora (Microsoft)}

\begin{itemize}
  \item \y{Transformer-based foundation model}
  \item Regular lat--lon grids
  \item Multi-task Earth-system scope
  \item Research-driven, not NWP-native
\end{itemize}

\textbf{AIFS (ECMWF)}

\begin{itemize}
  \item Graph Neural Network (Anemoi)
  \item \y{ECMWF Flagship ML Model}
  \item Trained on ECMWF reanalysis ERA
  \item Operational global forecast system
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\textbf{BRIS (Met Norway)}

\begin{itemize}
  \item Anemoi-based national system
  \item \y{Nested Grid Approach, high resolution}
  \item Independent training, AIFS-aligned
  \item Operational national usage
\end{itemize}

\textbf{AICON (DWD)}

\begin{itemize}
  \item Graph Neural Network (Anemoi)
  \item Native ICON triangular grid
  \item Trained on \y{ICON-DREAM reanalysis}
  \item Operational ICON emulator
\end{itemize}

\end{column}

\end{columns}

\vspace{4mm}
\footnotesize
\rtext{\bf European Meteorological Infrastructure is carrying out exciting development.}

\end{frame}
%!TEX root = lec17.tex
% ================================================================================
% Lecture 17 — Slide 04
% ================================================================================
\begin{frame}[t]

\mytitle{Anemoi based Emulators: Fields and Grids}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\centering
\footnotesize

\vspace{-4mm}
\includegraphics[width=\textwidth]{../../images/img17/AICON.png}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\centering
\footnotesize
\textbf{Icosahedral Grid Representation}

\vspace{2mm}
\includegraphics[width=\textwidth]{../../images/img17/aicon_grid1.png}

\vspace{1mm}
Triangular ICON mesh used as the computational graph
for message passing and inference.

\end{column}

\end{columns}

\footnotesize
\rtext{\bf AICON learns a mapping on the ICON mesh, not on a Cartesian grid.}

\end{frame}
%!TEX root = lec17.tex
% ================================================================================
% Lecture 17 — Slide 05
% ================================================================================
\begin{frame}[t]
\mytitle{ICON-DREAM Reanalysis: High-quality training basis for AI emulators}

\begin{columns}[T,totalwidth=\textwidth]
% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\vspace{-1mm}
\footnotesize

\textbf{Motivation}
\begin{itemize}
\item reanalyses are key for \y{climate services} and many applications
\item now also essential as \y{training basis} for AI-based NWP emulators
\end{itemize}

\vspace{0mm}
\textbf{ICON reanalysis framework at DWD}
\begin{itemize}
\item \textbf{ICON-DREAM:} global-to-regional \y{ensemble reanalysis}
\item \textbf{ICON-FORCE:} 2.1\,km ensemble reanalysis for Central Europe
\item focus on \y{Europe} and on \y{continuous updates} (2010--present)
\end{itemize}

\vspace{0mm}
ICON-DREAM delivers \y{consistent, high-resolution} data
\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\vspace{-1mm}
\footnotesize

\textbf{ICON-DREAM: key characteristics}
\begin{itemize}
\item global ICON at \textbf{13\,km}, 120 levels
\item two-way nest over Europe at \textbf{6.5\,km}
\item DA: \y{LETKF} with \textbf{20-member ensemble} for $B$-covariances
\item ensemble at 40\,km (20\,km over Europe)
\end{itemize}

\vspace{2mm}
\textbf{ICON-FORCE (2\,km):}
\begin{itemize}
\item hourly LETKF (KENDA), incl.\ radar + SEVIRI
\item 2-moment microphysics, snow / SST analyses
\end{itemize}

\vspace{1mm}
\textbf{Outlook:}
backward extension to the 1980s using rescued obs + CDR products.
\end{column}
\end{columns}

\end{frame}



%!TEX root = lec17.tex
% ================================================================================
% Lecture 17 — Slide 05
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{AICON Walkthrough: Environment Setup}

\vspace{-1mm}
\centering
{\color{blue}\bf Thanks to {\sl Florian Prill} for a great Notebook!}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\textbf{Core ML stack}

\begin{itemize}
  \item Python $\ge$ 3.10
  \item PyTorch (CPU or CUDA)
  \item PyTorch Lightning
  \item PyTorch Geometric (PyG)
\end{itemize}

\textbf{Anemoi framework}

\begin{itemize}
  \item \texttt{anemoi-core} (graphs, models, training)
  \item \texttt{anemoi-datasets} (Zarr + YAML I/O)
  \item \texttt{anemoi-inference} (generic inference)
  \item Supporting packages (e.g. transforms)
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\textbf{Data and configuration}

\begin{itemize}
  \item Zarr (chunked training data)
  \item Xarray (inspection and analysis)
  \item eccodes + earthkit (GRIB2 handling)
  \item Hydra / OmegaConf (YAML configuration)
\end{itemize}

\textbf{Recommended setup}

\begin{itemize}
  \item Pinned \texttt{requirements.txt}
  \item Virtual environment or container
  \item Consistent library versions
\end{itemize}

\end{column}

\end{columns}

\vspace{4mm}
\footnotesize
\rtext{\bf Reproducibility depends on a stable, fully controlled software environment.}

\end{frame}
%!TEX root = lec17.tex
% ================================================================================
% Lecture 17 — Slide 07
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{AICON Walkthrough: Manual Setup (Packages and ecCodes)}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.42\textwidth}
\footnotesize

\vspace{-2mm}
\textbf{Install required Python packages}

\begin{codeonly}{Pinned Python environment}
# Install all required packages (version!)
%pip install --no-cache-dir -U -r ../requirements.txt

# Inspect installed versions
!pip freeze
\end{codeonly}

\vspace{1mm}
Exact package versions are critical for
PyTorch, PyG, Lightning, and Anemoi compatibility.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.56\textwidth}
\footnotesize

\vspace{-2mm}
\textbf{Configure ecCodes definitions}

\begin{minipage}{6cm}
\begin{lstlisting}
import os
from pathlib import Path

# Path to ICON/DWD ecCodes definitions
# (provided with the repo)
edzw_defs = Path("eccodes/definitions.edzw").resolve()

# Standard ecCodes definitions (system install)
std_defs = "/path/to/eccodes/definitions"

os.environ["ECCODES_DEFINITION_PATH"] = \
    f"{edzw_defs}:{std_defs}"
\end{lstlisting}
\end{minipage}

\vspace{1mm}
\color{darkgreen}
ICON GRIB decoding requires extended
definition tables beyond standard ecCodes.

\end{column}

\end{columns}


\end{frame}
%!TEX root = lec17.tex
% ================================================================================
% Lecture 17 — Slide 08
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{AICON Walkthrough: Notebook Initialization}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\textbf{Jupyter and runtime setup}

\begin{codeonly}{Notebook basics}
% Enable autoreload for iterative development
%load_ext autoreload
%autoreload 2

# Standard imports
import os
import numpy as np
import torch
\end{codeonly}

\vspace{1mm}
Ensures code changes are picked up
and the runtime environment is visible.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.51\textwidth}
\footnotesize

\textbf{Determinism and sanity checks}

\begin{codeonly}{Reproducibility checks}
# Fix random seeds
torch.manual_seed(42)
np.random.seed(42)

# Check PyTorch device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)
\end{codeonly}

\vspace{1mm}
Deterministic behavior is essential
for debugging and scientific comparison.

\end{column}

\end{columns}

\footnotesize
\rtext{\bf Initialization is not boilerplate — it defines the experimental contract.}

\end{frame}
% ================================================================================
% Lecture 17 — Slide 09
% ================================================================================
\begin{frame}[t,fragile]
\mytitle{AICON training setup (Anemoi): config-driven workflow}

\begin{columns}[T,totalwidth=\textwidth]
% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\vspace{-1mm}
\footnotesize

\textbf{Main idea}
\begin{itemize}
\item training is \y{fully controlled by YAML configs}
\item Hydra composes config blocks:
\begin{itemize}
\item data (Zarr), variables, normalization
\item model architecture (AICON / GNN)
\item trainer settings (epochs, batch, strategy)
\end{itemize}
\end{itemize}

\vspace{-2mm}
\textbf{Workflow}
\begin{itemize}
\item choose config (start from \y{integration test})
\item instantiate trainer
\item run training (checkpoints + logger)
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\vspace{-1mm}
\footnotesize

\textbf{Notebook pattern (core lines)}
\begin{lstlisting}
config_filename = "test_aicon_01.yaml"

# Hydra loads and resolves config
config = load_config(config_filename)

# Anemoi trainer wraps Lightning
trainer = AnemoiTrainer(config)

# run training
trainer.train()
\end{lstlisting}

\vspace{1mm}
\textbf{Outputs}

\vspace{-2mm}
\begin{itemize}
\item checkpoints: \texttt{last.ckpt}, \texttt{inference-last.ckpt}
\item logs: TensorBoard / MLflow-style metrics
\end{itemize}

\end{column}
\end{columns}

\end{frame}
% ================================================================================
% Lecture 17 — Slide 10
% ================================================================================
\begin{frame}[t]
\mytitle{Training diagnostics: loss curve and experiment logger}

\begin{columns}[T,totalwidth=\textwidth]
% ------------------------------------------------------------
\begin{column}[T]{0.40\textwidth}
\vspace{-1mm}
\footnotesize

\textbf{What we monitor}
\begin{itemize}
\item training loss vs epoch/step
\item validation loss (generalization)
\item learning rate schedule
\item walltime + throughput
\end{itemize}

\vspace{2mm}
\textbf{Why it matters}
\begin{itemize}
\item early detection of instability
\item reproducible experiments
\item compare model variants
\end{itemize}

\vspace{2mm}
\color{red}\bf
\textbf{Take-away:}
training is \y{observable} and \y{traceable}.
\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.60\textwidth}


\vspace{-5mm}
\begin{center}
% Replace with your actual images from the notebook / export
\includegraphics[width=0.6\linewidth]{../../images/img17/aicon_loss_curve.png}

\vspace{1mm}
\includegraphics[width=0.85\linewidth]{../../images/img17/aicon_logger.png}
\end{center}

\end{column}
\end{columns}

\end{frame}
% ================================================================================
% Lecture 17 — Slide 11
% ================================================================================
\begin{frame}[t]
\mytitle{AICON training workflow (overview)}

\vspace{-2mm}
\begin{center}
% Put your overview graphic exported from the notebook / created by you
\includegraphics[width=0.96\linewidth]{../../images/img17/anemoi_icon_overview.png}
\end{center}

\vspace{-2mm}
\footnotesize
\textbf{Pipeline:} ICON data $\rightarrow$ graph dataset $\rightarrow$ training config $\rightarrow$ trainer $\rightarrow$ checkpoints + logs
\end{frame}
% ================================================================================
% Lecture 17 — Slide 12
% ================================================================================
\begin{frame}[t,fragile]
\mytitle{Training configuration: input and outputs}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\vspace{-1mm}
\footnotesize
\textbf{Input data (from config)}
\vspace{1mm}

\begin{codeonly}{text}
ICON mesh (NetCDF):
  <.../icon_mesh.nc>

Training interval:
  <YYYY-MM-DD HH> ... <YYYY-MM-DD HH>

Data files:
  <...>  (joined list)
\end{codeonly}

\vspace{1mm}
\textbf{Key point:} a single config fixes both \y{data geometry} and \y{time range}.
\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\vspace{-1mm}
\footnotesize
\textbf{Output directories}
\vspace{1mm}

\begin{codeonly}{text}
Checkpoints:
  <.../checkpoints/...>

Logs (incl. MLFlow):
  <.../logs/...>
\end{codeonly}

\vspace{2mm}
\color{red}\bf
\textbf{Take-away:}
config $\Rightarrow$ reproducible paths and artifacts.
\end{column}

\end{columns}
\end{frame}
% ================================================================================
% Lecture 17 — Slide 13
% ================================================================================
\begin{frame}[t]
\mytitle{Training dataset (Zarr) inspected as Xarray}

\vspace{-2mm}
\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.36\textwidth}
\vspace{-1mm}
\footnotesize

\textbf{Key idea}
\begin{itemize}
\item dataset is a \y{4D tensor}:
\newline
(time, variable, ensemble, cell)
\item efficient I/O via \y{chunking} (Dask)
\item includes metadata:
\begin{itemize}
\item latitudes / longitudes
\item variable-wise statistics
(mean, std, min/max)
\end{itemize}
\end{itemize}

\vspace{1mm}
\color{red}\bf
\textbf{Take-away:}
this is \y{ML-ready} data with rich metadata.
\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.64\textwidth}
\vspace{-2mm}
\begin{center}
\includegraphics[width=\linewidth]{../../images/img17/dataset_xarray.png}
\end{center}
\end{column}

\end{columns}
\end{frame}
% ================================================================================
% Lecture 17 — Slide 14
% ================================================================================
\begin{frame}[t]
\mytitle{Vertical levels: selected ICON layers in the dataset}

\vspace{-2mm}
\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.54\textwidth}
\vspace{-1mm}
\scriptsize

\textbf{Variables on model levels}
\vspace{1mm}

\begin{tabular}{lll}
\textbf{shortName} & \textbf{Name} & \textbf{Levels} \\
\hline
P  & Pressure                     & 49,57,64,70,75,79,86,...,120 \\
QV & Specific humidity            & 49,57,64,70,75,79,86,...,120 \\
T  & Temperature                  & 49,57,64,70,75,79,86,...,120 \\
U  & U-component of wind          & 49,57,64,70,75,79,86,...,120 \\
V  & V-component of wind          & 49,57,64,70,75,79,86,...,120 \\
W  & Vertical velocity (geom.)    & 49,57,64,70,75,79,86,...,120 \\
\hline
\end{tabular}

\vspace{4mm}
\footnotesize

\textbf{Forcings / static features (examples):}\\[2mm]
\scriptsize
EMIS\_RAD, FR\_LAND, FR\_LAKE, HSURF, Z0, insolation,
SSO\_*, sin/cos(latitude, longitude, local\_time, julian\_day)

\vspace{1mm}
\footnotesize
\textbf{Idea:} \y{multi-level state + forcings} $\Rightarrow$ complete ML input for AICON.
\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\vspace{-2mm}
\raggedleft

% replace with your actual image path:
\includegraphics[width=0.8\linewidth]{../../images/img17/icon_levels.png}

\vspace{-2mm}
\footnotesize
\textbf{ICON level structure:} full model vertical grid (selection highlighted).
\end{column}

\end{columns}
\end{frame}
% ================================================================================
% Lecture 17 — Slide 15
% ================================================================================
\begin{frame}[t]
\mytitle{ICON multimesh: the hidden graph behind AICON}

\vspace{-2mm}
\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}
\vspace{-1mm}
\footnotesize

\textbf{Key idea}
\begin{itemize}
\item AICON does not run on a regular lat--lon grid
\item it uses ICON's \y{hierarchical triangular mesh}
\item the GNN operates on a \y{hidden multi-mesh}
\end{itemize}

\vspace{2mm}
\textbf{Multi-mesh principle}
\begin{itemize}
\item union of coarse-to-fine subgraphs \\
\quad R$n$B0 $\cup$ R$n$B1 $\cup$ ... $\cup$ R$n$Bk
\item mixes \y{short-range} + \y{long-range} edges
\item similar spirit as GraphCast multi-mesh
\end{itemize}

\vspace{2mm}
\color{red}\bf
\textbf{Take-away:}
the multi-mesh gives the GNN both \y{local physics} and \y{global context}.
\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}
\vspace{-2mm}
\raggedleft
% Use the level-wise multimesh plot from the notebook:
\includegraphics[width=0.95\linewidth]{../../images/img17/grid_visual.png}

\vspace{4mm}
\scriptsize
Hidden mesh edges shown level-wise: coarse levels enable long-range interaction.
\end{column}

\end{columns}
\end{frame}
% ================================================================================
% Lecture 17 — Slide 16
% ================================================================================
\begin{frame}[t]
\mytitle{AICON model: encoder -- graph processor -- decoder}

\vspace{-2mm}
\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\vspace{-1mm}
\footnotesize

\textbf{Graph-to-graph forecasting}
\begin{itemize}
\item input: state + forcings on ICON cells (nodes)
\item output: next-step state (multi-var, multi-level)
\end{itemize}

\vspace{0mm}
\textbf{Architecture blocks}
\begin{itemize}
\item \textbf{Encoder:} maps raw variables to latent node/edge features
\item \textbf{Processor:} message passing on the mesh graph (several layers)
\item \textbf{Decoder:} projects latent features to physical output variables
\end{itemize}

\vspace{0mm}
\color{red}\bf
\textbf{Take-away:}
encoder/decoder makes the network \y{variable-agnostic} in latent space.
\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.54\textwidth}
\vspace{-2mm}
\raggedleft
% Use the architecture figure / screenshot from the notebook:
\includegraphics[width=0.9\linewidth]{../../images/img17/encoder_decoder.png}

\vspace{-2mm}
\scriptsize
Encoder maps physics variables $\rightarrow$ latent graph; decoder maps latent $\rightarrow$ output fields.
\end{column}

\end{columns}
\end{frame}
% ================================================================================
% Lecture 17 — Slide 17
% ================================================================================
\begin{frame}[t]
\mytitle{Graph structure: local neighborhoods on the ICON mesh}

\vspace{-2mm}
\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.49\textwidth}
\vspace{-1mm}
\footnotesize

\textbf{Why this matters}
\begin{itemize}
\item AICON runs on the ICON grid as \y{graph neural network (GNN)}
\item each ICON cell $\Rightarrow$ one \y{graph node}
\item edges connect \y{mesh neighbors}
\end{itemize}

\vspace{2mm}
\textbf{Message passing view}
\begin{itemize}
\item prediction at one node uses information from:
\begin{itemize}
\item \textbf{1st neighbors} (directly connected)
\item \textbf{2nd neighbors} (neighbors-of-neighbors)
\end{itemize}
\item this defines the local receptive field of the GNN
\end{itemize}


\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\vspace{-2mm}

\vspace{2mm}
\color{red}\bf
\textbf{Take-away:}
GNNs learn transport + interaction patterns through \y{local connectivity}.

\vspace{0mm}
\raggedleft
% Replace with your exported image:
\includegraphics[width=0.8\linewidth]{../../images/img17/graph_neighbours_crop.png}

\vspace{-2mm}
\scriptsize
Example: subgraph around one node (orange) with 1st and 2nd neighbors.
\end{column}

\end{columns}
\end{frame}
% ================================================================================
% Lecture 17 — Slide 18
% ================================================================================
\begin{frame}[t]
\mytitle{Graph Transformer attention: which neighbors matter?}

\vspace{-2mm}
\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\vspace{-1mm}
\footnotesize

\textbf{Graph Transformer vs.\ plain message passing}
\begin{itemize}
\item classic GNN: neighbors contribute via fixed averaging / sum
\item GraphTransformer: each edge gets a learned \y{attention weight}
\end{itemize}

\vspace{2mm}
\textbf{Interpretation}
\begin{itemize}
\item for one receiver node $i$, all incoming edges $(j \rightarrow i)$
\item attention weights $\alpha_{i,j}$ sum to 1 (per head)
\item thick edges $\Rightarrow$ \y{high influence} of neighbor $j$
\end{itemize}

\vspace{2mm}
\color{red}\bf
\textbf{Take-away:}
the model learns \y{where to look} on the graph depending on flow regime and structure.
\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\vspace{-2mm}
\raggedleft

\includegraphics[width=0.86\linewidth]{../../images/img17/aicon_attention_graph.png}

\vspace{-1mm}
\includegraphics[width=0.86\linewidth]{../../images/img17/aicon_attention_graph2.png}

\vspace{-2mm}
\scriptsize
\textbf{Example:}
(top) ICON multi-mesh graph (coarse + fine connections);
(bottom) attention setup
\end{column}

\end{columns}
\end{frame}
% ================================================================================
% Lecture 17 — Slide 19
% ================================================================================
\begin{frame}[t, fragile]
\mytitle{Transfer learning: reuse weights on a finer hidden mesh}

\vspace{-2mm}
\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.58\textwidth}
\vspace{-1mm}
\footnotesize

\textbf{Motivation}
\begin{itemize}
\item training on the finest multi-mesh is expensive
\item idea: \y{train on coarse mesh} and transfer to finer mesh
\end{itemize}

\vspace{2mm}
\textbf{What transfers well?}
\begin{itemize}
\item most encoder/processor/decoder weights
\item learned graph attention patterns are largely mesh-agnostic
\end{itemize}

\vspace{2mm}
\textbf{What must be adapted?}
\begin{itemize}
\item graph-dependent parameters:
\begin{itemize}
\item hidden node coordinates / embeddings
\item extra trainable node/edge attributes
\end{itemize}
\item these are re-initialized and fine-tuned on the new mesh
\end{itemize}

\vspace{2mm}
\color{red}\bf
\textbf{Take-away:}
efficient training strategy: \y{pretrain coarse} $\rightarrow$ \y{fine-tune fine}.
\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.4\textwidth}
\vspace{-1mm}
\footnotesize

\textbf{Example (AICON walkthrough)}
\begin{itemize}
\item change hidden mesh resolution:
\begin{itemize}
\item \texttt{max\_level\_multimesh: 3 $\rightarrow$ 4}
\end{itemize}
\item load weights only + enable transfer learning
\end{itemize}

\vspace{1mm}
\scriptsize
\begin{block}{Config idea (YAML)}
\begin{verbatim}
training:
  load_weights_only: true
  transfer_learning: true
  run_id: <pretrained_run_id>

graph:
  nodes:
    icon_mesh:
      node_builder:
        max_level_multimesh: 4
\end{verbatim}
\end{block}

\vspace{-1mm}
\footnotesize
This enables \y{cost-efficient scaling} to higher resolution.
\end{column}

\end{columns}
\end{frame}
% ================================================================================
% Lecture 17 — Slide 20
% ================================================================================
\begin{frame}[t]
\mytitle{Operational inference at DWD: why a dedicated tool?}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.55\textwidth}
\vspace{-1mm}
\footnotesize

\textbf{Goal}
\begin{itemize}
\item run AICON forecasts \y{operationally} and \y{reproducibly}
\item integrate into existing NWP infrastructure (GRIB2, workflows, monitoring)
\end{itemize}

\vspace{2mm}
\textbf{Why not only \texttt{anemoi-inference}?}
\begin{itemize}
\item DWD-specific I/O and preprocessing (GRIB2 conventions)
\item additional input engineering (e.g.\ soil moisture index etc.)
\item packaging as stable runtime for ops (container)
\item hooks for monitoring and verification pipelines
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.43\textwidth}
\vspace{-1mm}
\footnotesize

\textbf{Key ingredients}
\begin{itemize}
\item \textbf{checkpoint:} \texttt{inference-last.ckpt}
\item \textbf{input:} ICON / reanalysis data streams
\item \textbf{output:} GRIB2 forecast products
\end{itemize}

\vspace{2mm}
\textbf{Operational packaging}
\begin{itemize}
\item Apptainer / Singularity container
\item fixed paths to constants + weights
\item versioning: container + config + checkpoint
\end{itemize}

\vspace{2mm}
\color{red}\bf
\textbf{Take-away:}
DWD inference tool = \y{bridge from ML model to ops}.
\end{column}

\end{columns}
\end{frame}
% ================================================================================
% Lecture 17 — Slide 21
% ================================================================================
\begin{frame}[t]
\mytitle{Demo: AICON forecast from operational inference}

\vspace{-2mm}
\begin{center}
% Replace with your actual inference output figure
\includegraphics[width=0.96\linewidth]{../../images/img17/aicon_inference_forecast.png}
\end{center}

\vspace{-1mm}
\footnotesize
\textbf{Example product:} ML forecast fields generated from checkpoint + operational inference tool.
\end{frame}
% ================================================================================
% Slide 22 — FRAIM ecosystem graphic (Library + Apps + DAWID)
% ================================================================================
\begin{frame}[t, fragile]
\mytitle{FRAIM Ecosystem: Central Library, FRAIM-Apps, and DAWID Platform}

\centering
\vspace{0mm}

% requires:
% \usepackage{tikz}
% \usetikzlibrary{positioning,arrows.meta}

\begin{tikzpicture}[
  scale=0.7, transform shape,
  font=\footnotesize,
  >=Latex,
  node distance=12mm,
  box/.style={rounded corners=2mm, draw=black!60, thick, align=center, inner sep=2mm},
  app/.style={box, minimum width=28mm, minimum height=10mm, fill=blue!4},
  lib/.style={box, minimum width=44mm, minimum height=16mm, fill=blue!10},
  daw/.style={box, minimum width=44mm, minimum height=16mm, fill=green!8},
  arrow/.style={->, thick, draw=black!70}
]

% ------------------------------------------------------------
% Center: FRAIM library
% ------------------------------------------------------------
\node[lib] (lib) {\textbf{FRAIM Library}\\[-0.5mm]
\scriptsize reusable modules + standards};

% ------------------------------------------------------------
% FRAIM-Apps around (examples)
% ------------------------------------------------------------
\node[app, above left=18mm and 38mm of lib]  (app1) {\textbf{FRAIM-App}\\QC / Monitoring};
\node[app, above=26mm of lib]                (app2) {\textbf{FRAIM-App}\\CBCF Aviation};
\node[app, above right=18mm and 38mm of lib] (app3) {\textbf{FRAIM-App}\\Downsampling};
\node[app, right=52mm of lib]                (app4) {\textbf{FRAIM-App}\\Text Generation};
\node[app, below=26mm of lib]                (app6) {\textbf{FRAIM-App}\\Road Weather};
\node[app, below left=18mm and 38mm of lib]  (app7) {\textbf{FRAIM-App}\\Nowcasting};
\node[app, left=52mm of lib]                 (app8) {\textbf{FRAIM-App}\\Obs Processing};

% arrows from apps to library (reuse)
\draw[arrow] (app1) -- (lib);
\draw[arrow] (app2) -- (lib);
\draw[arrow] (app3) -- (lib);
\draw[arrow] (app4) -- (lib);
\draw[arrow] (app6) -- (lib);
\draw[arrow] (app7) -- (lib);
\draw[arrow] (app8) -- (lib);

% ------------------------------------------------------------
% DAWID Platform (placed bottom-right)
% ------------------------------------------------------------
\node[daw, below right=24mm and 34mm of lib] (dawid)
{\textbf{DAWID Platform}\\[-0.5mm]
\scriptsize UI + LLMs + Function calling};

% DAWID-API link to library
\draw[arrow] (dawid.west) to[bend left=15]
  node[midway, above, sloped, font=\scriptsize]{\textbf{DAWID-API}} (lib.south east);

% DAWID link to Postprocessing (rerouted to avoid Nowcasting area)
\draw[arrow] (dawid.north) -- (app4.south);

\end{tikzpicture}

\end{frame}
% ================================================================================
% Slide — Anemoi vs. FRAIM (1/3)
% ================================================================================
\begin{frame}[t]
\mytitle{Anemoi vs.\ FRAIM — What are they about?}

\begin{columns}[T,totalwidth=\textwidth]
% ------------------------------------------------------------
\begin{column}[T]{0.49\textwidth}
\footnotesize
\textbf{Anemoi (ECMWF \& Partners)}
\begin{itemize}
\item international collaboration to build \y{ML-based forecast models}
\item \textbf{end-to-end framework} for \y{training \& inference}
\item well-defined pipeline:
\newline
datasets $\rightarrow$ graphs/models $\rightarrow$ training $\rightarrow$ inference/deploy
\item \textbf{Open Source}, pan-European community
\end{itemize}

\vspace{2mm}
\textbf{Typical question:}
\newline
\emph{How do we train and operate an ML forecasting model operationally?}
\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.49\textwidth}

\vspace{-2mm}
\footnotesize
\textbf{FRAIM (E-AI / DWD / Partners)}
\begin{itemize}
\item international collaboration focused on \y{many AI applications}
\item \textbf{method toolbox / modular framework} across a broad portfolio:
\newline
products, services, and smaller AI components
\item platform/integration view:
\y{standards, building blocks, reuse}
\item \textbf{umbrella framework} (forecasting is only one use case)
\end{itemize}

\vspace{0mm}
\textbf{Typical question:}
\newline
\emph{How do we build a modular AI ecosystem for many meteorological products and services?}
\end{column}
\end{columns}
\end{frame}
% ================================================================================
% Slide — Anemoi vs. FRAIM (2/3)
% ================================================================================
\begin{frame}[t]
\mytitle{Pipeline view: where does each framework sit?}

\footnotesize
\vspace{-1mm}

\textbf{Anemoi:} lifecycle of an ML forecast model \\
\vspace{1mm}
\begin{center}
\begin{tabular}{c c c c c}
\textbf{Data} & $\rightarrow$ & \textbf{Training} & $\rightarrow$ & \textbf{Inference/Deploy} \\
(anemoi-datasets) & & (anemoi-training) & & (operational tooling) \\
\end{tabular}
\end{center}

\vspace{3mm}
\textbf{FRAIM:} system / toolbox view across multiple AI components \\
\vspace{1mm}
\begin{center}
\begin{tabular}{c c c c c}
\textbf{Use case} & $\rightarrow$ & \textbf{Modules} & $\rightarrow$ & \textbf{Integration/Operations} \\
Forecast / Nowcast / QC / \\
DA / Postproc
& &
training, surrogates, \\
QA, LLM, etc.
& &
platform + standards \\
\end{tabular}
\end{center}

\vspace{2mm}
\textbf{Take-away:}
\newline
Anemoi is \y{forecast-model-centric}, FRAIM is \y{architecture- \& reuse-centric}.
\end{frame}
% ================================================================================
% Slide — Anemoi vs. FRAIM (3/3)
% ================================================================================
\begin{frame}[t]

\mytitle{Concrete differences and a good integration story}

\begin{columns}[T,totalwidth=\textwidth]
% ------------------------------------------------------------
\begin{column}[T]{0.54\textwidth}

\vspace{0mm}
\footnotesize
\textbf{Differences (short \& concrete)}
\begin{itemize}
\item \textbf{Scope:}
Anemoi = end-to-end ML forecasting \\
FRAIM = modular AI toolbox for many meteorological products
\item \textbf{Core artifacts:}
\begin{itemize}
\item \textbf{Anemoi:} datasets, graphs, model weights, training pipelines
\item \textbf{FRAIM:} central library + reusable modules + standards
\end{itemize}
\item \textbf{Organization principle:}
\begin{itemize}
\item Anemoi: one coherent forecasting stack
\item FRAIM: many \y{use-case driven FRAIM-Apps} (each in its own repo)
\end{itemize}
\end{itemize}
\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.45\textwidth}

\vspace{-1mm}
\footnotesize
\textbf{How does this combine well?}
\begin{itemize}
\item FRAIM can \y{integrate} mfai or Anemoi as a forecasting or processing engine
\item FRAIM then provides:
\begin{itemize}
\item product-specific pipelines (QC, DA, verification, monitoring, etc.)
\item deployment patterns and operational standards
\end{itemize}
\end{itemize}

\vspace{2mm}
\color{red}\bf
\textbf{One-liner:}
\newline
Anemoi = \emph{forecast-model factory}; \\
FRAIM = \emph{modular product ecosystem}.
\end{column}
\end{columns}
\end{frame}
% ================================================================================
% Slide 26 — DAWID as LLM Platform and Integration Layer
% ================================================================================
\begin{frame}[t]
\mytitle{DAWID — LLM Platform, Tools, and FRAIM Integration}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.53\textwidth}
\vspace{-1mm}
\footnotesize

\textbf{DAWID capabilities}
\begin{itemize}
\item \textbf{LLM user interface}
\begin{itemize}
\item chat + document context (RAG)
\item role-based workflows (science / dev / ops)
\end{itemize}

\item \textbf{Function calling}
\begin{itemize}
\item controlled execution of domain functions
\item structured I/O and provenance
\end{itemize}

\item \textbf{Agents (multi-step)}
\begin{itemize}
\item plan $\rightarrow$ call tools $\rightarrow$ validate
\end{itemize}
\end{itemize}

\vspace{1mm}
\textbf{Key idea:} DAWID is the \y{interactive AI cockpit}.
\end{column}


% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\vspace{-1mm}
\footnotesize

\textbf{DAWID-API integration}
\begin{itemize}
\item \textbf{Unified API} to LLMs and tools
\begin{itemize}
\item multi-LLM backends
\item tool/function endpoints
\end{itemize}

\item \textbf{Link to FRAIM-Apps}
\begin{itemize}
\item FRAIM-App $\rightarrow$ DAWID-API: reasoning + tooling
\item consistent interface across products
\end{itemize}
\end{itemize}

\vspace{2mm}
\color{red}\bf
\textbf{Take-away:}
DAWID connects \y{LLMs + tools + FRAIM-Apps}.
\end{column}

\end{columns}
\end{frame}
% ================================================================================
% E-AI Tutorial Slides
% Filename: lec17.tex
%
% Roland Potthast 2025/2026
% Licence: CC-BY4.0
% ================================================================================
\documentclass[aspectratio=169]{beamer}

% --- Load lecture macros --------------------------------------------------------
\input{../lec_macros.tex}
\newcommand{\LectureNumber}{Lecture 17}

% --- Document -------------------------------------------------------------------
\begin{document}

% somewhere before the frame (or in lec17.tex)
% put this before the image
\setagendaboxforlecture{17}

\input{../lec_agenda.tex}
\input{lec17_01.tex}
\input{lec17_02.tex}
\input{lec17_03.tex}
\input{lec17_04.tex}
\input{lec17_05.tex}
\input{lec17_06.tex}
\input{lec17_07.tex}
\input{lec17_08.tex}
\input{lec17_09.tex}
\input{lec17_10.tex}
\input{lec17_11.tex}
\input{lec17_12.tex}
\input{lec17_13.tex}
\input{lec17_14.tex}
\input{lec17_15.tex}
\input{lec17_16.tex}
\input{lec17_17.tex}
\input{lec17_18.tex}
\input{lec17_19.tex}
\input{lec17_20.tex}
\input{lec17_21.tex}
\input{lec17_22.tex}
\input{lec17_23.tex}
\input{lec17_24.tex}
\input{lec17_25.tex}
\input{lec17_26.tex}

% --- End Document ---------------------------------------------------------------
\end{document}
%!TEX root = lec18.tex
% ================================================================================
% Lecture 18 — Slide 01
% ================================================================================
\begin{frame}[t]

\mytitle{AI Data Assimilation — Why Does It Matter?}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize

\textbf{Numerical Weather Prediction (NWP)}

\vspace{1mm}
Weather forecasts are produced by integrating
\y{high-dimensional dynamical models} forward in time.

\vspace{0mm}
However:

\begin{itemize}
  \item The atmosphere is \y{chaotic}
  \item Small initial errors grow rapidly
  \item Forecast skill is \rtext{\bf dominated by initial conditions}
\end{itemize}

\vspace{0mm}
\textbf{Core problem}

\vspace{1mm}
At any analysis time, we have:
\begin{itemize}
  \item an \y{imperfect model forecast} (background)
  \item \y{sparse, noisy observations}
\end{itemize}

\vspace{1mm}
These must be combined optimally.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize

\textbf{Data assimilation}

\vspace{1mm}
Data assimilation provides a \y{statistically consistent framework}
to merge:
\[
\text{model information}
\quad + \quad
\text{observations}
\]

\vspace{2mm}
The result is the \y{analysis state}:
\begin{itemize}
  \item best estimate of the atmospheric state
  \item starting point for forecasts
\end{itemize}

\vspace{2mm}
\rtext{\bf Data assimilation is the information bottleneck of NWP.}

\vspace{1mm}
Everything that follows — forecasts, warnings, applications —
depends on it.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec18.tex
% ================================================================================
% Lecture 18 — Slide 02
% ================================================================================
\begin{frame}[t]

\mytitle{Classical Data Assimilation: The Analysis Cycle}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.54\textwidth}
\footnotesize

\textbf{The classical DA cycle}

\vspace{1mm}
Operational NWP systems run a \y{repeating assimilation cycle}:

\begin{enumerate}
  \item Start from a \y{background state} $x_b$
  \item Assimilate observations $\;y$
  \item Compute an \y{analysis} $x_a$
  \item Run the numerical model forward
  \item Use the forecast as next background
\end{enumerate}

\vspace{2mm}
This cycle is repeated every few hours as new
observations become available.

\vspace{2mm}
\rtext{\bf The analysis step is the only place where observations enter.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\vspace{-2mm}
\textbf{Established DA methods}

\vspace{1mm}
Several algorithmic families are used in practice:

\begin{itemize}
  \item \y{\bf 3D-Var / 4D-Var}
  \begin{itemize}
    \item variational optimization
    \item adjoint-based
  \end{itemize}

  \vspace{0mm}
  \item \y{\bf Ensemble Kalman Filters (EnKF)}
  \begin{itemize}
    \item flow-dependent uncertainty
    \item ensemble statistics
  \end{itemize}

  \vspace{0mm}
  \item \y{\bf Particle Filters}
  \begin{itemize}
    \item fully Bayesian
    \item now also high-dimensional!
  \end{itemize}
\end{itemize}

\vspace{0mm}
All methods aim at the \y{same goal}:
a statistically optimal analysis.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec18.tex
% ================================================================================
% Lecture 18 — Slide 03
% ================================================================================
\begin{frame}[t]

\mytitle{Two AI Paths for Using Observations}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\textbf{Path 1: AI-based forecasting}

\vspace{1mm}
Observations are used \y{directly inside neural networks}
that produce forecasts.

\vspace{1mm}
Typical characteristics:

\begin{itemize}
  \item observations as additional inputs
  \item sometimes \y{no explicit model state}
  \item learning focuses on \rtext{\bf prediction skill}
\end{itemize}

\vspace{2mm}
This approach bypasses the classical analysis concept.

\vspace{1mm}
\rtext{\bf Observations $\rightarrow$ forecast directly}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\vspace{-2mm}
\textbf{Path 2: AI-based data assimilation}

\vspace{1mm}
Observations are used to compute an \y{analysis state},
not a forecast.

\vspace{1mm}
Key properties:

\begin{itemize}
  \item preserves the \y{analysis–forecast separation}
  \item consistent with Bayesian DA theory
  \item AI replaces the \y{analysis algorithm}, not the model
\end{itemize}

\vspace{2mm}
\rtext{\bf Observations $\rightarrow$ analysis $\rightarrow$ forecast}

\vspace{1mm}
This is the conceptual space of \y{\bf AI-Var}.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec18.tex
% ================================================================================
% Lecture 18 — Slide 04
% ================================================================================
\begin{frame}[t]

\mytitle{Why Bring AI into Data Assimilation?}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.54\textwidth}
\footnotesize

\textbf{Limits of classical DA}

\vspace{1mm}
State-of-the-art data assimilation systems are:

\begin{itemize}
  \item \y{computationally expensive}
  \item difficult to scale to higher resolution
  \item reliant on \y{adjoint models}
\end{itemize}

\vspace{2mm}
Operational challenges include:

\begin{itemize}
  \item complex model development and maintenance
  \item long wall-clock times
  \item limited flexibility for new observation types
\end{itemize}

\vspace{2mm}
\hspace*{1cm}\begin{minipage}{5cm}
\rtext{\bf DA is often the most expensive component of NWP.}
\end{minipage}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\vspace{-2mm}
\textbf{What AI can offer}

\vspace{1mm}
Modern neural networks provide:

\begin{itemize}
  \item fast inference once trained
  \item automatic differentiation
  \item flexible nonlinear mappings
\end{itemize}

\vspace{2mm}
Potential benefits for DA:

\begin{itemize}
  \item orders-of-magnitude speedup
  \item end-to-end differentiability
  \item easier adaptation to new data streams
\end{itemize}

\vspace{2mm}
\rtext{\bf Goal: replace the solver, not the statistics.}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec18.tex
% ================================================================================
% Lecture 18 — Slide 05
% ================================================================================
\begin{frame}[t]

\mytitle{From Variational Data Assimilation to AI-Var}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\textbf{Variational DA: main Idea}

\vspace{3mm}
The analysis is obtained by minimizing:
\[
J(x)
=
\frac{1}{2}(x-x_b)^T B^{-1}(x-x_b)
+
\frac{1}{2}(y-H(x))^T R^{-1}(y-H(x))
\]

\vspace{2mm}
\textbf{Interpretation}

\begin{itemize}
  \item first term: \y{background constraint}
  \item second term: \y{observation constraint}
\end{itemize}

\vspace{2mm}
\rtext{\bf Classical DA = iterative \\numerical minimization.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\footnotesize
\centering
AI-VAR is the \y{AI verion} of \rtext{\bf 3D-Var, 4D-Var or En-VAR} depending on 
how exactly the minimizer is formulated. 

\vspace{3mm}
\hspace*{-1.3cm}
\begin{minipage}{9cm}
\includegraphics[width=\textwidth]{../../images/img18/aivar2.png}
\end{minipage}

\vspace{1mm}
\footnotesize
AI-Var sits inside the \y{variational DA family},
alongside 3D-Var, 4D-Var, and EnVar.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec18.tex
% ================================================================================
% Lecture 18 — Slide 06
% ================================================================================
\begin{frame}[t]

\mytitle{Core Idea of AI-Var}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}
\footnotesize

\textbf{Classical variational DA}

\vspace{2mm}
\begin{itemize}
  \item iterative minimization of $J(x)$
  \item requires adjoints and solvers
  \item expensive and sequential
\end{itemize}

\vspace{3mm}
\rtext{\bf Replace the minimization algorithm.}

\vspace{2mm}
\textbf{AI-Var}

\vspace{1mm}
\begin{itemize}
  \item neural network approximates the minimizer
  \item outputs analysis $x_a$ directly
  \item trained using the \y{same cost function}
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.54\textwidth}

\centering
\vspace{-8mm}
\hspace*{-1cm}
\begin{minipage}{9cm}
\includegraphics[width=\textwidth]{../../images/img18/aivar1.png}
\end{minipage}

\vspace{1mm}
\footnotesize
Classical DA workflow (left) versus AI-based inference of the analysis (right).

\vspace{5mm}
\footnotesize
\rtext{\bf Paradigm shift}

\vspace{1mm}
\begin{itemize}
  \item \color{darkgreen} DA becomes \y{inference}, not optimization
  \item milliseconds instead of iterations
  \item same statistics, different machinery
  \item flexible inflow of further information
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec18.tex
% ================================================================================
% Lecture 18 — Slide 07
% ================================================================================
\begin{frame}[t]

\mytitle{AI-Var: Architecture, Loss, and Learning}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\footnotesize

\textbf{Architecture}

\vspace{1mm}
\begin{itemize}
  \item inputs: \y{background} $x_b$ and \y{observations} $y$
  \item neural network outputs \y{analysis} $\hat{x}_a$
\end{itemize}

\vspace{2mm}
\textbf{Training loss}

\vspace{-3mm}
\[
L
=
(\hat{x}_a-x_b)^T B^{-1}(\hat{x}_a-x_b)
+
(H(\hat{x}_a)-y)^T R^{-1}(H(\hat{x}_a)-y)
\]

\vspace{2mm}
\begin{itemize}
  \item $B^{-1}$ and $R^{-1}$ weight uncertainties
  \item observation operator $H$ is inside the loss
\end{itemize}

\vspace{2mm}
\rtext{\bf Statistics and physics are embedded in the loss.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\centering
\vspace{-6mm}
\hspace*{0cm}
\begin{minipage}{6cm}
\includegraphics[width=\textwidth]{../../images/img18/aivar1.png}
\end{minipage}

\vspace{2mm}
\footnotesize

\textbf{What is learned}

\vspace{1mm}
\begin{itemize}
  \item mapping $(x_b, y) \;\rightarrow\; x_a$
\end{itemize}

\vspace{1mm}
\textbf{What is \rtext{not} learned}

\vspace{1mm}
\begin{itemize}
  \item no reanalysis targets
  \item no iterative solvers
  \item no adjoint code
\end{itemize}

\vspace{1mm}
\rtext{\bf Optimization is replaced by inference.}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec18.tex
% ================================================================================
% Lecture 18 — Slide 08
% ================================================================================
\begin{frame}[t, fragile]

\mytitle{1D Data Assimilation Setup}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize

\textbf{Toy problem}

\vspace{1mm}
We consider a \y{1D state} on a fixed grid, periodic (!).

\vspace{1mm}
\begin{itemize}
  \item truth: modulated sine function
  \item background $x_b$: shifted, smoothed, biased
  \item observations $y$: sparse, noisy point samples
\end{itemize}

\vspace{2mm}
All ingredients are \y{fully controlled}:
\begin{itemize}
  \item known truth
  \item known error statistics
  \item explicit observation locations
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\centering
\vspace{-6mm}
\hspace*{0cm}
\begin{minipage}{8cm}
\includegraphics[width=\textwidth]{../../images/img18/1d_xt_xb_obs.png}
\end{minipage}

\vspace{1mm}
\footnotesize
Truth $x_{true}$, background $x_b$, and sparse observations $y$.

\vspace{8mm}
\rtext{\bf Ideal testbed to explore data assimilation.}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec18.tex
% ================================================================================
% Lecture 18 — Slide 09
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{Classical 3D-Var in 1D: Mathematics Made Explicit}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\textbf{3D-Var cost function}

\vspace{1mm}
The analysis $x_a$ minimizes $J(x)$ from above. 


\vspace{2mm}
\textbf{Linear case (this setup)}

\vspace{1mm}
\begin{itemize}
  \item $H$: point-sampling operator
  \item $B$: Gaussian covariance
  \item $R = \sigma_o^2 I$
\end{itemize}

\vspace{2mm}
\textbf{Closed-form solution}

\vspace{-3mm}
\[
x_a
=
x_b
+
B H^T (H B H^T + R)^{-1}
\bigl(y - H x_b\bigr)
\]

\vspace{2mm}
\rtext{\bf This is the optimal Bayesian estimate.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}

\centering
\vspace{-3mm}
\hspace*{0cm}
\begin{minipage}{7cm}
\includegraphics[width=\textwidth]{../../images/img18/1d_xa_3dvar.png}
\end{minipage}

\vspace{1mm}
\footnotesize

Top: state space — truth, background, analysis.  

Bottom: \y{analysis increment}
\[
\delta x = x_a - x_b
\]

\vspace{-2mm}
\y{Information from sparse observations is spread by $B$.}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec18.tex
% ================================================================================
% Lecture 18 — Slide 10
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{AI-Var in 1D: From Mathematics to Code}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize

\textbf{Neural increment model}

\vspace{1mm}
The network predicts the \y{analysis increment}:
\[
\delta x_\theta = \mathcal{N}_\theta(x_b, y)
\]

\vspace{1mm}
\textbf{PyTorch implementation (kept simple)}

\tiny
\begin{verbatim}
class IncrementMLP(nn.Module):
    def __init__(self, n):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(3*n, 256),
            nn.Tanh(),
            nn.Linear(256, 256),
            nn.Tanh(),
            nn.Linear(256, n))

    def forward(self, inp):
        return self.net(inp)
\end{verbatim}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}
\footnotesize

\vspace{-4mm}
{\bf Input vector:}
\[
\texttt{inp} = [x_b,\; y_{\text{grid}},\; \text{mask}]
\]


\textbf{Variational loss in code}

\vspace{1mm}
The 3D-Var cost is used \y{directly}:

\begin{verbatim}
def J_3dvar(delta_x):
    x = xb + delta_x
    innov = y - H @ x

    Jb = 0.5 * (delta_x @ B_inv @ delta_x)
    Jo = 0.5 * (innov @ R_inv @ innov)
    return Jb + Jo
\end{verbatim}

\vspace{2mm}
\rtext{\bf No analysis data.  
No solver.  
Only the variational objective.}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec18.tex
% ================================================================================
% Lecture 18 — Slide 11
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{AI-Var in 1D: Training Loop with Background \& Observations}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize

\textbf{Neural input construction}

\vspace{1mm}
The network receives \y{both} background and observations:

\begin{verbatim}
# observations mapped to grid
y_grid = torch.zeros(n)
mask   = torch.zeros(n)

y_grid[obs_idx] = y
mask[obs_idx]   = 1.0

# NN input
inp = torch.cat([xb_t, y_grid, mask])
\end{verbatim}

\vspace{-4mm}
\[
\delta x_\theta
=
\mathcal{N}_\theta(x_b,\; y)
\]

\vspace{0mm}
\hspace*{2cm}\rtext{\bf The solver is replaced by learning.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\textbf{Training loop}

\vspace{-2mm}
\begin{verbatim}
for ep in range(n_epochs):
    optimizer.zero_grad()

    delta_x = model(inp)

    loss, Jb, Jo = J_3dvar(delta_x)

    loss.backward()
    optimizer.step()
\end{verbatim}

\vspace{0mm}
\textbf{Key points}

\vspace{1mm}
\begin{itemize}
  \item loss = classical 3D-Var functional
  \item no analysis targets
  \item gradients pass through $B^{-1}$ and $H$
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec18.tex
% ================================================================================
% Lecture 18 — Slide 12
% ================================================================================
\begin{frame}[t]

\mytitle{1D Result: AI-Var Analysis vs 3D-Var}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.30\textwidth}
\footnotesize

\vspace{-2mm}
\textbf{What is shown}

\vspace{1mm}
\begin{itemize}
  \item true state $x_{true}$
  \item background $x_b$
  \item 3D-Var analysis $x_a$
  \item AI-Var analysis $x_b + \delta x_{\text{ML}}$
\end{itemize}

\vspace{0mm}
\textbf{Bottom panel}

\vspace{1mm}
\begin{itemize}
  \item classical 3D-Var increment
  \item learned AI-Var increment
  \item observation increments at obs points
\end{itemize}

\vspace{0mm}
\rtext{\bf \y{AI-Var reproduces} the \y{variational update.}}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.68\textwidth}

\centering
\vspace{-4mm}
\hspace*{0cm}
\begin{minipage}{10cm}
\includegraphics[width=\textwidth]{../../images/img18/1d_xa_MLP.png}
\end{minipage}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec18.tex
% ================================================================================
% Lecture 18 — Slide 13
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{AI-Var in 1D: Training on Many Cases}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize

\textbf{From single case to ensemble training}

\vspace{1mm}
Instead of one fixed $(x_b, y)$ pair, we train on
\y{many randomly generated cases}.

\vspace{2mm}
Each training sample contains:
\begin{itemize}
  \item a new truth $x_{true}$
  \item a new background $x_b$
  \item new observation locations and values $y$
\end{itemize}

\vspace{2mm}
\textbf{What stays fixed}

\vspace{1mm}
\begin{itemize}
  \item background covariance $B$
  \item observation error $R$
  \item variational cost $J$
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\vspace{-1mm}
\rtext{\bf The network learns a general DA operator.}

\vspace{2mm}
\textbf{Training logic (conceptual)}

\vspace{1mm}
\begin{verbatim}
for sample in training_set:
    xb, y = sample
    inp = build_input(xb, y)

    delta_x = model(inp)
    loss = J_3dvar(delta_x)

    loss.backward()
    optimizer.step()
\end{verbatim}

\vspace{2mm}
\y{Same loss, many realizations.}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec18.tex
% ================================================================================
% Lecture 18 — Slide 14
% ================================================================================
\begin{frame}[t]

\mytitle{1D Generalization: Many Unseen Test Cases}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.4\textwidth}
\footnotesize

\textbf{Test phase}

\vspace{1mm}
The trained AI-Var network is applied to
\y{previously unseen} cases.

\vspace{2mm}
For each case:
\begin{itemize}
  \item different truth
  \item different background
  \item different observations
\end{itemize}

\vspace{0mm}
\textbf{Observation}

\vspace{1mm}
\begin{itemize}
  \item consistent increments
  \item smooth, physical updates
  \item no retraining required
\end{itemize}

\vspace{1mm}
\rtext{\bf One network, many analyses.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.55\textwidth}

\centering
\vspace{-3mm}

\includegraphics[width=\textwidth]{../../images/img18/1d_multiple_01_crop.png}
\includegraphics[width=\textwidth]{../../images/img18/1d_multiple_02_crop.png}
\includegraphics[width=\textwidth]{../../images/img18/1d_multiple_05_crop.png}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec18.tex
% ================================================================================
% Lecture 18 — Slide 15
% ================================================================================
\begin{frame}[t, fragile]

\mytitle{2D Data Assimilation Setup}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.34\textwidth}
\footnotesize

\textbf{2D atmospheric toy problem}

\vspace{1mm}
\begin{itemize}
  \item horizontal–vertical grid
  \item structured background errors
  \item sparse column observations
\end{itemize}

\vspace{2mm}
\textbf{State variables}

\vspace{1mm}
\begin{itemize}
  \item truth $x_{true}(x,z)$
  \item background $x_b(x,z)$
  \item analysis $x_a(x,z)$
\end{itemize}

\vspace{2mm}
\rtext{\bf This already resembles NWP geometry.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.64\textwidth}
\footnotesize

\vspace{-4mm}
\hspace*{-0.5cm}
\begin{minipage}{11cm}
\includegraphics[width=\textwidth]{../../images/img18/2d_setup.png}
\end{minipage}

\begin{minipage}{5cm}
\tiny
\textbf{2D setup in code}

\begin{verbatim}
# 2D grid (x,z)
nx, nz = 120, 40
x = np.linspace(0, Lx, nx)
z = np.linspace(0, Lz, nz)

# background covariance (separable)
B = Bx x Bz

# sparse vertical profiles
H : (n_obs × n_state)
\end{verbatim}
\end{minipage}
\begin{minipage}{3cm}
\includegraphics[width=\textwidth]{../../images/img18/2d_B.png} \\
B matrix in 2d, $B e_{ij}$
\end{minipage}

\vspace{2mm}
\y{Same DA ingredients as in 1D, now on a 2D grid.}


\end{column}

\end{columns}

\end{frame}
%!TEX root = lec18.tex
% ================================================================================
% Lecture 18 — Slide 16
% ================================================================================
\begin{frame}[t, fragile]
\begin{tightmath}

\mytitle{2D AI-Var: Explicit Spectral $B^{-1}$ in Flattened Control Space}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.54\textwidth}
\footnotesize

\textbf{2D control vector}

\vspace{0mm}
The 2D field is represented as a \y{1D control vector}:
\[
x \in \mathbb{R}^{n},\qquad n = n_x n_z
\]

\vspace{-1mm}
{\tiny
\begin{verbatim}
nz, nx = xb.shape
n = nz * nx

X_flat = X.reshape(-1)
Z_flat = Z.reshape(-1)
\end{verbatim}
}

\vspace{-1mm}
\textbf{Full Gaussian background covariance}

\vspace{0mm}
{\tiny
\begin{verbatim}
dx2 = (X_flat[:,None]-X_flat[None,:])**2
dz2 = (Z_flat[:,None]-Z_flat[None,:])**2

B = sigma_b**2 * np.exp(
   -0.5*(dx2/Lx**2 + dz2/Lz**2)
)
B = 0.5*(B + B.T)
\end{verbatim}
}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}
\footnotesize

\textbf{Spectral regularization}

\vspace{0mm}
{\tiny
\begin{verbatim}
lam, U = np.linalg.eigh(B)

lam_floor = alpha * lam.max()
lam_reg   = np.maximum(lam, lam_floor)

Breg_inv = (U * (1.0/lam_reg)) @ U.T
Breg_inv = 0.5*(Breg_inv + Breg_inv.T)
\end{verbatim}
}

\vspace{-1mm}
\textbf{Background term in the loss}

\vspace{-1mm}
\[
J_b(\delta x)
=
\frac12\,\delta x^T\,B^{-1}\,\delta x
\]

\vspace{-1mm}
{\tiny
\begin{verbatim}
Jb = 0.5 * dx @ Breg_inv @ dx
\end{verbatim}
}

\vspace{-1mm}
\rtext{\bf Key point: $B^{-1}$ is built explicitly in this tutorial.}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec18.tex
% ================================================================================
% Lecture 18 — Slide 17  (reduced)
% ================================================================================
\begin{frame}[t, fragile]
\begin{tightmath}

\mytitle{2D AI-Var (Tutorial Code): Flattened Control + Obs Encoding + 3D-Var Loss}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize

\textbf{Inputs: background + obs on grid + mask}

\vspace{0mm}
{\tiny
\begin{verbatim}
# flatten 2D -> 1D control
nz, nx = xb.shape
n = nz * nx
xb_t = torch.tensor(xb.reshape(-1), dtype=dtype, device=device)

# obs indices (iz-major, ix-minor)
obs_indices = iz_idx * nx + ix_idx
y_vec = y_field.reshape(-1)[obs_indices]
y_t   = torch.tensor(y_vec, dtype=dtype, device=device)

# obs on grid + mask (length n)
y_grid = np.zeros(n);  mask = np.zeros(n)
y_grid[obs_indices] = y_vec
mask[obs_indices]   = 1.0

inp_t = torch.cat([xb_t,
       torch.tensor(y_grid, dtype=dtype, device=device),
       torch.tensor(mask,   dtype=dtype, device=device)], dim=0)
\end{verbatim}
}

\vspace{-1mm}
\rtext{\bf Input is $[x_b,\; y_{\rm grid},\; {\rm mask}]$ in control space.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize

\textbf{Increment MLP + variational loss}

\vspace{0mm}
{\tiny
\begin{verbatim}
class IncrementMLP(nn.Module):
    def __init__(self, n):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(3*n, 256), nn.Tanh(),
            nn.Linear(256, 256), nn.Tanh(),
            nn.Linear(256, n),
        )

def quadform(A, v): return torch.dot(v, A @ v)

def J_3dvar(dx):
    x = xb_t + dx
    innov = y_t - (H_t @ x)
    Jb = 0.5 * quadform(B_inv_t, dx)
    Jo = 0.5 * quadform(R_inv_t, innov)
    return Jb + Jo
\end{verbatim}
}

\vspace{-1mm}
\y{Exactly the classical 3D-Var objective,} \\
\y{now differentiable.}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec18.tex
% ================================================================================
% Lecture 18 — Slide 18
% ================================================================================
\begin{frame}[t, fragile]

\mytitle{2D Result: Variational Reference vs Learned Analysis}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.35\textwidth}
\footnotesize

\textbf{What is compared}

\vspace{1mm}
\begin{itemize}
  \item background $x_b$
  \item 3D-Var analysis $x_a$
  \item AI-Var analysis $\hat{x}_a$
\end{itemize}

\vspace{2mm}
\textbf{Key observation}

\vspace{1mm}
\begin{itemize}
  \item smooth spatial increments
  \item correct information spreading
  \item close to variational solution
\end{itemize}

\vspace{2mm}
\rtext{\bf Learned analysis = inference of the minimizer.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.63\textwidth}

\centering
\vspace{-3mm}
\hspace*{0cm}
\begin{minipage}{8.5cm}
\includegraphics[width=\textwidth]{../../images/img18/2d_xa_MLP_xa_3dVAR_crop.png}
\end{minipage}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec18.tex
% ================================================================================
% Lecture 18 — Slide 19  (tight version)
% ================================================================================
\begin{frame}[t]
\begin{tightmath}

\mytitle{AI Particle Filter (Gaussian Mixture): Core Idea}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.54\textwidth}
\footnotesize

\textbf{Filtering problem}

\vspace{0mm}
Sequential posterior:

\vspace{-3mm}
\[
p(x_n \mid y_{1:n})
\]

\vspace{-1mm}
Represent the distribution by \y{particles}

\vspace{-2mm}
\[
X_n = \{x^{(i)}_n\}_{i=1}^N
\]

\vspace{1mm}
\textbf{AI Particle Filter (this tutorial)}

\vspace{0mm}
Forecast ensemble $X^b_n$ is transformed into analysis ensemble:
\[
X^a_n = \mathcal{N}_\theta(X^b_n,\; y_n)
\]

\vspace{1mm}
\textbf{Gaussian mixture view}

\vspace{0mm}
Both prior and posterior are approximated by mixtures:
\[
q^b(x)\approx \frac1N\sum_i \mathcal{N}(x|x^{b,(i)},\Sigma),
\qquad
q^a(x)\approx \frac1N\sum_i \mathcal{N}(x|x^{a,(i)},\Sigma)
\]

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.42\textwidth}
\footnotesize

\textbf{Model problem: Lorenz-63}

\vspace{0mm}
\begin{itemize}
  \item state $x=(x_1,x_2,x_3)\in\mathbb{R}^3$
  \item partial observations $y=(x_1,x_2)$ + noise
  \item wrong forecast model (intentional)
\end{itemize}

\vspace{1mm}
\textbf{Key message}

\vspace{0mm}
Instead of resampling / MCMC moves, we learn a
\y{distribution transform} that fits the ensemble to the posterior.

\vspace{4mm}
\rtext{\bf Network output is a posterior particle cloud.}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec18.tex
% ================================================================================
% Lecture 18 — Slide 20
% ================================================================================
\begin{frame}[t, fragile]
\begin{tightmath}

\mytitle{Neural Particle Update: DeepSets (Permutation Invariance)}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\footnotesize

\textbf{Particle set input}

\vspace{0mm}
Forecast ensemble is an unordered set:
\[
X^b = \{x_i^b\}_{i=1}^N
\]

\vspace{1mm}
Update must be \y{permutation invariant}:
\[
\mathcal{N}_\theta(\pi X^b,\;y)=\pi\,\mathcal{N}_\theta(X^b,\;y)
\]

\vspace{2mm}
\textbf{DeepSets structure}

\vspace{0mm}
\[
\phi(x_i,y)\;\rightarrow\;
\text{mean pool}\;\rightarrow\;
\rho(\cdot)\;\rightarrow\;
\psi(x_i,\text{context},y)
\]

\vspace{1mm}
\rtext{\bf Each particle sees local state + global context + obs.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize

{\tiny
\begin{verbatim}
class ParticleUpdateNN(nn.Module):
  def forward(self, Xb, y):
    N = Xb.shape[0]
    y_rep = y.expand(N, -1)

    emb = phi(torch.cat([Xb, y_rep], 1))
    pooled = emb.mean(0, keepdim=True)
    ctx = rho(pooled).expand(N, -1)

    dX = psi(torch.cat([Xb, ctx, y_rep], 1))
    return Xb + dX
\end{verbatim}
}

\vspace{-1mm}
\y{Output: updated ensemble $X^a$.}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec18.tex
% ================================================================================
% Lecture 18 — Slide 21
% ================================================================================
\begin{frame}[t, fragile]
\begin{tightmath}

\mytitle{Training Loss: Fit a Gaussian-Mixture Posterior}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.56\textwidth}
\footnotesize

\textbf{Posterior fitting objective}

\vspace{0mm}
Train the particle update network such that
the \y{analysis ensemble} represents the posterior:
\[
q^a(x)\;\approx\; p(x\mid y)
\]

\vspace{1mm}
\textbf{Gaussian mixture model}

\vspace{-2mm}
Particles define a mixture density:
\[
q(x\mid X)=\frac1N\sum_{i=1}^N\mathcal{N}(x\mid x^{(i)},\Sigma)
\]

\vspace{-1mm}
\textbf{Loss = likelihood + KL fit}

\vspace{-4mm}
\[
L
=
\underbrace{-\log\Big(\tfrac1N\sum_i p(y\mid x_i^a)\Big)}_{L_{\rm obs}}
+
\lambda_{\rm bg}\,
\underbrace{\mathrm{KL}\!\Big(q_{\rm target}(\cdot)\,\Vert\,q^a(\cdot)\Big)}_{L_{\rm GM}}
\]

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.40\textwidth}
\footnotesize

\vspace{-3mm}
{\tiny
\begin{verbatim}
# evaluation points (single Kalman update)
Z = kalman_eval_points(Xb, y)

# target posterior weights on Z
log_t = log_mix(Z|Xb) + log_like(y|Z)
w_t = softmax(log_t)

# model mixture log-density on Z
log_m = log_mix(Z|Xa)

# mixture KL term
L_GM = sum_z w_t(z) * (log w_t(z) 
	- log softmax(log_m(z)))
loss = L_obs + lambda_bg * L_GM
\end{verbatim}
}

\vspace{-1mm}
\y{Target uses prior mixture + obs likelihood.}

\vspace{4mm}
\centering
\rtext{\bf Learn the posterior distribution, not only the mean.}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec18.tex
% ================================================================================
% Lecture 18 — Slide 22
% ================================================================================
\begin{frame}[t, fragile]
\begin{tightmath}

\mytitle{Gaussian-Mixture PF: Comparing Two Distributions (Math)}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize

\textbf{1) Ensembles as Gaussian mixtures}

\vspace{0mm}
Forecast particles $X^b=\{x_i^b\}_{i=1}^N$ and analysis particles
$X^a=\{x_i^a\}_{i=1}^N$ define mixture densities, e.g.:
\vspace{-2mm}
\begin{equation*}
q^a_\theta(x)=\tfrac1N\sum_{i=1}^N \mathcal{N}(x\mid x_i^a,\Sigma)
\end{equation*}

\vspace{-1mm}
\textbf{2) Discretize comparison}

\vspace{0mm}
Choose evaluation points $Z=\{z_k\}_{k=1}^K$
(from a Kalman-type proposal step in the notebook).

\textbf{Target posterior on $Z$}

\vspace{-2mm}
\begin{equation*}
w^\star_k
=
\frac{q^b(z_k)\;p(y\mid z_k)}
     {\sum_{\ell=1}^K q^b(z_\ell)\;p(y\mid z_\ell)}
\end{equation*}

\vspace{-1mm}
\y{Prior mixture + obs likelihood $\Rightarrow$ posterior weights.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize

\textbf{3) Model distribution on $Z$}

\vspace{0mm}
Evaluate the analysis mixture on the same points and normalize:
\vspace{-2mm}
\begin{equation*}
\pi_{\theta,k}
=
\frac{q^a_\theta(z_k)}
     {\sum_{\ell=1}^K q^a_\theta(z_\ell)}
=
\mathrm{softmax}\!\big(\log q^a_\theta(z_k)\big)
\end{equation*}

\vspace{2mm}
\textbf{4) Fit posterior mass distribution}

\vspace{0mm}
Training minimizes the discrete KL divergence:
\vspace{-2mm}
\begin{equation*}
L_{\rm GM}
=
\mathrm{KL}(w^\star\;\|\;\pi_\theta)
=
\sum_{k=1}^K w^\star_k\;
\log\frac{w^\star_k}{\pi_{\theta,k}}
\end{equation*}

\vspace{-1mm}
\rtext{\bf Network learns to move particles toward posterior mass.}

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec18.tex
% ================================================================================
% Lecture 18 — Slide 23
% ================================================================================
\begin{frame}[t]

\mytitle{Ensemble Geometry: Prior $\rightarrow$ Analysis in a 2D Slice}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.30\textwidth}
\footnotesize

\vspace{-2mm}
\textbf{What the plot shows}

\vspace{0mm}
2D slice of the state space (e.g. $x_1$--$x_2$ plane).

\vspace{2mm}
\textbf{Prior (forecast ensemble)}

\vspace{0mm}
\begin{itemize}
  \item particles $X^b$ (cloud)
  \item prior mean $\bar{x}^b$
\end{itemize}

\vspace{1mm}
\textbf{Observation / truth}

\vspace{0mm}
\begin{itemize}
  \item observation $y$ (marker)
  \item truth $x_{\rm true}$ (marker)
\end{itemize}

\vspace{1mm}
\textbf{Analysis ensemble}

\vspace{0mm}
\begin{itemize}
  \item updated particles $X^a$
  \item analysis mean $\bar{x}^a$
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.68\textwidth}

\centering
\vspace{-4mm}
\hspace*{-0.5cm}
\begin{minipage}{10cm}
\includegraphics[width=\textwidth]{../../images/img18/f_ensemble_scatter_step_0022.png}
\end{minipage}

\vspace{-2mm}
\tiny
Prior ensemble (forecast) and analysis ensemble after the 
learned update.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec18.tex
% ================================================================================
% Lecture 18 — Slide 24
% ================================================================================
\begin{frame}[t]

\mytitle{Ablation: Why the Background / Posterior-Fit Term Matters}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.30\textwidth}
\footnotesize

\textbf{Two trained networks}

\vspace{0mm}
\begin{itemize}
  \item \y{\bf net}: full AI-PF loss
  \item \y{\bf net\_obs}: obs term only
\end{itemize}

\vspace{2mm}
\textbf{Metric shown}

\vspace{0mm}
Difference of first-guess error:
\[
\Delta
=
{\rm FG}_{\rm err}(\texttt{net\_obs})
-
{\rm FG}_{\rm err}(\texttt{net})
\]

\vspace{2mm}
\textbf{Interpretation}

\vspace{0mm}
\begin{itemize}
  \item \y{$\Delta>0$ (green)}: net is better
  \item $\Delta<0$ (red): net\_obs is better
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.68\textwidth}

\centering
\vspace{-4mm}
\hspace*{0cm}
\begin{minipage}{9cm}
\includegraphics[width=\textwidth]{../../images/img18/fg_error_diff_netobs_minus_net.png}
\end{minipage}

\vspace{1mm}
\footnotesize
Evaluation over 10\,000 assimilation cycles after short training.

\includegraphics[width=5cm]{../../images/img18/fg_error_diff_10000.png}



\end{column}

\end{columns}

\end{frame}
%!TEX root = lec18.tex
% ================================================================================
% Lecture 18 — Slide 25
% ================================================================================
\begin{frame}[t]

\mytitle{Summary: Two AI Paths for Data Assimilation}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\textbf{AI-Var (Keller \& Potthast)}

\y{\bf What it learns:}

\vspace{-3mm}
\[
(x_b,\;y)\;\mapsto\; x_a
\]

\vspace{0mm}
\begin{itemize}
  \item neural network approximates the minimizer
  \item trained by variational cost $J(x)$
  \item output = \y{one deterministic analysis field}
\end{itemize}

\vspace{2mm}
\y{\bf Strengths}
\begin{itemize}
  \item stable, structured increments
  \item scalable in dimension (1D $\rightarrow$ 2D demo)
  \item direct link to operational 3D/4D-Var
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\vspace{-3mm}
\textbf{AI Particle Filter (Gaussian mixture)}

\y{\bf What it learns:}

\vspace{-2mm}
\[
(X^b,\;y)\;\mapsto\; X^a
\]

\vspace{0mm}
\begin{itemize}
  \item neural update transforms particle cloud
  \item trained to fit posterior mass distribution
  \item output = \y{analysis distribution (ensemble)}
\end{itemize}

\vspace{2mm}
\y{\bf Strengths}
\begin{itemize}
  \item non-Gaussian posteriors (multi-modal)
  \item distribution-aware filtering
  \item background-term ablation shows skill gain
\end{itemize}

\end{column}

\end{columns}

\vspace{4mm}
\rtext{\bf Take-home: AI-Var learns the analysis; AI-PF learns a posterior distribution.}

\end{frame}
% ================================================================================
% E-AI Tutorial Slides
% Filename: lec18.tex
%
% Roland Potthast 2025/2026
% Licence: CC-BY4.0
% ================================================================================
\documentclass[aspectratio=169]{beamer}

% --- Load lecture macros --------------------------------------------------------
\input{../lec_macros.tex}
\newcommand{\LectureNumber}{Lecture 18}

% --- Document -------------------------------------------------------------------
\begin{document}

\setagendaboxforlecture{18}

\input{../lec_agenda.tex}
\input{lec18_01.tex}
\input{lec18_02.tex}
\input{lec18_03.tex}
\input{lec18_04.tex}
\input{lec18_05.tex}
\input{lec18_06.tex}
\input{lec18_07.tex}
\input{lec18_08.tex}
\input{lec18_09.tex}
\input{lec18_10.tex}
\input{lec18_11.tex}
\input{lec18_12.tex}
\input{lec18_13.tex}
\input{lec18_14.tex}
\input{lec18_15.tex}
\input{lec18_16.tex}
\input{lec18_17.tex}
\input{lec18_18.tex}
\input{lec18_19.tex}
\input{lec18_20.tex}
\input{lec18_21.tex}
\input{lec18_22.tex}
\input{lec18_23.tex}
\input{lec18_24.tex}
\input{lec18_25.tex}

% --- End Document ---------------------------------------------------------------
\end{document}
%!TEX root = lec19.tex
% ================================================================================
% Lecture 19 — Slide 01
% ================================================================================

\begin{frame}[t,fragile]

\mytitle{Lecture 19: AI and Physics and Data}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.54\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{Core question}

Given a dynamical system, what can machine learning do?

\vspace{1mm}
\begin{itemize}
  \item Solve known equations (ODE/PDE)
  \item Discover unknown governing laws from observations
  \item Emulate complex dynamics as a surrogate model
\end{itemize}

\vspace{3mm}
\textbf{Unifying viewpoint}

All methods impose (explicitly or implicitly) a constraint:

\rtext{\bf state evolution must be consistent with } $\dot{\mathbf{x}} = \mathbf{f}(\mathbf{x})$.


\vspace{3mm}
How can different ML approaches enforce this consistency?

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.42\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{Three routes in this lecture}

\begin{enumerate}
  \item \textbf{PINNs:} \y{physics drives training}
  \item \textbf{SINDy:} \y{sparse laws from data}
  \item \textbf{Neural RHS learning:} \y{black-box emulation}
\end{enumerate}

\vspace{2mm}
\textbf{Key trade-offs}

\begin{itemize}
  \item Accuracy vs.\ interpretability
  \item Data-efficiency vs.\ flexibility
  \item Stability / extrapolation vs.\ expressiveness
\end{itemize}

\vspace{2mm}
\rtext{\bf Message:} \\
same goal (dynamics), different framework.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec19.tex
% ================================================================================
% Lecture 19 — Slide 02
% ================================================================================

\begin{frame}[t,fragile]

\mytitle{Lecture Roadmap}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{Part I — Physics-Informed Neural Networks}

\vspace{1mm}
\begin{itemize}
  \item learn \y{solutions} of known equations
  \item training uses \y{ODE/PDE residuals} + anchor conditions
  \item representation matters for extrapolation
\end{itemize}

\vspace{3mm}
\textbf{Part II — Discovering equations from data}

\vspace{1mm}
\begin{itemize}
  \item \textbf{SINDy:} sparse regression on a function library
  \item \textbf{Neural SINDy:} smooth NN trajectory $\Rightarrow$ stable derivatives
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize
\vspace{-9mm}

\textbf{Part III — Learning the Force Term}

\vspace{1mm}
\begin{itemize}
  \item learn the unknown RHS / forcing from data:
  \[
  \dot{\mathbf{x}} = \mathbf{f}(\mathbf{x}) + \mathbf{g}_\theta(\mathbf{x})
  \]
  \item \y{hybrid modeling:} known physics + learned closure
  \item stable rollout by integrating the learned system
\end{itemize}

\vspace{2mm}
\textbf{Part IV — Causal Modeling with Neural Networks}

\vspace{1mm}
\begin{itemize}
  \item distinguish \y{correlation} vs.\ \y{cause}
  \item learn structural relations (SCMs) as NN modules
  \item intervene and test counterfactual predictions:
  \[
  do(X=x)
  \quad\Rightarrow\quad
  p(Y\,|\,do(X=x))
  \]
\end{itemize}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec19.tex
% ================================================================================
% Lecture 19 — Slide 03
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{A Minimal Physics-Informed Neural Network (PINN)}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\footnotesize

\textbf{Problem setup}

We consider a simple second-order ODE:
\[
y''(x) + y(x) = 0
\]

with boundary conditions
\[
y(0) = 0, \qquad y'(0) = 1.
\]

\vspace{2mm}
The unique solution is
\[
y(x) = \sin(x).
\]

\vspace{2mm}
This example is deliberately \y{simple}, but already
captures all essential PINN ingredients.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\textbf{PINN idea}

\begin{itemize}
  \item Approximate $y(x)$ by a neural network $y_\theta(x)$
  \item \y{No training data} $y(x)$ are used
  \item Training is driven by \y{physics constraints}
\end{itemize}

\vspace{2mm}
\textbf{What is enforced}

\begin{itemize}
  \item Differential equation via automatic differentiation
  \item Boundary conditions via penalty terms
\end{itemize}

\vspace{2mm}
\rtext{\bf The network learns the solution by minimizing violations of physics.}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec19.tex
% ================================================================================
% Lecture 19 — Slide 04
% ================================================================================
\begin{frame}[t,fragile]

\mytitle{PINN Loss: Physics Instead of Data}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize

\textbf{ODE residual}

Using automatic differentiation, we compute
\[
y_\theta'(x), \qquad y_\theta''(x).
\]

The differential equation is enforced by minimizing
\[
r(x) = y_\theta''(x) + y_\theta(x).
\]

The corresponding loss term is
\[
\mathcal{L}_{\text{ODE}}
=
\frac{1}{N}
\sum_{i=1}^N
\bigl( y_\theta''(x_i) + y_\theta(x_i) \bigr)^2.
\]

\vspace{2mm}
Collocation points $x_i$ are sampled in the domain.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize

\vspace{-4mm}
\textbf{Boundary conditions}

Boundary (anchor) constraints enforce uniqueness:
\[
y_\theta(0) = 0,
\qquad
y_\theta'(0) = 1.
\]

This yields the boundary loss
\[
\mathcal{L}_{\text{BC}}
=
\bigl( y_\theta(0) \bigr)^2
+
\bigl( y_\theta'(0) - 1 \bigr)^2.
\]

\vspace{2mm}
\textbf{Total loss}

The parameter $\lambda$ controls the \y{strength of the boundary conditions.}

\[
\mathcal{L}
=
\mathcal{L}_{\text{ODE}}
+
\lambda\,\mathcal{L}_{\text{BC}}.
\]


\vspace{2mm}
\rtext{\bf No data term appears anywhere in the loss.}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec19.tex
% ================================================================================
% Lecture 19 — Slide 05
% ================================================================================
\begin{frame}[t]

\mytitle{PINN Result: Naive Training, Extended Evaluation}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\textbf{Training setup}

\begin{itemize}
  \item ODE residual enforced on $[0,\,2\pi]$
  \item Boundary conditions at $x=0$
  \item No data, no periodic constraints
  \item Standard MLP representation
\end{itemize}

\vspace{2mm}
\textbf{Evaluation}

\begin{itemize}
  \item Solution evaluated on a \y{larger domain}
  \item Outside the region where physics was enforced
\end{itemize}

\vspace{2mm}
\rtext{\bf This tests extrapolation, not interpolation.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}

\centering
\vspace{-4mm}
\includegraphics[width=5.5cm]{../../images/img19/pinn_sine_1_crop.png}

\vspace{-2mm}

\includegraphics[width=5.6cm]{../../images/img19/pinn_sine_2_crop.png}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec19.tex
% ================================================================================
% Lecture 19 — Slide 06
% ================================================================================
\begin{frame}[t]

\mytitle{Improving Extrapolation by Wider Residual Sampling}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\footnotesize

\textbf{Key modification}

The PINN formulation is unchanged, but the
\y{ODE residual is enforced on a wider domain}.

\vspace{2mm}
\textbf{Training setup}

\begin{itemize}
  \item ODE residual sampled beyond $[0,\,2\pi]$
  \item Boundary conditions still imposed at $x=0$
  \item Same network architecture and loss terms
\end{itemize}

\vspace{2mm}
\textbf{Effect}

\begin{itemize}
  \item Physics is enforced more \y{globally}
  \item Extrapolation becomes significantly more stable
  \item No change in representation or constraints
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\centering
\vspace{-2mm}

\includegraphics[width=\textwidth]{../../images/img19/pinn_sine_3.png}


\vspace{2mm}
\rtext{ This already fixes many extrapolation problems for simple ODEs.}


\end{column}

\end{columns}

\end{frame}
%!TEX root = lec19.tex
% ================================================================================
% Lecture 19 — Slide 07
% ================================================================================
\begin{frame}[t]

\mytitle{Improving Representation with Fourier Features}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.49\textwidth}
\footnotesize

\vspace{-2mm}
\textbf{Motivation}

Standard MLPs learn functions of $x$ that are biased toward
\y{smooth, slowly varying behavior}.

\vspace{2mm}
Oscillatory solutions, such as
\[
y(x) = \sin(x),
\]
are therefore harder to represent and extrapolate.

\vspace{2mm}
\textbf{Fourier feature idea}

Instead of learning directly from $x$, we apply a fixed
\y{feature map}:
\[
x \;\mapsto\;
\bigl(
\sin(\omega_k x),\;
\cos(\omega_k x)
\bigr)_{k=1}^m.
\]

\vspace{2mm}
The neural network then learns a function
of these periodic features.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize
\centering
\vspace{-3mm}

\includegraphics[width=6cm]{../../images/img19/pinn_sine_4.png}

\vspace{0mm}
\raggedright
\textbf{Effect on the PINN}

\begin{itemize}
  \item Periodicity is \y{easy to represent}
  \item Long-range extrapolation improves
  \item Fewer parameters are needed
\end{itemize}

\vspace{0mm}
\textbf{Interpretation}

\begin{itemize}
  \item Linear models become \y{Fourier series fits}
  \item Nonlinear MLPs allow mode interactions
\end{itemize}

\vspace{0mm}
\rtext{\bf This changes the representation, not the physics.}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec19.tex
% ================================================================================
% Lecture 19 — Slide 08
% ================================================================================
\begin{frame}[t]

\mytitle{Result: Fourier-Feature PINN for a Modulated Oscillation}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\textbf{What changed compared to previous examples}

\begin{itemize}
  \item Governing ODE and anchor conditions unchanged
  \item Same PINN loss formulation
  \item \y{Only the input representation is modified}
\end{itemize}

\vspace{2mm}
The network uses a Fourier feature embedding.

\vspace{2mm}
\textbf{Observed behavior}

\begin{itemize}
  \item Accurate solution on the training domain $[0,\,5\pi]$
  \item \y{Stable extrapolation} far beyond the training region
  \item Correct phase and amplitude over many oscillations
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\centering
\vspace{-2mm}

\includegraphics[width=\textwidth]{../../images/img19/pinn_sine_cosine.png}

\vspace{2mm}
\raggedright
\footnotesize
Gray shading indicates the training domain.
The solution is evaluated well beyond the region where the ODE residual
was enforced.


\vspace{2mm}
\rtext{\bf Representation choice alone can control extrapolation quality.}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec19.tex
% ================================================================================
% Lecture 19 — Slide 09
% ================================================================================
\begin{frame}[t]

\mytitle{SINDy: Sparse Identification of Nonlinear Dynamics}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize

\vspace{-2mm}
\textbf{Problem setting}

We observe a dynamical system
\[
\dot{\mathbf{x}}(t) = \mathbf{f}(\mathbf{x}(t)),
\qquad
\mathbf{x}(t)\in\mathbb{R}^n,
\]
from time series data $\mathbf{x}(t_i)$.

\vspace{2mm}
\textbf{Key assumption (sparsity)}

The vector field can be written as a sparse combination of candidate functions:
\[
\dot{\mathbf{x}}(t)
\;\approx\;
\Theta(\mathbf{x}(t))\,\Xi,
\]
where
\begin{itemize}
  \item $\Theta(\mathbf{x})$ is a library of functions
        (e.g.\ $1, x, y, z, xy, xz, yz,\dots$),
  \item $\Xi$ is a \y{sparse coefficient matrix}.
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.55\textwidth}

\vspace{-2mm}
\textbf{Identification}

SINDy solves a sequence of
\[
\min_{\Xi}\;\|\Theta(\mathbf{x})\Xi-\dot{\mathbf{x}}\|_2^2
\]
with thresholding to eliminate small coefficients.


\includegraphics[width=\textwidth]{../../images/img19/SINDy_01.png}

\vspace{-3mm}
\raggedright
\footnotesize
\textbf{Lorenz--63 example (noise-free).}

Left: true trajectory.  
Right: trajectory from \emph{SINDy}.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec19.tex
% ================================================================================
% Lecture 19 — Slide 10
% ================================================================================
\begin{frame}[t, fragile]

\mytitle{SINDy Sparse Regression of Nonlinear Dynamics: Lorenz--63 System}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\footnotesize

\vspace{-2mm}
\textbf{True governing equations}

The Lorenz--63 system is defined by
\[
\begin{aligned}
\dot{x} &= \sigma (y - x), \\
\dot{y} &= x(\rho - z) - y, \\
\dot{z} &= x y - \beta z,
\end{aligned}
\qquad
\begin{minipage}{3cm}$
\sigma=10, \\ 
\rho=28, \\
\beta=\tfrac{8}{3}.
$
\end{minipage}
\]

\vspace{0mm}
\textbf{SINDy function library}

SINDy assumes the dynamics can be written as a sparse linear combination of
candidate functions:

\begin{lstlisting}[basicstyle=\ttfamily\scriptsize]
Theta(x,y,z) = [  1,  x, y, z,
                      x*y, x*z, y*z ]
\end{lstlisting}

Only a few of these terms are retained in each equation after sparse
regression.

\vspace{2mm}
\rtext{\bf Goal:} \y{recover the correct active terms} and coefficients
directly from time series data.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\centering
\vspace{-2mm}

\includegraphics[width=6cm]{../../images/img19/sindy_timeseries.png}

\vspace{2mm}
\raggedright
\footnotesize
Time series of the Lorenz--63 state variables used as input for SINDy
{\color{blue}(blue)}.
Numerical derivatives are estimated and matched against the candidate
library during sparse regression. \color{darkgreen}
Discovered dynamics evolution in Green.

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec19.tex
% ================================================================================
% Lecture 19 — Slide 11
% ================================================================================
\begin{frame}[t]
\begin{tightmath}

\mytitle{Neural SINDy: Using Neural Networks as Smooth Surrogates}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize
\vspace{-2mm}

Neural SINDy augments classical SINDy by introducing a neural network
as a smooth surrogate for the observed trajectory:
\[
\mathbf{x}(t)\;\longrightarrow\;\mathbf{x}_\theta(t).
\]

The neural network is trained on noisy observations
$\mathbf{x}_{\text{obs}}(t_i)$, \rtext{but constrained to produce a
\emph{smooth time-continuous representation}}.

\vspace{0mm}
\textbf{Neural trajectory fitting}

The network parameters $\theta$ are obtained by minimizing

\vspace{-4mm}
\[
\min_{\theta}
\sum_i \|\mathbf{x}_\theta(t_i)-\mathbf{x}_{\text{obs}}(t_i)\|^2
\;+\;
\alpha \int \Bigl\|\tfrac{d}{dt}\mathbf{x}_\theta(t)\Bigr\|^2\,dt.
\]

\vspace{-2mm}
A \y{regularization term} penalizes rapid temporal variations and suppresses
noise amplification.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{Derivative estimation via autograd}

Once trained, time derivatives are computed analytically:
\[
\dot{\mathbf{x}}_\theta(t)
=
\frac{d}{dt}\mathbf{x}_\theta(t),
\]
using automatic differentiation.

\vspace{2mm}
\textbf{Sparse discovery step}

The smoothed trajectory and its derivatives are then passed to the
\emph{unchanged} SINDy pipeline:
\[
\dot{\mathbf{x}}_\theta(t)\;\approx\;\Theta(\mathbf{x}_\theta(t))\,\Xi,
\qquad \Xi\ \text{sparse}.
\]

\vspace{-2mm}
\rtext{\bf Here:}

Neural networks are \emph{not} used to represent the dynamics,
but only to \y{stabilize} \y{derivative} \y{estimation} prior to sparse regression.

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec19.tex
% ================================================================================
% Lecture 19 — Slide 13
% ================================================================================
\begin{frame}[t]

\mytitle{Neural SINDy: Results on Noisy Lorenz--63 Data}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.35\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{Experimental setup}

\begin{itemize}
  \item Lorenz--63 system
  \item Strong additive noise on observations
  \item Identical SINDy library and sparsity settings
\end{itemize}

\vspace{2mm}
\textbf{Comparison}

\begin{itemize}
  \item Classical SINDy: finite-difference derivatives
  \item Neural SINDy: NN-smoothed trajectory + autograd
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.63\textwidth}
\centering
\vspace{-2mm}

\includegraphics[width=\textwidth]{../../images/img19/neural_sindy_comparison.png}

\vspace{-2mm}
\raggedright
\footnotesize
Comparison of trajectories, derivatives, and predictions for
classical vs.\ Neural SINDy on noisy data.

\end{column}

\end{columns}

\vspace{0mm}
\textbf{Outcome}

\begin{itemize}
  \item Neural SINDy recovers an improved equation structure
\end{itemize}


\end{frame}
%!TEX root = lec19.tex
% ================================================================================
% Lecture 19 — Slide 13
% ================================================================================
\begin{frame}[t]

\begin{tightmath}

\mytitle{Alternative: Learning the Full RHS with Neural Networks}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize

\vspace{-2mm}
\textbf{Black-box RHS learning}

Instead of discovering equations, one may directly learn the vector field
\[
\dot{\mathbf{x}} = \mathbf{f}_\theta(\mathbf{x}),
\]
where $\mathbf{f}_\theta$ is a neural network.


\vspace{4mm}
The network is trained to match observed time derivatives or trajectories.

\begin{itemize}
  \item Very flexible function class
  \item \y{Can approximate complex, unknown} \y{dynamics}
  \item Naturally handles noise with regularization
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize
\vspace{0mm}

\textbf{Neural SINDy: a different goal}

Neural SINDy uses neural networks only to stabilize intermediate steps
(denoising and differentiation), but still identifies
\[
\dot{\mathbf{x}} \approx \Theta(\mathbf{x})\,\Xi,
\]
with a sparse, explicit structure.

\vspace{4mm}
\rtext{\bf Key distinction:}

\begin{itemize}
  \item Neural RHS learning $\rightarrow$ \y{predictive black box}
  \item Neural SINDy $\rightarrow$ \emph{interpretable equations}
\end{itemize}

\vspace{0mm}
This distinction is critical in scientific modeling, where the goal
is understanding, not only prediction.

\end{column}

\end{columns}

\end{tightmath}

\end{frame}
%!TEX root = lec19.tex
% ================================================================================
% Lecture 19 — Slide 14
% ================================================================================
\begin{frame}[t]

\mytitle{Neural \y{RHS Learning}: Results on Lorenz--63}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.54\textwidth}
\footnotesize

\vspace{-2mm}
\textbf{Experimental setup}

\begin{itemize}
  \item Lorenz--63 system
  \item Neural network trained on $(\mathbf{x},\dot{\mathbf{x}})$ pairs
  \item No sparsity or physics constraints
\end{itemize}

\vspace{0mm}
\textbf{Observations}

\begin{itemize}
  \item Learned vector field ${\bf f_{\theta}}$ reproduces the chaotic attractor
  \item Short- to medium-term trajectories remain accurate, \rtext{\bf climatology ok!}
  \item Long-term divergence is unavoidable due to chaos
\end{itemize}

\vspace{0mm}
\rtext{\bf Interpretation:}

The neural network successfully emulates the dynamics,
but the \y{governing equations remain hidden.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}
\centering

\vspace{-8mm}
\includegraphics[width=6cm]{../../images/img19/rhs_learning1.png}

\vspace{2mm}

\includegraphics[width=6cm]{../../images/img19/rhs_learning2.png}


\end{column}

\end{columns}

\end{frame}
%!TEX root = lec19.tex
% ================================================================================
% Lecture 19 — Slide 15
% ================================================================================
\begin{frame}[t]

\mytitle{Neural RHS Learning in State Space}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.51\textwidth}

\footnotesize
\vspace{-2mm}

\textbf{Experimental setup}

\begin{itemize}
  \item Lorenz--63 vector field \y{sampled in state space}
  \item Random training points covering a 3D domain
  \item Neural network trained on $(\mathbf{x},\dot{\mathbf{x}})$ pairs
\end{itemize}

\vspace{0mm}
\textbf{Key difference to trajectory-based learning}

\begin{itemize}
  \item Training data no longer restricted to the attractor
  \item Vector field is constrained in a full region of state space
  \item Dynamics are learned as a global mapping
\end{itemize}

\vspace{0mm}
\rtext{\bf Outcome:}

The learned neural vector field reproduces the Lorenz dynamics
consistently from unseen initial conditions, not only along the
original trajectory.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\centering
\vspace{-8mm}

\includegraphics[width=8cm]{../../images/img19/rhs_learning_space_sampling_crop.png}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec19.tex
% ================================================================================
% Lecture 19 — Slide 16
% ================================================================================
\begin{frame}[t]
\begin{tightmath}

\mytitle{Learning Dynamical Systems: Goals and Methods}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}


\footnotesize
\vspace{-2mm}

\textbf{Three fundamentally different goals}

\vspace{0mm}
\begin{itemize}
  \item \rtext{\bf \y{Solve known equations}}
  \begin{itemize}
    \item Given: governing ODE/PDE
    \item Task: compute the solution
    \item Method: \textbf{PINNs}
  \end{itemize}

  \vspace{0mm}
  \item \rtext{\bf \y{Discover equations from data}}
  \begin{itemize}
    \item Given: time series observations
    \item Task: identify governing laws
    \item Method: \textbf{SINDy / Neural SINDy}
  \end{itemize}

  \vspace{0mm}
  \item \rtext{\bf \y{Emulate dynamics}}
  \begin{itemize}
    \item Given: state–derivative pairs
    \item Task: reproduce system behavior
    \item Method: \textbf{Neural RHS learning}
  \end{itemize}
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}

\footnotesize
\vspace{-2mm}

\textbf{What is learned in each case?}

\vspace{1mm}
\begin{itemize}
  \item \textbf{PINNs}
  \begin{itemize}
    \item learn the \emph{solution} $x(t)$
    \item equations are assumed known
  \end{itemize}

  \vspace{0mm}
  \item \textbf{SINDy / Neural SINDy}
  \begin{itemize}
    \item learn \emph{explicit equations}
    \item sparse, interpretable models
  \end{itemize}

  \vspace{0mm}
  \item \textbf{Neural RHS learning}
  \begin{itemize}
    \item learn a \emph{vector field}
    \item accurate dynamics, but opaque
  \end{itemize}
\end{itemize}

\vspace{2mm}
\rtext{\bf Key trade-off:}

Interpretability \;\;\(\leftrightarrow\)\;\; Flexibility

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec19.tex
% ================================================================================
% Lecture 19 — Slide 17
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Physics-Constrained Neural Emulators: 1D Periodic Advection}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize
\vspace{-2mm}

We consider \y{1D linear advection} on a periodic domain:

\vspace{-4mm}
\[
\partial_t u + c\,\partial_x u = 0,
\qquad x \in [0,1], \;\; u(0)=u(1).
\]

\vspace{0mm}
Key physical properties:
\begin{itemize}
  \item Pure \y{translation on a ring}
  \item Exact \y{mass conservation}
  \item Smooth initial conditions remain smooth
\end{itemize}

\vspace{1mm}
\textbf{Learning task}

\begin{itemize}
  \item Learn a one-step map \y{$u^n \mapsto u^{n+1}$}
  \item Training data from a conservative upwind solver
  \item Compare different neural inductive biases
\end{itemize}


\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\centering
\vspace{-3mm}

\includegraphics[width=\textwidth]{../../images/img19/Advection_Periodic_Truth.png}

\vspace{1mm}
\raggedright
\footnotesize
\textbf{Reference solution (truth).}

Gaussian bump advected periodically.
Snapshots at $t=0,30,60$ clearly show wrap-around and mass preservation.

\vspace{4mm}
\rtext{\bf Physics is simple — but violations are immediately visible.}


\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec19.tex
% ================================================================================
% Lecture 19 — Slide 18
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{CNN Emulator without Mass Conservation}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{Neural model}

\begin{itemize}
  \item Local 1D CNN with \y{circular padding}
  \item Learns one-step map $u^n \mapsto u^{n+1}$
  \item Trained by minimizing one-step MSE
\end{itemize}

\vspace{0mm}
\textbf{What is \rtext{not} enforced}

\begin{itemize}
  \item No mass conservation constraint
  \item No global invariant control
\end{itemize}

\vspace{0mm}
\textbf{Observed behavior}

\begin{itemize}
  \item \y{Low training loss}
  \item Smooth short-term evolution
  \item \rtext{Gradual drift in total mass}
\end{itemize}

\vspace{0mm}
\rtext{\bf Locality alone is not enough to guarantee physical correctness.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\centering
\vspace{-4mm}

\includegraphics[width=0.9\textwidth]{../../images/img19/Advection_Periodic_CNN_3_0.png}

\vspace{-2mm}

\includegraphics[width=0.9\textwidth]{../../images/img19/Advection_Periodic_CNN_3_60.png}

\vspace{0mm}
\raggedright
\footnotesize
\textbf{CNN without conservation.}
Small amplitude and mass errors accumulate despite visually plausible transport.

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec19.tex
% ================================================================================
% Lecture 19 — Slide 19
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{CNN Emulator with Exact Mass Conservation}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{Conservative update}

The CNN predicts a residual update
\[
u^{n+1} = u^n + \Delta u,
\]
with the constraint $\sum_i \Delta u_i = 0$.

\vspace{-1mm}
\begin{itemize}
  \item \rtext{\bf Mass conservation enforced \y{by construction}}
  \item Same architecture and data as unconstrained CNN
  \item No penalty tuning required
\end{itemize}

\vspace{0mm}
\textbf{Effect}

\begin{itemize}
  \item Slightly higher one-step loss
  \item \y{Exact preservation of the global invariant}
  \item Significantly improved long-term behavior
\end{itemize}


\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\centering
\vspace{-3mm}

\includegraphics[width=\textwidth]{../../images/img19/Advection_Periodic_CNN_Mass_Conservation_Test1.png}

\vspace{1mm}

\includegraphics[width=0.9\textwidth]{../../images/img19/Advection_Periodic_CNN_4_60.png}

\vspace{1mm}
\raggedright
\footnotesize
\textbf{CNN with mass conservation.}
The global invariant is preserved exactly.

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec19.tex
% ================================================================================
% Lecture 19 — Slide 20
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Long-Time Rollout: Accuracy vs Physical Validity}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{Long-time test}

\begin{itemize}
  \item Rollout over hundreds of time steps
  \item Same initial condition
  \item Compare truth, CNN-free, CNN-conservative
\end{itemize}

\vspace{1mm}
\textbf{Key observation}

\begin{itemize}
  \item CNN-free: errors accumulate steadily
  \item CNN-conservative: structure remains coherent
  \item Physics constraints matter most \y{far beyond training horizon}
\end{itemize}

\vspace{2mm}
{\bf Short-term accuracy is not a proxy for long-term validity.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\centering
\vspace{-3mm}

\includegraphics[width=0.9\textwidth]{../../images/img19/Advection_Periodic_CNN_Long_0.png}

\vspace{-1mm}

\includegraphics[width=0.9\textwidth]{../../images/img19/Advection_Periodic_CNN_Long_600.png}

\vspace{1mm}
\raggedright
\footnotesize
\rtext{\bf Only the conservative model maintains physically consistent transport.}

\end{column}

\end{columns}


\end{tightmath}
\end{frame}
%!TEX root = lec19.tex
% ================================================================================
% Lecture 19 — Slide 21
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Generalization: Advection of Unseen Shapes}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{What was trained}

\begin{itemize}
  \item CNN emulator trained only on \y{Gaussian initial conditions}
  \item Local architecture with \y{periodic padding}
  \item Conservative variant enforces exact mass preservation
\end{itemize}

\vspace{1mm}
\textbf{We test:} Sine waves, Top-hat functions (discontinuous), Multiple separated bumps.

\vspace{1mm}
\textbf{What we observe}

\begin{itemize}
  \item Correct \y{translation on the periodic domain}
  \item Shapes are transported without spurious creation or loss of mass
  \item Superpositions (multiple bumps) are handled consistently
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}
\centering
\vspace{-8mm}

\includegraphics[width=0.7\textwidth]{../../images/img19/Advection_Periodic_CNN_B_3_60.png}

\vspace{-1mm}

\includegraphics[width=0.7\textwidth]{../../images/img19/Advection_Periodic_CNN_B_2_60.png}

\vspace{-1mm}

\includegraphics[width=0.7\textwidth]{../../images/img19/Advection_Periodic_CNN_B_4_60.png}

\vspace{1mm}
\raggedright
\footnotesize
Examples of \y{\rtext{\bf unseen initial conditions}} advected by the CNN emulator.


\end{column}

\end{columns}


\end{tightmath}
\end{frame}
%!TEX root = lec19.tex
% ================================================================================
% Lecture 19 — Slide 22
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Correlation vs Causality in Dynamical Systems}

\footnotesize

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\vspace{-2mm}

\textbf{The trap}

\begin{itemize}
  \item Many variables in geosciences are \y{strongly correlated}
  \item But correlation alone cannot identify \y{directionality}
  \item Hidden drivers (\y{confounders}) can create spurious links
\end{itemize}

\vspace{0mm}
\textbf{Causal question}

\vspace{-2mm}
\[
P(T\,|\,P) \quad \neq \quad P\bigl(T\,|\,do(P)\bigr)
\]

\vspace{-1mm}
\textbf{Why time series are special}

\begin{itemize}
  \item Dynamics introduce \y{time ordering}
  \item Causal effects typically appear with \y{lags}
  \item Strong autocorrelation can mask cross-effects
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\vspace{-2mm}

\textbf{Key idea}

\begin{itemize}
  \item Use \y{lagged dependencies} to separate:
  \begin{itemize}
    \item self-dynamics (memory)
    \item cross-variable influences
  \end{itemize}
\end{itemize}

\vspace{2mm}
\textbf{In Earth-system applications this matters because}

\begin{itemize}
  \item interventions (what-if) require causal structure
  \item attribution needs confounding control
  \item robust extrapolation benefits from causal mechanisms
\end{itemize}

\vspace{0mm}
\rtext{\bf Take-home message:}

\vspace{-4mm}
\[
\text{\rtext{similar correlations} do not imply \rtext{same physics}}
\]

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec19.tex
% ================================================================================
% Lecture 19 — Slide 23
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Two Physical Processes Behind the Same Correlation}

\footnotesize

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\vspace{2mm}

\textbf{Scenario 1: direct causal coupling}

\begin{itemize}
  \item Pressure evolves under synoptic forcing
  \item Temperature responds via adiabatic processes
\end{itemize}

\vspace{1mm}
\[
\frac{dP}{dt} = -\gamma_P(P - P_{eq}) + \beta_P F(t)
\]
\vspace{-1mm}
\[
\frac{dT}{dt} = -\gamma_T(T - T_{eq}) + \rtext{\alpha(P-P_{eq})}
\]

\vspace{1mm}
\rtext{\bf True causal link:} \y{$P \rightarrow T$}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\vspace{2mm}

\textbf{Scenario 2: common external forcing}

\begin{itemize}
  \item Air-mass advection drives both variables
  \item No direct physical coupling between $P$ and $T$
\end{itemize}

\vspace{1mm}
\[
\frac{dP}{dt} = -\gamma_P(P - P_{eq}) + \beta_P F(t)
\]
\vspace{-1mm}
\[
\frac{dT}{dt} = -\gamma_T(T - T_{eq}) + \beta_T F(t)
\]

\vspace{1mm}
\rtext{\bf No direct causal link:} \y{$P \not\rightarrow T$}

\end{column}

\end{columns}

\vspace{5mm}
\rtext{\bf Both scenarios can show similar $P$--$T$ correlation — but they are physically different.}

\end{tightmath}
\end{frame}
%!TEX root = lec19.tex
% ================================================================================
% Lecture 19 — Slide 24
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Baseline: Classical Statistical Causal Analysis}

\footnotesize

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\vspace{-2mm}

\textbf{Naive statistical analysis}

\begin{itemize}
  \item correlation: $\mathrm{corr}(P,T)$
  \item regression: $T \sim P$
\end{itemize}

\vspace{2mm}
\textbf{Problem}

\begin{itemize}
  \item in Scenario 2, regression suggests \y{$P\rightarrow T$}
  \item but correlation is \y{spurious} (confounded by $F$)
\end{itemize}

\vspace{2mm}
\textbf{Improvement (if forcing known)}

\begin{itemize}
  \item control for confounder:
  \[
  T \sim P + F
  \]
  \item can recover causal effect if model is correct
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\vspace{-2mm}
\centering

\includegraphics[width=\textwidth]{../../images/img19/causal_timeseries_dynamics.png}

\vspace{1mm}
\raggedright
\footnotesize
\textbf{Simulation diagnostics.}
Time series + scatter: naive regression can be misleading when $F(t)$ induces
common variability.

\vspace{1mm}
\rtext{\bf Limitation:}
Confounders must be known and included (strong prior assumptions).

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec19.tex
% ================================================================================
% Lecture 19 — Slide 25
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Causal Discovery from Time Series: PCMCI (Classical Method)}

\footnotesize

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\vspace{-2mm}

\textbf{Goal}

\begin{itemize}
  \item learn the directed graph from multivariate time series
  \item distinguish:
  \begin{itemize}
    \item \y{direct causal links}
    \item \y{common forcing} and confounding
  \end{itemize}
\end{itemize}

\vspace{0mm}
\textbf{PCMCI in one line}

\begin{itemize}
  \item PC algorithm + conditional independence tests
  \item works with lagged dependencies
  \item reduces false links by conditioning on relevant parents
\end{itemize}

\vspace{-1mm}
\rtext{\bf Important:} PCMCI is \y{statistical causal discovery}, not neural.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\vspace{-2mm}
\centering

\includegraphics[width=\textwidth]{../../images/img19/causal_pcmci_graphs.png}

\vspace{1mm}
\raggedright
\footnotesize
\textbf{Discovered graphs (PCMCI).}
Left: Scenario 1 matches the chain \y{$F\rightarrow P\rightarrow T$}.
Right: Scenario 2 reveals no direct \y{$P\rightarrow T$} link.

\vspace{1mm}
\rtext{\bf Message:} same correlation $\neq$ same causal structure.

\vspace{0mm}
\textbf{Key capability}

\begin{itemize}
  \item Scenario 1: recover \y{$F \rightarrow P \rightarrow T$}
  \item Scenario 2: recover \y{$F \rightarrow P$ and $F \rightarrow T$} only
\end{itemize}
\end{column}

\end{columns}

\end{tightmath}
\end{frame}
%!TEX root = lec19.tex
% ================================================================================
% Lecture 19 — Slide 26
% ================================================================================
\begin{frame}[t,fragile]
\begin{tightmath}

\mytitle{Neural Causal Discovery: Scaling Ideas to Complex Systems}

\footnotesize

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.5\textwidth}
\vspace{-2mm}

\textbf{Motivation}

\begin{itemize}
  \item Earth-system variables are high-dimensional
  \item dependencies are nonlinear and state-dependent
  \item autocorrelation dominates raw signals
\end{itemize}

\vspace{0mm}
\textbf{Neural causal discovery idea}

\begin{itemize}
  \item first remove \y{self-dependence} (autocorrelation)
  \item learn cross-effects from \y{innovations}
  \item enforce sparsity $\Rightarrow$ interpretable directed links
\end{itemize}

\vspace{0mm}
\textbf{Innovation form:} $x(t) - a\,x(t-1)$

\vspace{0mm}
\rtext{\bf Key message:}
AI helps to \y{extend classical causal ideas}
to nonlinear, high-dimensional dynamics.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\vspace{-2mm}
\centering

\includegraphics[width=0.75\textwidth]{../../images/img19/neural_causal_discovery.png}

\vspace{1mm}
\raggedright
\footnotesize
\textbf{Example result.}
After removing autocorrelation, sparse learning recovers directed links:
Scenario 1: \y{$F\rightarrow P\rightarrow T$}, Scenario 2: \y{$F\rightarrow P$, $F\rightarrow T$}.

\end{column}

\end{columns}

\end{tightmath}
\end{frame}
% ================================================================================
% E-AI Tutorial Slides
% Filename: lec19.tex
%
% Roland Potthast 2025/2026
% Licence: CC-BY4.0
% ================================================================================
\documentclass[aspectratio=169]{beamer}

% --- Load lecture macros --------------------------------------------------------
\input{../lec_macros.tex}
\newcommand{\LectureNumber}{Lecture 19}

% --- Document -------------------------------------------------------------------
\begin{document}

\setagendaboxforlecture{19}

\input{../lec_agenda.tex}
\input{lec19_01.tex}
\input{lec19_02.tex}
\input{lec19_03.tex}
\input{lec19_04.tex}
\input{lec19_05.tex}
\input{lec19_06.tex}
\input{lec19_07.tex}
\input{lec19_08.tex}
\input{lec19_09.tex}
\input{lec19_10.tex}
\input{lec19_11.tex}
\input{lec19_12.tex}
\input{lec19_13.tex}
\input{lec19_14.tex}
\input{lec19_15.tex}
\input{lec19_16.tex}
\input{lec19_17.tex}
\input{lec19_18.tex}
\input{lec19_19.tex}
\input{lec19_20.tex}
\input{lec19_21.tex}
\input{lec19_22.tex}
\input{lec19_23.tex}
\input{lec19_24.tex}
\input{lec19_25.tex}
\input{lec19_26.tex}

% --- End Document ---------------------------------------------------------------
\end{document}
%!TEX root = lec20.tex
% ================================================================================
% Lecture 20 — Slide 01
% ================================================================================
\begin{frame}[t,fragile]
\mytitle{Lecture 20 — Obs-to-Obs Learning on a 2D Toy Atmosphere}

\footnotesize

\vspace{4mm}
\textbf{Goal of this lecture}

\begin{itemize}
  \item Build a simple 2D dynamical system $\phi(x,z,t)$ with \y{transport + diffusion + source}
  \item Generate two observation types
  \begin{itemize}
    \item \textbf{Radiosondes (RS):} sparse vertical profiles at a few columns
    \item \textbf{Satellite (SAT):} \y{integrated} vertical weighted observations for every column
  \end{itemize}
  \item Train a neural network to predict \y{next-step observations}
  \[
  (y^{sat}_t,\;y^{rs}_t) \;\mapsto\; (y^{sat}_{t+1},\;y^{rs}_{t+1})
  \]
  \item Reconstruct the full field at $t+1$ by querying RS predictions everywhere
\end{itemize}

\vspace{2mm}
\rtext{\bf Key message:} learn a \y{forecast step} in observation space, and still recover a \y{state-like} field.

\end{frame}
%!TEX root = lec20.tex
% ================================================================================
% Lecture 20 — Slide 02
% ================================================================================
\begin{frame}[t]
\mytitle{Toy Dynamics: Advection--Diffusion with Source and Damping}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.55\textwidth}
\footnotesize
\vspace{-2mm}

We simulate a tracer/heating field $\phi(x,z,t)$ on a 2D domain:

\vspace{-5mm}
\[
(x,z)\in[0,L_x]\times[0,L_z].
\]

\textbf{Dynamics (PDE)}
\[
\frac{\partial\phi}{\partial t}
=
-u\frac{\partial\phi}{\partial x}
-w\frac{\partial\phi}{\partial z}
+K\nabla^2\phi
+A(t)\,S(x,z)
-\lambda\,\phi
-\lambda_{\text{top}}(z)\,\phi.
\]

\textbf{Key design choices}
\begin{itemize}
  \item Mean wind: $\,(u,w)\,$ \y{right + upward} $\Rightarrow$ visible transport
  \item Source $S(x,z)$: localized bottom-left heating region
  \item \y{Pulsed forcing} $A(t)$ $\Rightarrow$ visible trace stripes
  \item Damping $\lambda$ + top sponge $\lambda_{\text{top}}$ $\Rightarrow$ equilibrium
\end{itemize}

\vspace{0mm}
\rtext{\bf Time stepping:} RK4.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.43\textwidth}
\centering
\vspace{5mm}

\includegraphics[width=\textwidth]{../../images/img20/images_dyn/1_dyn_01.png}

\vspace{1mm}
\includegraphics[width=\textwidth]{../../images/img20/images_dyn/1_dyn_02.png}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec20.tex
% ================================================================================
% Lecture 20 — Slide 03
% ================================================================================
\begin{frame}[t]
\mytitle{Boundary Conditions: Wrap-Around Transport (Periodic in $x$)}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize
\vspace{-2mm}

We want a flow where structures move out to the right and re-enter from the left.

\vspace{2mm}
\textbf{Boundary conditions}
\begin{itemize}
  \item \y{Periodic in $x$:} outflow wraps around
  \item Reflective/top treatment in $z$ (plus sponge)
\end{itemize}

\textbf{Effect}
\begin{itemize}
  \item A persistent tracer train forms
  \item The system reaches a \y{statistical steady state}
  \item Ideal for learning \y{time transitions}
\end{itemize}

\vspace{4mm}
\rtext{\bf This creates a clean, cyclic “atmosphere” for ML demos.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\centering
\vspace{4mm}

\includegraphics[width=\textwidth]{../../images/img20/images_dyn/1_dyn_03.png}

\vspace{1mm}
\includegraphics[width=\textwidth]{../../images/img20/images_dyn/1_dyn_04.png}

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec20.tex
% ================================================================================
% Lecture 20 — Slide 04
% ================================================================================
\begin{frame}[t,fragile]
\mytitle{RK4 Implementation (Core Loop)}

\footnotesize
\vspace{-1mm}

\textbf{Right-hand side}
\[
\mathrm{RHS}(\phi,t)
=
-u\,\partial_x\phi
-w\,\partial_z\phi
+K\nabla^2\phi
+A(t)S(x,z)
-(\lambda+\lambda_{\text{top}})\phi.
\]

\textbf{One RK4 step (schematic)}
\begin{lstlisting}[basicstyle=\ttfamily\scriptsize]
k1 = rhs(phi, t)
k2 = rhs(phi + 0.5*dt*k1, t + 0.5*dt)
k3 = rhs(phi + 0.5*dt*k2, t + 0.5*dt)
k4 = rhs(phi + dt*k3,     t + dt)
phi_next = phi + (dt/6)*(k1 + 2*k2 + 2*k3 + k4)
\end{lstlisting}

\vspace{1mm}
\textbf{Snapshot logic}
\begin{itemize}
  \item Choose $n_{vis}$ time indices between $0$ and $nsteps$
  \item Save numbered PNGs: \texttt{1\_dyn\_XX.png}
\end{itemize}

\vspace{4mm}
\rtext{\bf This gives clean training snapshots + nice lecture figures.}

\end{frame}
%!TEX root = lec20.tex
% ================================================================================
% Lecture 20 — Slide 05
% ================================================================================
\begin{frame}[t]
\mytitle{Energy / Mass Budget Monitoring (Sanity Checks)}

\footnotesize
\vspace{-2mm}

We monitor injected heat content and losses:
\[
C(t)=\int\phi\,dx\,dz, \qquad
I(t)=\int A(t)S\,dx\,dz,\qquad
L(t)=\int(\lambda+\lambda_{top})\phi\,dx\,dz.
\]

\textbf{Cumulative budget (discrete)}
\[
\mathrm{acc\_in}=\sum_n I(t_n)\Delta t,
\qquad
\mathrm{acc\_loss}=\sum_n L(t_n)\Delta t.
\]

\begin{itemize}
  \item $\int\phi$ stabilizes near equilibrium
  \item injected vs lost energy becomes balanced
  \item confirms numerical stability and correct forcing/damping design
\end{itemize}

\vspace{2mm}
\rtext{\bf Always build monitoring into the toy model: it prevents silent nonsense.}

\end{frame}
%!TEX root = lec20.tex
% ================================================================================
% Lecture 20 — Slide 06
% ================================================================================
\begin{frame}[t]
\mytitle{Observations: Radiosondes (Sparse Vertical Profiles)}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize
\vspace{4mm}

\textbf{Radiosonde observation operator}

At station column $x_{s}$ and selected heights $z_k$:
\[
y^{rs}_t(s,k)=\phi(x_s,z_k,t)+\epsilon.
\]

\textbf{Geometry is discrete}
\begin{itemize}
  \item $n_{rs}$ station columns: \texttt{rs\_ix}
  \item $n_{vert}$ vertical levels: \texttt{rs\_iz}
  \item output array: \texttt{yrs[time, station, vert]}
\end{itemize}

\vspace{4mm}
\rtext{\bf RS gives a sparse but physically intuitive reference view.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\centering
\vspace{-2mm}

\includegraphics[width=\textwidth]{../../images/img20/images_obs_rs/1_x_yrs_00.png}

\vspace{1mm}
\includegraphics[width=\textwidth]{../../images/img20/images_obs_rs/1_x_yrs_05.png}

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec20.tex
% ================================================================================
% Lecture 20 — Slide 07
% ================================================================================
\begin{frame}[t]
\mytitle{Observations: Satellite (Vertical Weighting Integrals)}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize
\vspace{4mm}

\textbf{Satellite observation operator}

For each channel $c$ (Gaussian vertical weights $w_c(z)$):
\[
y^{sat}_t(c,x_i)
=
\sum_{j=1}^{n_z} w_c(z_j)\,\phi(x_i,z_j,t)\,\Delta z.
\]

\textbf{Properties}
\begin{itemize}
  \item available \y{for all columns} $x_i$
  \item integrated information $\Rightarrow$ ill-posed inverse problem
  \item multiple channels $\Rightarrow$ multi-layer sensitivity
\end{itemize}

\textbf{Array}
\begin{itemize}
  \item \texttt{ysat[time, channel, x]}
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\centering
\vspace{-2mm}

\includegraphics[width=0.95\textwidth]{../../images/img20/sat_weights.png}

\vspace{2mm}
\rtext{Gaussian vertical weighting functions used for the SAT channels.}

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec20.tex
% ================================================================================
% Lecture 20 — Slide 08
% ================================================================================
\begin{frame}[t]
\mytitle{Saved Dataset: Truth + Two Observation Types}

\footnotesize
\vspace{4mm}

We store everything into \texttt{dyn\_truth\_obs.npz}:

\begin{itemize}
  \item \textbf{Truth fields}
  \[
  xtrue \in \mathbb{R}^{T_{snap}\times n_z\times n_x}
  \]
  \item \textbf{Radiosondes}
  \[
  yrs \in \mathbb{R}^{T_{snap}\times n_{rs}\times n_{vert}}
  \]
  \item \textbf{Satellite}
  \[
  ysat \in \mathbb{R}^{T_{snap}\times n_{sat}\times n_x}
  \]
  \item Snapshot times: \texttt{t\_snap}
  \item Geometry: \texttt{rs\_ix}, \texttt{rs\_iz}
  \item SAT vertical weights: \texttt{sat\_w}
\end{itemize}

\vspace{4mm}
\rtext{\bf This allows a clean separation:} Notebook 1 = generate dataset, Notebook 2 = learn transitions.

\end{frame}
%!TEX root = lec20.tex
% ================================================================================
% Lecture 20 — Slide 09
% ================================================================================
\begin{frame}[t]
\mytitle{Learning Task: Next-Step Obs Forecasting}

\footnotesize
\vspace{4mm}

We train an ML model that predicts the next observation state:

\[
(y^{sat}_t,\;y^{rs}_t)\;\mapsto\;(\hat y^{sat}_{t+1},\;\hat y^{rs}_{t+1}(\cdot)).
\]

\textbf{Inputs at time $t$}
\begin{itemize}
  \item Satellite curtain: $y^{sat}_t(c,x)$ for all columns
  \item RS set of points: $\{(x_m,z_m,y_m)\}_{m=1}^{N_{in}}$
\end{itemize}

\textbf{Outputs at time $t+1$}
\begin{itemize}
  \item Predicted satellite curtain $\hat y^{sat}_{t+1}(c,x)$
  \item Predicted RS values at query points $\hat y^{rs}_{t+1}(x_q,z_q)$
\end{itemize}

\vspace{4mm}
\rtext{\bf Important:} query points can be anywhere $\Rightarrow$ \y{generalization to new RS placements}.

\end{frame}
%!TEX root = lec20.tex
% ================================================================================
% Lecture 20 — Slide 10
% ================================================================================
\begin{frame}[t,fragile]
\mytitle{Normalization: The Key Practical Ingredient}

\footnotesize
\vspace{4mm}

We normalize observations before training:

\vspace{2mm}
\textbf{SAT: per-channel statistics}
\[
y^{sat}_n
=
\frac{y^{sat}-\mu_{sat}}{\sigma_{sat}},
\qquad
\mu_{sat}=\mathbb{E}_{t,x}[y^{sat}],
\qquad
\sigma_{sat}=\mathrm{std}_{t,x}[y^{sat}].
\]

\textbf{RS / truth: global}
\[
\phi_n=\frac{\phi-\mu_\phi}{\sigma_\phi},
\qquad
y^{rs}_n=\frac{y^{rs}-\mu_\phi}{\sigma_\phi}.
\]

\vspace{4mm}
\rtext{\bf Without normalization} the training becomes unstable and “learns the wrong scale”.

\end{frame}
%!TEX root = lec20.tex
% ================================================================================
% Lecture 20 — Slide 11
% ================================================================================
\begin{frame}[t, fragile]
\mytitle{Flexible RS Input: Two Dataset Modes (A/B Switch)}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.7\textwidth}
\footnotesize
\vspace{4mm}

We implement a dataset switch (important for interpretability):

\vspace{2mm}
\textbf{Mode A (synthetic RS from truth)}
\begin{itemize}
  \item sample RS input points randomly from $xtrue[t]$
  \item add realistic noise $\sigma_{rs}$
  \item \y{excellent generalization} for arbitrary RS geometry
\end{itemize}

\vspace{1mm}
\textbf{Mode B (use only stored RS observations)}
\begin{itemize}
  \item RS input points are exactly \texttt{yrs[t,:,:]} at fixed \texttt{rs\_ix, rs\_iz}
  \item strict statement: \rtext{\bf “input uses only observations at time $t$”}
  \item weaker geometric diversity, but realistic RS network
\end{itemize}

\vspace{2mm}
\rtext{\bf Reality:} We have only fixed radiosondes, but we have \y{airplanes}!

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.28\textwidth}
\vspace{4mm}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
Saved:
  data_dyn_obs/dyn_truth_obs.npz

Content:
  xtrue  shape=(10,50,130)
  yrs    shape=(10,7,18)
  ysat   shape=(10,4,130)

  t_snap shape=(10,)
  rs_ix  shape=(7,)
  rs_iz  shape=(18,)
  sat_w  shape=(4,50)

  x      shape=(130,)
  z      shape=(50,)
\end{lstlisting}
\end{column}

\end{columns}

\end{frame}
%!TEX root = lec20.tex
% ================================================================================
% Lecture 20 — Slide 12
% ================================================================================
\begin{frame}[t]
\mytitle{Architecture: CNN on SAT + Set Encoder for RS + Query Head}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{Why a CNN?}

\vspace{3mm}
SAT is a \y{curtain} $y^{sat}(c,x)$ along $x$. \\
Spatial patterns advect $\Rightarrow$ translation-like structure.

\vspace{3mm}
\textbf{Components}
\begin{itemize}
  \item \textbf{SAT encoder:} 1D-CNN
  \begin{itemize}
    \item extracts local features along $x$
  \end{itemize}
  \item \textbf{RS encoder:} DeepSets / pooling
  \begin{itemize}
    \item handles variable-size RS point sets
  \end{itemize}
  \item \textbf{Query decoder:} predicts $y^{rs}_{t+1}(x_q,z_q)$
\end{itemize}

\vspace{1mm}
\rtext{\bf This enforces coupling:} RS inference is \\
\centering
\y{driven by SAT structure}.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize
\vspace{0mm}

\textbf{Query-style output}
\[
\hat y^{rs}_{t+1}(x_q,z_q)
=
g_\theta\big( \mathrm{CNN}(y^{sat}_t),\;
\mathrm{Set}(y^{rs}_t),\;
x_q,z_q \big).
\]

\textbf{Practical win}
\begin{itemize}
  \item RS can be placed anywhere
  \item same model predicts:
  \begin{itemize}
    \item sparse profiles
    \item full fields (query everywhere)
  \end{itemize}
\end{itemize}

\hspace*{-8mm}
\begin{minipage}{7cm}
\tiny\color{darkgreen}
\textbf{DeepSets / pooling: why order does not matter}

RS inputs form a \emph{set} $\mathcal S=\{(x_m,z_m,y_m)\}_{m=1}^{N}$.
A set has no order, so the encoding must satisfy
$F(\mathcal S)=F(\pi(\mathcal S))$ for any permutation $\pi$.

We enforce this with a permutation-invariant encoder:
\begin{equation*}
e_m=\psi_\theta(x_m,z_m,y_m),\qquad
E=\mathrm{pool}(e_1,\dots,e_N)
\end{equation*}
where pooling is sum/mean/max (commutative $\Rightarrow$ order-invariant).
Locations matter via $(x_m,z_m)$ inside $\psi_\theta$.
\end{minipage}

\end{column}

\end{columns}

\end{frame}
%!TEX root = lec20.tex
% ================================================================================
% Lecture 20 — Slide 13
% ================================================================================
\begin{frame}[t,fragile]
\mytitle{Training Loss: Joint SAT + RS Query Targets}

\footnotesize
\vspace{2mm}

We train on snapshot transitions $t\to t+1$ using a joint loss:

\vspace{2mm}
\textbf{SAT loss (next curtain)}
\[
\mathcal{L}_{sat}
=
\| \hat y^{sat}_{t+1}-y^{sat}_{t+1}\|_2^2.
\]

\textbf{RS query loss (next profile at query points)}
\[
\mathcal{L}_{rs}
=
\frac{1}{N_q}\sum_{q=1}^{N_q}
\left(
\hat y^{rs}_{t+1}(x_q,z_q) - y^{rs}_{t+1}(x_q,z_q)
\right)^2.
\]

\textbf{Total}
\[
\mathcal{L}=\mathcal{L}_{sat}+\alpha\,\mathcal{L}_{rs}.
\]

\vspace{2mm}
\rtext{\bf Note:} RS targets for arbitrary $(x_q,z_q)$ are taken from truth $xtrue[t+1]$.

\end{frame}
%!TEX root = lec20.tex
% ================================================================================
% Lecture 20 — Slide 14
% ================================================================================
\begin{frame}[t]
\mytitle{Evaluation 1: Predict a New RS Profile at an Unseen Location}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\footnotesize
\vspace{2mm}

We test \y{generalization}:

\begin{itemize}
  \item Input RS: taken from stored network \texttt{yrs[t,:,:]}
  \item Choose a new $x$ column not used by RS
  \item Query all heights $\{z_q\}$ at that $x$
  \item Compare predicted profile $\hat y^{rs}_{t+1}$ vs truth $xtrue[t+1]$
\end{itemize}

\vspace{4mm}
\rtext{\bf This checks whether the model learned physics-like transport information from SAT.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\centering
\vspace{-2mm}

\includegraphics[width=\textwidth]{../../images/img20/rs_rec/rs_profile_pred_truth_ix002_t05_to_06.png}

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec20.tex
% ================================================================================
% Lecture 20 — Slide 15
% ================================================================================
\begin{frame}[t]
\mytitle{Evaluation 2: Full-Field Reconstruction at $t+1$ (Query Everywhere)}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}
\footnotesize
\vspace{2mm}

The RS query head can be evaluated on the whole grid:
\[
x_{\mathrm{pred}}(x_i,z_j,t+1) := \hat y^{rs}_{t+1}(x_i,z_j).
\]

\textbf{We visualize}
\begin{itemize}
  \item $xtrue[t]$ (reference)
  \item $xtrue[t+1]$ (truth)
  \item $xpred[t+1]$ (prediction)
  \item difference $\;xpred-xtrue$
\end{itemize}

\vspace{1mm}
\rtext{\bf This turns obs-to-obs learning into a state-like field prediction.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.54\textwidth}
\centering
\vspace{4mm}

\includegraphics[width=\textwidth]{../../images/img20/rs_rec/xpred_full_2x2_t05_to_06.png}

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec20.tex
% ================================================================================
% Lecture 20 — Slide 16
% ================================================================================
\begin{frame}[t,fragile]
\mytitle{Observation-based Reconstruction \& Inversion for Generative Emulation of Nonlinear Systems: \rtext{ORIGEN}}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.54\textwidth}
\footnotesize
\vspace{0mm}

\begin{itemize}
  \item A \y{closed learning cycle} linking
  \y{observations}, \y{analysis reconstruction}, and \y{forecast models}.
\end{itemize}

\vspace{1mm}
\textbf{Conceptual loop}
\begin{itemize}
  \item Start from a \y{current model} (here: persistence / baseline)
  \item Use \y{observations} to reconstruct state: \y{AI analysis / inversion}
  \item Update the model/forecast emulator from reconstructed states
  \item Iterate: \y{next cycle uses the new model}
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.46\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{ORIGEN cycle schematic}
\vspace{1mm}

\begin{center}
\includegraphics[width=0.98\textwidth]{../../images/img20/origen/origen_graphics.pdf}
\end{center}

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec20.tex
% ================================================================================
% Lecture 20 — Slide 17
% ================================================================================
\begin{frame}[t,fragile]
\mytitle{ORIGEN on a Minimal Example: Simple Oscillator}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.4\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{Minimal testbed (2D circle)}
\begin{itemize}
  \item \y{Truth trajectory} $x_k=(x_{1,k},x_{2,k})$ on a circle
  \[
  x_k=
  \begin{bmatrix}
  \cos\theta_k\\ \sin\theta_k
  \end{bmatrix},
  \qquad
  \theta_k=\frac{2\pi k}{n}
  \]
  \item Observations are \y{scalar} and \y{partial}:
  \[
  y_k = H_k x_k + \epsilon_k,
  \qquad
  H_k\in\{[1,0],[0,1]\}
  \]
\end{itemize}

\vspace{1mm}
\rtext{\bf Aim:}
Explain ORIGEN mechanics without complex dynamics.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.58\textwidth}
\footnotesize
\vspace{-2mm}
\begin{center}
\includegraphics[width=0.8\textwidth]{../../images/img20/origen/origen01.png}
\end{center}

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec20.tex
% ================================================================================
% Lecture 20 — Slide 18
% ================================================================================
\begin{frame}[t,fragile]
\mytitle{Observations: Partial Measurements of $x_1$ or $x_2$}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.45\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{Time-dependent observation operator}
\vspace{-1mm}
\begin{itemize}
  \item At each step $k$ we observe only \y{one component}
  \item Selector:
  \[
    s_k\in\{1,2\}
  \]
  \item Observation operator:
  \[
    H_k =
    \begin{cases}
      [1,0] & s_k=1 \ (\text{observe }x_1)\\
      [0,1] & s_k=2 \ (\text{observe }x_2)
    \end{cases}
  \]
  \item Observation equation:
  \[
    y_k = H_k x_k + \epsilon_k,
    \qquad
    \epsilon_k\sim\mathcal N(0,R)
  \]
\end{itemize}

\vspace{0mm}
\rtext{\bf Interpretation:}
This mimics \y{heterogeneous sensors} and \y{missing data}.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.58\textwidth}
\footnotesize
\vspace{-2mm}

\begin{center}
\includegraphics[width=0.88\textwidth]{../../images/img20/origen/origen02.png}
\end{center}

\vspace{-1mm}
\begin{center}
{\scriptsize Blue: $x_1$ observed \qquad Orange: $x_2$ observed}
\end{center}

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec20.tex
% ================================================================================
% Lecture 20 — Slide 19
% ================================================================================
\begin{frame}[t,fragile]
\mytitle{3D-Var Step: Background $\rightarrow$ Analysis (Single Observation)}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{We combine background + one scalar obs}

\vspace{1mm}
\begin{itemize}
  \item Background state: $x_k^b\in\mathbb R^2$
  \item Obs: $y_k\in\mathbb R$, operator $H_k\in\mathbb R^{1\times 2}$
\end{itemize}

\vspace{1mm}
\textbf{Innovation}
\vspace{-1mm}
\[
d_k = y_k - H_k x_k^b
\]

\textbf{Gain (scalar obs)}
\vspace{-1mm}
\[
K_k = B H_k^\top \left(H_k B H_k^\top + R\right)^{-1}
\]

\textbf{Analysis update}
\vspace{-1mm}
\[
x_k^a = x_k^b + K_k\,d_k
\]

\vspace{1mm}
\rtext{\bf Effect:}
update only in observed direction, but shaped by \y{$B$}.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize
\vspace{0mm}

\textbf{Initial choice of covariances}
\vspace{-1mm}
\[
B=
\begin{bmatrix}
\sigma_b^2(x_1) & 0\\
0 & \sigma_b^2(x_2)
\end{bmatrix},
\qquad
R=\sigma_o^2
\]

\vspace{2mm}
\textbf{Cycling (persistence model)}
\vspace{-1mm}
\[
x_{k+1}^b = M(x_k^a),
\qquad
M(x)=x
\]

\vspace{2mm}
\begin{itemize}
  \item This produces a full sequence:
  \[
  x_0^b \rightarrow x_0^a \rightarrow x_1^b \rightarrow \dots
  \]
  \item We visualize results next: truth vs background vs analysis
\end{itemize}

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec20.tex
% ================================================================================
% Lecture 20 — Slide 20
% ================================================================================
\begin{frame}[t,fragile]
\mytitle{3D-Var Cycle Result: Time Series of $x_1$ and $x_2$}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{What we compare}
\vspace{-1mm}
\begin{itemize}
  \item \y{Truth} $x_k$
  \item \y{Background} $x_k^b$
  \item \y{Analysis} $x_k^a$
  \item and the \y{scalar observations} $y_k$
\end{itemize}

\vspace{1mm}
\textbf{Key behavior}
\vspace{-1mm}
\begin{itemize}
  \item analyses are pulled towards the obs
  \item cycling propagates improvements forward
  \item unobserved component still benefits \y{indirectly} (via $B$ and cycling)
\end{itemize}

\vspace{2mm}
\rtext{\bf Idea:}
Information is collected iteratively.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.56\textwidth}
\footnotesize
\vspace{-2mm}

\begin{center}
\includegraphics[width=0.95\textwidth]{../../images/img20/origen/origen03.png}
\end{center}

\vspace{-1mm}
\begin{center}
{\scriptsize Top: $x_1$ time series \qquad Bottom: $x_2$ time series}
\end{center}

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec20.tex
% ================================================================================
% Lecture 20 — Slide 21
% ================================================================================
\begin{frame}[t,fragile]
\mytitle{Sequential Rounds: With All Observations We Converge in Two Cycles}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{Idea: assimilate in two rounds}
\vspace{-1mm}
\begin{itemize}
  \item \y{Round 1:} observe $x_1$ only
  
  \vspace{-3mm}
  \[
    y_k^{(1)} = x_{1,k} + \epsilon_k
  \]
  \item \y{Round 2:} observe $x_2$ only, using

  \vspace{-3mm}
  \[
    x_{k}^{b,(2)} := x_{k}^{a,(1)}
  \]
\end{itemize}

\vspace{1mm}
\textbf{If obs error is small}
\vspace{-1mm}
\begin{itemize}
  \item after Round 1: $x_1$ aligns with truth
  \item after Round 2: $x_2$ aligns with truth
  \item \y{both components observed} $\Rightarrow$ fast convergence
\end{itemize}

\vspace{2mm}
\rtext{\bf Message:}
With complete information, ORIGEN-style cycling converges quickly.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.56\textwidth}
\footnotesize
\vspace{-2mm}

\begin{center}
\includegraphics[width=0.92\textwidth]{../../images/img20/origen/origen05.png}
\end{center}

\vspace{-1mm}
\begin{center}
{\scriptsize Truth vs Round 1 ($x_1$ obs) vs Round 2 ($x_2$ obs, bg=Round 1)}
\end{center}

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec20.tex
% ================================================================================
% Lecture 20 — Slide 22
% ================================================================================
\begin{frame}[t,fragile]
\mytitle{Iterative 3D-Var: Reconstruction Improves over Cycles (Demo)}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{What is iterated here?}
\vspace{-1mm}
\begin{itemize}
  \item We reconstruct an \y{entire trajectory}
  
  \vspace{-3mm}
  \[
    \{x_k^a\}_{k=0}^{n-1}
  \]
  from \y{noisy, partial observations}

  \vspace{-3mm}
  \[
    y_k = H_k x_k + \epsilon_k
  \]
  \item Each cycle produces a refined estimate of the full sequence:

  \vspace{-3mm}
  \[
    \{x_k^{a,(c)}\} \;\Rightarrow\; \{x_k^{a,(c+1)}\}
  \]
\end{itemize}

\vspace{-2mm}
\textbf{Crucial point}
\vspace{-1mm}
\begin{itemize}
  \item The ``dynamics'' is \y{implicit} in the reconstructed series
  \item We are not propagating with a separate model;
        we repeatedly improve the \y{sequence itself}
\end{itemize}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.54\textwidth}
\footnotesize
\vspace{-5mm}

\begin{center}
\includegraphics[width=0.96\textwidth]{../../images/img20/origen/origen08_crop.png}
\end{center}

\vspace{-3mm}
\begin{center}
{\scriptsize RMSE per assimilation cycle: iterative 3D-Var improves the reconstructed trajectory}
\end{center}

\vspace{-2mm}
\rtext{\bf ORIGEN:}
from the reconstructed $\{x_k^a\}$ we learn a forecast map

\vspace{-3mm}
\[
x^a(t)\mapsto x^a(t+\Delta t),
\]
in the notebook we focus on trajectory reconstruction.

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec20.tex
% ================================================================================
% Lecture 20 — Slide 23
% ================================================================================
\begin{frame}[t,fragile]
\mytitle{Reconstruction: 2D Trajectory over Iterative 3D-Var Cycles}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{Iterative 3D-Var reconstruction}
\vspace{-1mm}
\begin{itemize}
  \item Each cycle reconstructs the full sequence:

  \vspace{-3mm}
  \[
  \{x_k^a\}_{k=0}^{n-1}
  \]
  \item Observations remain \y{noisy and partial}:

  \vspace{-3mm}
  \[
  y_k = H_k x_k + \epsilon_k
  \]
  \item Repeated cycles reduce reconstruction error
\end{itemize}

\vspace{1mm}
\textbf{What you see on the right}
\vspace{-1mm}
\begin{itemize}
  \item Truth trajectory (black)
  \item Selected analysis cycles (colored)
  \item Later cycles are closer to truth
\end{itemize}

\vspace{2mm}
\rtext{\bf Message:}
3D-Var keeps error coming in from the observation error

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize
\vspace{-2mm}

\begin{center}
\includegraphics[width=0.92\textwidth]{../../images/img20/origen/origen07.png}
\end{center}

\vspace{-1mm}
\begin{center}
{\scriptsize Iterative reconstruction in state space $(x_1,x_2)$}
\end{center}

\end{column}

\end{columns}
\end{frame}


%!TEX root = lec20.tex
% ================================================================================
% Lecture 20 — Slide 24
% ================================================================================
\begin{frame}[t,fragile]
\mytitle{Reconstruction: Cycle Time Series with Noisy Observations}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{Final-cycle diagnostics}
\vspace{-1mm}
\begin{itemize}
  \item Compare \y{truth} vs \y{final reconstructed trajectory}
  \item Show observations for the last random pattern:
  \[
    H_k \in \{[1,0],[0,1]\}
  \]
  \item Observations are noisy $\Rightarrow$ analysis does \y{not overfit}
\end{itemize}

\vspace{1mm}
\textbf{3D-Var property}
\vspace{-1mm}
\begin{itemize}
  \item analysis is a \y{weighted compromise}
  \item controlled by $\y{B}$ and $\y{R}$
\end{itemize}

\vspace{2mm}
\rtext{\bf Message:}
3D-VAR is not enough
\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize
\vspace{-2mm}

\begin{center}
\includegraphics[width=0.96\textwidth]{../../images/img20/origen/origen09.png}
\end{center}

\vspace{-1mm}
\begin{center}
{\scriptsize Final cycle: time series for $x_1$ and $x_2$ with noisy partial observations}
\end{center}

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec20.tex
% ================================================================================
% Lecture 20 — Slide 25
% ================================================================================
\begin{frame}[t,fragile]
\mytitle{Adding a Covariance Update: Kalman Filter--Type Uncertainty Reduction}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{Upgrade: update $B$ during cycling}
\vspace{-1mm}
\begin{itemize}
  \item Until now: fixed background covariance $B$
  \item Now: after each analysis step we also update uncertainty
\end{itemize}

\vspace{1mm}
\textbf{Kalman filter covariance update}
\vspace{-1mm}
\[
A_k = (I - K_k H_k)\,B_k
\qquad\Rightarrow\qquad
B_k \leftarrow A_k
\]

\vspace{1mm}
\textbf{Effect:}
\vspace{-1mm}
\begin{itemize}
  \item uncertainty shrinks in observed directions
  \item gain adapts across cycles
  \item analysis trajectory converges strongly to truth
\end{itemize}

\vspace{0mm}
\rtext{\bf Message:}
\y{With adaptive $B$, iterative DA converges.}

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.48\textwidth}
\footnotesize
\vspace{-2mm}

\begin{center}
\includegraphics[width=0.92\textwidth]{../../images/img20/origen/origen10.png}
\end{center}

\vspace{-1mm}
\begin{center}
{\scriptsize Selected cycles: trajectory converges towards the true circle}
\end{center}

\end{column}

\end{columns}
\end{frame}


%!TEX root = lec20.tex
% ================================================================================
% Lecture 20 — Slide 26
% ================================================================================
\begin{frame}[t,fragile]
\mytitle{Full Convergence: Final Trajectory with Covariance Update}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.44\textwidth}
\footnotesize
\vspace{-2mm}

\textbf{Final-cycle reconstruction}
\vspace{-1mm}
\begin{itemize}
  \item With $B$ update, repeated cycling yields \y{near-perfect reconstruction}
  \item Even with noisy and partial observations
\end{itemize}

\vspace{1mm}
\textbf{Why it converges}
\vspace{-1mm}
\begin{itemize}
  \item analysis reduces both error \y{and} uncertainty
  \item smaller uncertainty $\Rightarrow$ more consistent updates
  \item loop stabilizes around the truth trajectory
\end{itemize}

\vspace{2mm}
\rtext{\bf Message:}
ORIGEN principle: reconstruction + uncertainty adaptation $\Rightarrow$ convergence.

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.52\textwidth}
\footnotesize
\vspace{-2mm}

\begin{center}
\includegraphics[width=0.96\textwidth]{../../images/img20/origen/origen12.png}
\end{center}

\vspace{-4mm}
\begin{center}
{\scriptsize Final cycle: time series $x_1$, $x_2$ converged}
\end{center}

\end{column}

\end{columns}
\end{frame}
%!TEX root = lec20.tex
% ================================================================================
% Lecture 20 — Slide 27
% ================================================================================
\begin{frame}[t]
\mytitle{Lorenz-63: ORIGEN Reconstruction \& Learned Forecast Model}

\begin{columns}[T,totalwidth=\textwidth]

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\footnotesize
\vspace{-1mm}
\textbf{ORIGEN loop (concept)}
\begin{enumerate}
  \item Assimilate random observed subsets ($x$, $y$, $z$, $xy$, $xz$, $yz$)
  \item Update background $\mathbf{x}^b \leftarrow \mathbf{x}^a$
  \item Update covariance $B \leftarrow P^a$ (Kalman-style)
\end{enumerate}

\vspace{1mm}
\textbf{Model learning}
\begin{itemize}
  \item Train NN to learn one-step map
  \[
    \mathbf{x}^a(k)\ \mapsto\ \mathbf{x}^a(k+1)
  \]
  \item \y{\rtext{\bf Fine-Tuning with Rollout}}
\end{itemize}

Rollout: many subsequent short forecasts

\end{column}

% ------------------------------------------------------------
\begin{column}[T]{0.50\textwidth}
\vspace{-2mm}
\centering
\includegraphics[width=0.9\textwidth]{../../images/img20/L63_6_ML_model_fc_test_2.png}

\vspace{1mm}
\scriptsize
Forecast rollouts (blue) starting from analysis states (red dots), compared to the
reconstructed reference trajectory (black dashed).
\end{column}

\end{columns}
\end{frame}
% ================================================================================
% E-AI Tutorial Slides
% Filename: lec20.tex
%
% Roland Potthast 2025/2026
% Licence: CC-BY4.0
% ================================================================================
\documentclass[aspectratio=169]{beamer}

% --- Load lecture macros --------------------------------------------------------
\input{../lec_macros.tex}
\newcommand{\LectureNumber}{Lecture 20}

% --- Document -------------------------------------------------------------------
\begin{document}

\setagendaboxforlecture{20}

\input{../lec_agenda.tex}
\input{lec20_01.tex}
\input{lec20_02.tex}
\input{lec20_03.tex}
\input{lec20_04.tex}
\input{lec20_05.tex}
\input{lec20_06.tex}
\input{lec20_07.tex}
\input{lec20_08.tex}
\input{lec20_09.tex}
\input{lec20_10.tex}
\input{lec20_11.tex}
\input{lec20_12.tex}
\input{lec20_13.tex}
\input{lec20_14.tex}
\input{lec20_15.tex}
\input{lec20_16.tex}
\input{lec20_17.tex}
\input{lec20_18.tex}
\input{lec20_19.tex}
\input{lec20_20.tex}
\input{lec20_21.tex}
\input{lec20_22.tex}
\input{lec20_23.tex}
\input{lec20_24.tex}
\input{lec20_25.tex}
\input{lec20_26.tex}
\input{lec20_27.tex}

% --- End Document ---------------------------------------------------------------
\end{document}
