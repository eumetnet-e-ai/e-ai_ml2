data:
  format: zarr
  frequency: 3h
  timestep: 3h
  forcing:
  - CAPE_CON
  - LPI_CON_MAX
  - HTOP_CON
  - TOT_PREC
  - PREC_CON

  diagnostic:
  - CBCF
  - CLST
  - ISOL
  - WSPR
  - CBCF_top
  - CLST_top
  - ISOL_top
  - WSPR_top
  - CBCF_likeliness
  - CLST_likeliness
  - ISOL_likeliness
  - WSPR_likeliness

  normalizer:
    default: mean-std
    std:
    - CBCF_top
    - CLST_top
    - ISOL_top
    - WSPR_top
    #- tp
    min-max: null
    max: null
    #- sdor
    #- slor
    #- z
    none:
    - CBCF
    - CLST
    - ISOL
    - WSPR
    - CBCF_likeliness
    - CLST_likeliness
    - ISOL_likeliness
    - WSPR_likeliness

  processors:
    normalizer:
      _target_: anemoi.models.preprocessing.normalizer.InputNormalizer
      config: ${data.normalizer}
  num_features: null
dataloader:
  prefetch_factor: 2
  pin_memory: true
  read_group_size: ${system.hardware.num_gpus_per_model}
  num_workers:
    training: 2
    validation: 2
    test: 1
  batch_size:
    training: 16
    validation: 16
    test: 4
  limit_batches:
    training: null #3
    validation: null #2
    test: 20
  grid_indices:
    _target_: anemoi.training.data.grid_indices.FullGrid
    nodes_name: ${graph.data}
#  grid_indices:
#    _target_: anemoi.training.data.grid_indices.MaskedGrid
#    nodes_name: data
#    node_attribute_name: indices_connected_nodes
  dataset: ${system.input.dataset}
  training:
    dataset: ${dataloader.dataset}
    start: 2024-05-02T06:00:00
    end: 2024-10-01T21:00:00
    frequency: ${data.frequency}
    drop: []
  validation_rollout: 1
  validation:
    dataset: ${dataloader.dataset}
    start: 2024-10-02T06:00:00
    end: 2024-10-15T18:00:00
#    start: 2024-05-02T21:00:00
#    end: 2024-05-02T23:00:00
    frequency: ${data.frequency}
    drop: []
  test:
    dataset: ${dataloader.dataset}
    start: 2022
    end: null
    frequency: ${data.frequency}
    drop: []
diagnostics:
  plot:
    asynchronous: false
    datashader: true
    frequency:
      batch: 1
      epoch: 2
    parameters:
    - CBCF
    sample_idx: 0
    precip_and_related_fields:
    - tp
    - cp
    colormaps:
      default:
        _target_: anemoi.training.utils.custom_colormaps.MatplotlibColormap
        name: viridis
      error:
        _target_: anemoi.training.utils.custom_colormaps.MatplotlibColormap
        name: bwr
      precip:
        _target_: anemoi.training.utils.custom_colormaps.MatplotlibColormapClevels
        clevels:
        - '#ffffff'
        - '#04e9e7'
        - '#019ff4'
        - '#0300f4'
        - '#02fd02'
        - '#01c501'
        - '#008e00'
        - '#fdf802'
        - '#e5bc00'
        - '#fd9500'
        - '#fd0000'
        - '#d40000'
        - '#bc0000'
        - '#f800fd'
        variables: ${diagnostics.plot.precip_and_related_fields}
    callbacks:
    #- _target_: anemoi.training.diagnostics.callbacks.plot.GraphTrainableFeaturesPlot
    #  every_n_epochs: 5
    - _target_: anemoi.training.diagnostics.callbacks.plot.PlotLoss
      parameter_groups:
        moisture:
        - tp
        - cp
        - tcw
        sfc_wind:
        - 10u
        - 10v
      every_n_batches: ${diagnostics.plot.frequency.batch}
    - _target_: anemoi.training.diagnostics.callbacks.plot.PlotSample
      sample_idx: ${diagnostics.plot.sample_idx}
      per_sample: 1
      parameters:
        - CBCF
      every_n_batches: ${diagnostics.plot.frequency.batch}
      accumulation_levels_plot:
      - 0
      - 0.05
      - 0.1
      - 0.25
      - 0.5
      - 1
      - 1.5
      - 2
      - 3
      - 4
      - 5
      - 6
      - 7
      - 100
      precip_and_related_fields: ${diagnostics.plot.precip_and_related_fields}
      colormaps: ${diagnostics.plot.colormaps}
    - _target_: anemoi.training.diagnostics.callbacks.plot.PlotSpectrum
      sample_idx: ${diagnostics.plot.sample_idx}
      every_n_batches: ${diagnostics.plot.frequency.batch}
      parameters:
      - CBCF
    - _target_: anemoi.training.diagnostics.callbacks.plot.PlotHistogram
      sample_idx: ${diagnostics.plot.sample_idx}
      every_n_batches: ${diagnostics.plot.frequency.batch}
      precip_and_related_fields: ${diagnostics.plot.precip_and_related_fields}
      parameters:
      - CBCF
  callbacks: []
  benchmark_profiler:
    memory:
      enabled: true
      steps: 5
      warmup: 2
      extra_plots: false
      trace_rank0_only: false
    time:
      enabled: true
      verbose: false
    speed:
      enabled: true
    system:
      enabled: true
    model_summary:
      enabled: true
    snapshot:
      enabled: true
      steps: 4
      warmup: 0
  debug:
    anomaly_detection: false
  enable_checkpointing: true
  checkpoint:
    every_n_minutes:
      save_frequency: 30
      num_models_saved: 3
    every_n_epochs:
      save_frequency: 1
      num_models_saved: -1
    every_n_train_steps:
      save_frequency: null
      num_models_saved: 0
  log:
    wandb:
      enabled: false
      offline: false
      log_model: false
      project: Anemoi
      entity: ???
      gradients: false
      parameters: false
    tensorboard:
      enabled: false
    mlflow:
      enabled: false
      _target_: anemoi.training.diagnostics.mlflow.logger.AnemoiMLflowLogger
      offline: true
      authentication: false
      tracking_uri: https://mlflow
      experiment_name: cbcf
      project_name: cbcf
      system: false
      terminal: true
      run_name: null
      on_resume_create_child: true
      expand_hyperparams:
      - config
      http_max_retries: 35
      max_params_length: 2000
      save_dir: ${system.output.logs.mlflow}
    interval: 2
  enable_progress_bar: true
  progress_bar:
    _target_: pytorch_lightning.callbacks.TQDMProgressBar
    refresh_rate: 1
  check_val_every_n_epoch: 10
  print_memory_summary: false
system:
  input:
    graph: none
    dataset: "../dwd-dream-eu-archive-R03B05-20240502-20241017-3h-v3-CBCF.zarr"
    warm_start: null
    checkpoint:
  output:
    root: ./output
    checkpoints:
      root: checkpoint
      every_n_epochs: anemoi-by_epoch-epoch_{epoch:03d}-step_{step:06d}
      every_n_train_steps: anemoi-by_step-epoch_{epoch:03d}-step_{step:06d}
      every_n_minutes: anemoi-by_time-epoch_{epoch:03d}-step_{step:06d}
    plots: plots
    logs:
      root: logs
      wandb: ""
      mlflow: mlflow
      tensorboard: tensorboard
    profiler: profiler
  hardware:
    accelerator: cpu #auto # valid values: "cpu", "gpu", "auto"
    num_gpus_per_node: 1
    num_nodes: 1
    num_gpus_per_model: 1
graph:
  overwrite: true
  data: data
  hidden: hidden
  nodes:
    data:
      node_builder:
        _target_: anemoi.graphs.nodes.AnemoiDatasetNodes
        dataset: ${dataloader.training.dataset}
      attributes: ${graph.attributes.nodes}
    hidden:
      node_builder:
        _target_: anemoi.graphs.nodes.LimitedAreaTriNodes
        resolution: 6
        reference_node_name: ${graph.data}
        mask_attr_name: null # MX ???
        margin_radius_km: 100
  edges:
  - source_name: ${graph.data}
    target_name: ${graph.hidden}
    edge_builders:
    - _target_: anemoi.graphs.edges.CutOffEdges
      cutoff_factor: 0.6
      source_mask_attr_name: null
      target_mask_attr_name: null
      max_num_neighbours: 64
    attributes: ${graph.attributes.edges}
  - source_name: ${graph.hidden}
    target_name: ${graph.hidden}
    edge_builders:
    - _target_: anemoi.graphs.edges.MultiScaleEdges
      x_hops: 1
      scale_resolutions: ${graph.nodes.hidden.node_builder.resolution}
      source_mask_attr_name: null
      target_mask_attr_name: null
    attributes: ${graph.attributes.edges}
  - source_name: ${graph.hidden}
    target_name: ${graph.data}
    edge_builders:
    - _target_: anemoi.graphs.edges.KNNEdges
      num_nearest_neighbours: 3
      source_mask_attr_name: null
      target_mask_attr_name: null
    attributes: ${graph.attributes.edges}
#  post_processors:
#  - _target_: anemoi.graphs.processors.RemoveUnconnectedNodes
#    nodes_name: data
#    ignore: cutout_mask
#    save_mask_indices_to_attr: indices_connected_nodes
  attributes:
    nodes:
      area_weight:
        _target_: anemoi.graphs.nodes.attributes.SphericalAreaWeights
        fill_value: 0
        norm: unit-max
    edges:
      edge_length:
        _target_: anemoi.graphs.edges.attributes.EdgeLength
        norm: unit-std
      edge_dirs:
        _target_: anemoi.graphs.edges.attributes.EdgeDirection
        norm: unit-std
model:
  num_channels: 64
  cpu_offload: false
  keep_batch_sharded: true
  model:
    _target_: anemoi.models.models.AnemoiModelEncProcDec
  layer_kernels:
    LayerNorm:
      _target_: torch.nn.LayerNorm
    Linear:
      _target_: torch.nn.Linear
    Activation:
      _target_: torch.nn.GELU
    QueryNorm:
      _target_: anemoi.models.layers.normalization.AutocastLayerNorm
      bias: false
    KeyNorm:
      _target_: anemoi.models.layers.normalization.AutocastLayerNorm
      bias: false
  processor:
    _target_: anemoi.models.layers.processor.GraphTransformerProcessor
    trainable_size: ${model.trainable_parameters.hidden2hidden}
    sub_graph_edge_attributes: ${model.attributes.edges}
    num_layers: 4
    num_chunks: 4
    mlp_hidden_ratio: 4
    num_heads: 16
    qk_norm: false
    cpu_offload: ${model.cpu_offload}
    layer_kernels: ${model.layer_kernels}
    graph_attention_backend: pyg #triton
  encoder:
    _target_: anemoi.models.layers.mapper.GraphTransformerForwardMapper
    trainable_size: ${model.trainable_parameters.data2hidden}
    sub_graph_edge_attributes: ${model.attributes.edges}
    num_chunks: 4
    mlp_hidden_ratio: 4
    num_heads: 16
    qk_norm: false
    cpu_offload: ${model.cpu_offload}
    layer_kernels: ${model.layer_kernels}
    shard_strategy: edges
    graph_attention_backend: pyg #triton
  decoder:
    _target_: anemoi.models.layers.mapper.GraphTransformerBackwardMapper
    trainable_size: ${model.trainable_parameters.hidden2data}
    sub_graph_edge_attributes: ${model.attributes.edges}
    num_chunks: 4
    mlp_hidden_ratio: 4
    num_heads: 16
    initialise_data_extractor_zero: false
    qk_norm: false
    cpu_offload: ${model.cpu_offload}
    layer_kernels: ${model.layer_kernels}
    shard_strategy: edges
    graph_attention_backend: pyg #triton
  residual:
    _target_: anemoi.models.layers.residual.SkipConnection
    step: -1
  output_mask:
    _target_: anemoi.training.utils.masks.NoOutputMask
  trainable_parameters:
    data: 4
    hidden: 4
    data2hidden: 4
    hidden2data: 0
    hidden2hidden: 4
  compile: null
  #- module: anemoi.models.layers.conv.GraphTransformerConv
  attributes:
    edges:
    - edge_length
    - edge_dirs
    nodes: []
  bounding:
  - _target_: anemoi.models.layers.bounding.ReluBounding
    variables: []
    #- tp
training:
  scalers:
    general_variable:
      _target_: anemoi.training.losses.scalers.GeneralVariableLossScaler
      weights:
        default: 1
        q: 0.6
        t: 6
        u: 0.8
        v: 0.5
        w: 0.001
        z: 12
        sp: 10
        10u: 0.1
        10v: 0.1
        2d: 0.5
        tp: 0.025
        cp: 0.0025
    pressure_level:
      _target_: anemoi.training.losses.scalers.ReluVariableLevelScaler
      group: pl
      y_intercept: 0.2
      slope: 0.001
    nan_mask_weights:
      _target_: anemoi.training.losses.scalers.NaNMaskScaler
    #stdev_tendency:
    #  _target_: anemoi.training.losses.scalers.StdevTendencyScaler
    #var_tendency:
    #  _target_: anemoi.training.losses.scalers.VarTendencyScaler
    node_weights:
      _target_: anemoi.training.losses.scalers.GraphNodeAttributeScaler
      nodes_name: ${graph.data}
      nodes_attribute_name: area_weight
      norm: unit-sum
#    limited_area_mask:
#      _target_: anemoi.training.losses.scalers.GraphNodeAttributeScaler
#      nodes_name: ${graph.data}
#      nodes_attribute_name: cutout_mask
#      norm: null
  run_id: null
  fork_run_id: null
  transfer_learning: false
  load_weights_only: false
  deterministic: false
  precision: 16-mixed
  multistep_input: 2
  accum_grad_batches: 1
  num_sanity_val_steps: 6
  gradient_clip:
    val: 32.0
    algorithm: value
  swa:
    enabled: false
    lr: 0.0001
  optimizer:
    _target_: torch.optim.AdamW
    betas:
    - 0.9
    - 0.95
  model_task: anemoi.training.train.tasks.GraphDiagnoser
  strategy:
    _target_: anemoi.training.distributed.strategy.DDPGroupStrategy
    num_gpus_per_model: ${system.hardware.num_gpus_per_model}
    read_group_size: ${dataloader.read_group_size}
  loss_gradient_scaling: false
  training_loss:
    _target_: anemoi.training.losses.MSELoss
    scalers:
    - pressure_level
    - general_variable
    - node_weights
    ignore_nans: false
  validation_metrics:
    mse_inside_lam:
      _target_: anemoi.training.losses.MSELoss
      scalers:
      - node_weights
      ignore_nans: true
  variable_groups:
    default: sfc
    pl:
      param:
      - q
      - t
      - u
      - v
      - w
      - z
  metrics:
  - z_500
  - t_850
  - u_850
  - v_850
  rollout:
    start: 1
    epoch_increment: 0
    max: 1
  max_epochs: null
  max_steps: 70000
  lr:
    warmup: 1000
    rate: 6.25e-05
    iterations: ${training.max_steps}
    min: 3.0e-08
  submodules_to_freeze: []
  recompile_limit: 32
config_validation: true
